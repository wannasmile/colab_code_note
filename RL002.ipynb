{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannasmile/colab_code_note/blob/main/RL002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2mqo3wlhKKY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import pandas as pd\n",
        "import gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "takoF-rUiWXb"
      },
      "source": [
        "这段代码的目的是创建一个包含各种强化学习环境（来自`gym`库）特定信息的DataFrame。下面是对代码的详细解释：\n",
        "\n",
        "1. **初始化DataFrame列**：\n",
        "   ```python\n",
        "   space_names = ['观测空间', '动作空间', '奖励范围', '最大步数']\n",
        "   df = pd.DataFrame(columns=space_names)\n",
        "   ```\n",
        "   这里定义了一个名为`space_names`的列表，包含四个元素，分别代表DataFrame的列名。然后，使用这些列名创建一个空的DataFrame `df`。\n",
        "\n",
        "2. **获取所有注册的环境**：\n",
        "   ```python\n",
        "   env_specs = gym.envs.registry.all()\n",
        "   ```\n",
        "   通过调用`gym.envs.registry.all()`获取所有在`gym`库中注册的环境规格。`env_specs`是一个包含所有环境规格的列表。\n",
        "\n",
        "3. **遍历所有环境规格**：\n",
        "   ```python\n",
        "   for env_spec in env_specs:\n",
        "       env_id = env_spec.id\n",
        "   ```\n",
        "   遍历`env_specs`列表，每次迭代中获取环境的ID（`env_id`）。\n",
        "\n",
        "4. **尝试创建环境并记录信息**：\n",
        "   ```python\n",
        "   try:\n",
        "       env = gym.make(env_id)\n",
        "       observation_space = env.observation_space\n",
        "       action_space = env.action_space\n",
        "       reward_range = env.reward_range\n",
        "       max_episode_steps = None\n",
        "       if isinstance(env, gym.wrappers.time_limit.TimeLimit):\n",
        "           max_episode_steps = env._max_episode_steps\n",
        "       df.loc[env_id] = [observation_space, action_space, reward_range, max_episode_steps]\n",
        "   except:\n",
        "       pass\n",
        "   ```\n",
        "   在`try`块中，尝试使用`gym.make(env_id)`创建环境实例`env`。然后，从环境实例中提取以下信息：\n",
        "   - `observation_space`：观测空间，描述环境状态的格式和范围。\n",
        "   - `action_space`：动作空间，描述可以采取的动作的格式和范围。\n",
        "   - `reward_range`：奖励范围，一个元组，表示奖励的最小值和最大值。\n",
        "   - `max_episode_steps`：最大步数，如果环境是时间限制的（`TimeLimit`包装器），则提取`_max_episode_steps`属性；否则设置为`None`。\n",
        "\n",
        "   提取这些信息后，将它们作为一行添加到DataFrame `df`中，行索引为`env_id`。\n",
        "\n",
        "   如果在尝试创建环境或提取信息时发生错误，`except`块会捕获异常并跳过当前环境。\n",
        "\n",
        "5. **显示DataFrame**：\n",
        "   ```python\n",
        "   with pd.option_context('display.max_rows', None):\n",
        "       display(df)\n",
        "   ```\n",
        "   使用`pd.option_context`设置显示选项，使得DataFrame在输出时不限制行数。然后，使用`display`函数显示整个DataFrame。\n",
        "\n",
        "总之，这段代码的目的是遍历`gym`库中所有注册的环境，提取每个环境的观测空间、动作空间、奖励范围和最大步数，并将这些信息存储在一个DataFrame中以便查看和分析。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcuXC8R1jN8x"
      },
      "source": [
        "在强化学习中，观测空间、动作空间、奖励范围和最大步数是几个核心概念，它们共同定义了智能体与环境交互的基本框架。下面分别解释这些概念，并给出相应的例子。\n",
        "\n",
        "### 1. 观测空间（Observation Space）\n",
        "\n",
        "观测空间指的是智能体从环境中接收到的所有可能观测的集合。这些观测可以是环境的直接状态，也可以是经过某种处理（如传感器数据、图像处理等）后的信息。观测空间可以是连续的（如连续的图像数据）或离散的（如有限个传感器读数）。\n",
        "\n",
        "**例子**：在自动驾驶汽车的场景中，观测空间可能包括摄像头捕捉到的连续图像数据、激光雷达扫描结果、以及车辆自身的速度、加速度等传感器数据。智能体需要根据这些观测数据来做出决策。\n",
        "\n",
        "### 2. 动作空间（Action Space）\n",
        "\n",
        "动作空间是智能体可以采取的所有可能动作的集合。动作空间同样可以是连续的（如控制机械臂的连续角度变化）或离散的（如游戏中的移动指令上、下、左、右）。\n",
        "\n",
        "**例子**：在雅达利游戏Pong中，智能体的动作空间是离散的，包括向左移动挡板、向右移动挡板、不移动等。智能体需要根据当前的观测（如球和挡板的位置）来从这些动作中选择一个执行。\n",
        "\n",
        "### 3. 奖励范围（Reward Range）\n",
        "\n",
        "奖励范围是指智能体在执行动作后从环境中接收到的奖励值的范围。奖励是环境对智能体动作的一种即时反馈，用于指导智能体的学习。奖励范围可以是任意的实数区间，但通常为了简化问题，会将其限制在一个特定的范围内，如[-1, 1]或[0, 100]。\n",
        "\n",
        "**例子**：在迷宫探索任务中，智能体每走一步可能获得的奖励是-1（表示消耗了能量或时间），而当智能体找到出口时，可能获得一个较大的正奖励，如100。这样，智能体的目标就是通过学习找到一条从起点到出口的路径，使得累积奖励最大化。\n",
        "\n",
        "### 4. 最大步数（Maximum Episode Length）\n",
        "\n",
        "最大步数是指一个训练或测试回合中，智能体与环境交互的最大步数限制。这是为了避免智能体陷入无限循环或与环境的交互时间过长。当达到最大步数时，回合会强制结束，无论智能体是否完成了任务。\n",
        "\n",
        "**例子**：在玩超级玛丽兄弟这款游戏时，我们可以设定每个回合的最大步数为一定数量的游戏帧或时间单位。如果智能体在这么多步内未能通关或达到其他目标，回合就会结束，并计算该回合的累积奖励。\n",
        "\n",
        "综上所述，观测空间、动作空间、奖励范围和最大步数是强化学习中定义智能体与环境交互方式的关键要素。它们共同构成了强化学习问题的基本框架，使得智能体能够在复杂且不确定的环境中进行学习和决策。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "csb4EhHuhvNd",
        "outputId": "17a5be85-6423-4384-d78b-75ccf49a50f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:421: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Reacher-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Pusher-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment InvertedPendulum-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment InvertedDoublePendulum-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment HalfCheetah-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment HalfCheetah-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Hopper-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Hopper-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Swimmer-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Swimmer-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Walker2d-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Walker2d-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Ant-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Ant-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Humanoid-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Humanoid-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment HumanoidStandup-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: -inf",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ee901a93-f520-4216-abe7-a408b511f845\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>观测空间</th>\n",
              "      <th>动作空间</th>\n",
              "      <th>奖励范围</th>\n",
              "      <th>最大步数</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CartPole-v0</th>\n",
              "      <td>Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...</td>\n",
              "      <td>Discrete(2)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CartPole-v1</th>\n",
              "      <td>Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...</td>\n",
              "      <td>Discrete(2)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MountainCar-v0</th>\n",
              "      <td>Box([-1.2  -0.07], [0.6  0.07], (2,), float32)</td>\n",
              "      <td>Discrete(3)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MountainCarContinuous-v0</th>\n",
              "      <td>Box([-1.2  -0.07], [0.6  0.07], (2,), float32)</td>\n",
              "      <td>Box(-1.0, 1.0, (1,), float32)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pendulum-v1</th>\n",
              "      <td>Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)</td>\n",
              "      <td>Box(-2.0, 2.0, (1,), float32)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acrobot-v1</th>\n",
              "      <td>Box([ -1.        -1.        -1.        -1.    ...</td>\n",
              "      <td>Discrete(3)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Blackjack-v1</th>\n",
              "      <td>(Discrete(32), Discrete(11), Discrete(2))</td>\n",
              "      <td>Discrete(2)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FrozenLake-v1</th>\n",
              "      <td>Discrete(16)</td>\n",
              "      <td>Discrete(4)</td>\n",
              "      <td>(0, 1)</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FrozenLake8x8-v1</th>\n",
              "      <td>Discrete(64)</td>\n",
              "      <td>Discrete(4)</td>\n",
              "      <td>(0, 1)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CliffWalking-v0</th>\n",
              "      <td>Discrete(48)</td>\n",
              "      <td>Discrete(4)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Taxi-v3</th>\n",
              "      <td>Discrete(500)</td>\n",
              "      <td>Discrete(6)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee901a93-f520-4216-abe7-a408b511f845')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee901a93-f520-4216-abe7-a408b511f845 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee901a93-f520-4216-abe7-a408b511f845');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0584aa61-c023-4686-b300-c7095b796fd6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0584aa61-c023-4686-b300-c7095b796fd6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0584aa61-c023-4686-b300-c7095b796fd6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                                       观测空间  \\\n",
              "CartPole-v0               Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...   \n",
              "CartPole-v1               Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...   \n",
              "MountainCar-v0               Box([-1.2  -0.07], [0.6  0.07], (2,), float32)   \n",
              "MountainCarContinuous-v0     Box([-1.2  -0.07], [0.6  0.07], (2,), float32)   \n",
              "Pendulum-v1                   Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)   \n",
              "Acrobot-v1                Box([ -1.        -1.        -1.        -1.    ...   \n",
              "Blackjack-v1                      (Discrete(32), Discrete(11), Discrete(2))   \n",
              "FrozenLake-v1                                                  Discrete(16)   \n",
              "FrozenLake8x8-v1                                               Discrete(64)   \n",
              "CliffWalking-v0                                                Discrete(48)   \n",
              "Taxi-v3                                                       Discrete(500)   \n",
              "\n",
              "                                                   动作空间         奖励范围  最大步数  \n",
              "CartPole-v0                                 Discrete(2)  (-inf, inf)   200  \n",
              "CartPole-v1                                 Discrete(2)  (-inf, inf)   500  \n",
              "MountainCar-v0                              Discrete(3)  (-inf, inf)   200  \n",
              "MountainCarContinuous-v0  Box(-1.0, 1.0, (1,), float32)  (-inf, inf)   999  \n",
              "Pendulum-v1               Box(-2.0, 2.0, (1,), float32)  (-inf, inf)   200  \n",
              "Acrobot-v1                                  Discrete(3)  (-inf, inf)   500  \n",
              "Blackjack-v1                                Discrete(2)  (-inf, inf)  None  \n",
              "FrozenLake-v1                               Discrete(4)       (0, 1)   100  \n",
              "FrozenLake8x8-v1                            Discrete(4)       (0, 1)   200  \n",
              "CliffWalking-v0                             Discrete(4)  (-inf, inf)  None  \n",
              "Taxi-v3                                     Discrete(6)  (-inf, inf)   200  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "space_names = ['观测空间', '动作空间', '奖励范围', '最大步数']\n",
        "df = pd.DataFrame(columns=space_names)\n",
        "\n",
        "env_specs = gym.envs.registry.all()\n",
        "for env_spec in env_specs:\n",
        "    env_id = env_spec.id\n",
        "    try:\n",
        "        env = gym.make(env_id)\n",
        "        observation_space = env.observation_space\n",
        "        action_space = env.action_space\n",
        "        reward_range = env.reward_range\n",
        "        max_episode_steps = None\n",
        "        if isinstance(env, gym.wrappers.time_limit.TimeLimit):\n",
        "            max_episode_steps = env._max_episode_steps\n",
        "        df.loc[env_id] = [observation_space, action_space, reward_range, max_episode_steps]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "with pd.option_context('display.max_rows', None):\n",
        "    display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur2eoTmWkRCZ",
        "outputId": "a68f47de-f616-4957-affd-3fb1bdbc3ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "观测空间 = Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)\n",
            "动作空间 = Box(-2.0, 2.0, (1,), float32)\n",
            "观测范围 = [-1. -1. -8.] ~ [1. 1. 8.]\n",
            "动作空间形状 = (1,)\n",
            "动作范围 = [-2.] ~ [2.]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('Pendulum-v1')\n",
        "print('观测空间 = {}'.format(env.observation_space))\n",
        "print('动作空间 = {}'.format(env.action_space))\n",
        "print('观测范围 = {} ~ {}'.format(env.observation_space.low,\n",
        "        env.observation_space.high))\n",
        "#print('动作数 = {}'.format(env.action_space.n))\n",
        "\n",
        "# 对于连续动作空间，打印动作空间的形状和范围\n",
        "if isinstance(env.action_space, gym.spaces.Box):\n",
        "    print('动作空间形状 = {}'.format(env.action_space.shape))\n",
        "    print('动作范围 = {} ~ {}'.format(env.action_space.low, env.action_space.high))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzuMG0m1MIR"
      },
      "source": [
        "注意：\n",
        " `Pendulum-v1` 环境的动作空间是一个连续空间（`Box` 类型），而不是一个离散空间（如 `Discrete` 类型）。在连续空间中，没有 `n` 这个属性，因为动作不是离散的、有限数量的选项，而是一个在一定范围内的连续值。\n",
        "\n",
        "可以打印出动作空间的形状或范围：\n",
        "\n",
        "```python\n",
        "import gym\n",
        "\n",
        "env = gym.make('Pendulum-v1')\n",
        "print('观测空间 = {}'.format(env.observation_space))\n",
        "print('动作空间 = {}'.format(env.action_space))\n",
        "print('观测范围 = {} ~ {}'.format(env.observation_space.low,\n",
        "                                  env.observation_space.high))\n",
        "# 对于连续动作空间，打印动作空间的形状和范围\n",
        "if isinstance(env.action_space, gym.spaces.Box):\n",
        "    print('动作空间形状 = {}'.format(env.action_space.shape))\n",
        "    print('动作范围 = {} ~ {}'.format(env.action_space.low, env.action_space.high))\n",
        "```\n",
        "\n",
        "这段代码首先检查动作空间是否为 `Box` 类型，然后打印出相应的形状和范围。这样，就可以正确地处理 `Pendulum-v1` 环境的连续动作空间了。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzktz-ekmXg"
      },
      "source": [
        "这段代码定义了一个名为 `BespokeAgent` 的类，该类似乎被设计用于在某个环境（通过 `env` 参数指定）中做出决策。以下是对代码的详细解释：\n",
        "\n",
        "### 类定义：`BespokeAgent`\n",
        "\n",
        "1. **初始化方法：`__init__`**\n",
        "    ```python\n",
        "    def __init__(self, env):\n",
        "        pass\n",
        "    ```\n",
        "    - 这个方法是类的构造函数，用于初始化对象的状态。在这里，它接收一个参数 `env`，但并未对其进行任何操作（使用了 `pass` 语句）。可能的设计意图是在未来扩展初始化过程，目前只是一个占位符。\n",
        "\n",
        "2. **决策方法：`decide`**\n",
        "    ```python\n",
        "    def decide(self, observation):\n",
        "        position, velocity = observation\n",
        "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
        "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
        "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
        "        if lb < velocity < ub:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 0\n",
        "        return action\n",
        "    ```\n",
        "    - 这个方法用于根据当前的 `observation`（观测值）来做出决策。\n",
        "    - `observation` 被解构为两个变量：`position`（位置）和 `velocity`（速度）。\n",
        "    - 计算两个界限值 `lb`（下界）和 `ub`（上界）。这些界限值是基于位置的复杂数学表达式计算得出的。\n",
        "    - 如果速度 `velocity` 位于 `lb` 和 `ub` 之间，则采取动作 `2`；否则，采取动作 `0`。\n",
        "    - 最终返回所选择的动作。\n",
        "\n",
        "3. **学习方法：`learn`**\n",
        "    ```python\n",
        "    def learn(self, *args):\n",
        "        pass\n",
        "    ```\n",
        "    - 这个方法设计为用于学习，但目前未实现任何功能（使用了 `pass` 语句）。它接收任意数量的参数（通过 `*args`），可能用于未来添加学习相关的逻辑。\n",
        "\n",
        "### 创建 `BespokeAgent` 实例\n",
        "\n",
        "```python\n",
        "agent = BespokeAgent(env)\n",
        "```\n",
        "- 这行代码创建了一个 `BespokeAgent` 类的实例，并将其赋值给变量 `agent`。\n",
        "- `env` 是传递给构造函数的参数，代表智能体所处的环境。尽管在 `__init__` 方法中未对 `env` 进行任何操作，但通常这样的设计意味着未来可能会在这个环境中使用或存储相关信息。\n",
        "\n",
        "### 总结\n",
        "\n",
        "这个 `BespokeAgent` 类目前主要实现了一个基于位置和速度观测值进行决策的简单逻辑。学习功能尚未实现，可能是为将来的扩展预留的。代码中的数学表达式和逻辑可能特定于某个应用场景（如物理模拟、控制系统等），需要根据具体背景进一步理解。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPE1KpJSkizM"
      },
      "outputs": [],
      "source": [
        "class BespokeAgent:\n",
        "    def __init__(self, env):\n",
        "        pass\n",
        "\n",
        "    def decide(self, observation): # 决策\n",
        "        position, velocity = observation\n",
        "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
        "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
        "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
        "        if lb < velocity < ub:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 0\n",
        "        return action # 返回动作\n",
        "\n",
        "    def learn(self, *args): # 学习\n",
        "        pass\n",
        "\n",
        "agent = BespokeAgent(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtPLzXzs2JZf"
      },
      "source": [
        "为了与 `Pendulum-v1` 环境兼容，我们需要对您的 `BespokeAgent` 类进行一些调整。首先，`Pendulum-v1` 环境的观测空间是一个三维数组，包括摆的角度（`theta`）、角速度（`theta_dot`）以及一个辅助的角度表示（通常用于处理角度的周期性，即 `sin(theta)` 和 `cos(theta)` 之一，但在直接的观测中通常不包括这个）。因此，我们需要适应这个三维的输入。\n",
        "\n",
        "其次，`Pendulum-v1` 的动作空间是一个连续的区间，通常在 `[-2.0, 2.0]` 内（这取决于环境的具体实现，但这是常见的范围），而不是离散的几个动作。因此，我们的决策函数需要输出一个在这个区间内的连续值，而不是离散的 `0` 或 `2`。\n",
        "\n",
        "下面是根据 `Pendulum-v1` 环境修改后的 `BespokeAgent` 类：\n",
        "\n",
        "```python\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "class BespokeAgent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        # 可以初始化一些其他需要的参数或模型\n",
        "\n",
        "    def decide(self, observation): # 决策\n",
        "        # observation 是一个包含 theta, theta_dot (可能还有 sin(theta), cos(theta)) 的数组\n",
        "        theta, theta_dot = observation[:2]  # 我们只使用 theta 和 theta_dot\n",
        "        \n",
        "        # 这里我们可以设计一个基于 theta 和 theta_dot 的控制策略\n",
        "        # 例如，使用一个简单的 PD 控制器（比例-微分控制器）\n",
        "        kp = -1.0  # 比例系数（需要调试）\n",
        "        kd = -0.1  # 微分系数（需要调试）\n",
        "        action = kp * theta + kd * theta_dot\n",
        "        \n",
        "        # 限制动作在 [-2.0, 2.0] 范围内（这是 Pendulum-v1 的常见动作范围）\n",
        "        action = np.clip(action, -2.0, 2.0)\n",
        "        \n",
        "        return action # 返回动作\n",
        "\n",
        "    def learn(self, *args): # 学习\n",
        "        # 目前不实现学习功能\n",
        "        pass\n",
        "\n",
        "# 创建 Pendulum-v1 环境\n",
        "env = gym.make('Pendulum-v1')\n",
        "# 初始化代理\n",
        "agent = BespokeAgent(env)\n",
        "\n",
        "# 示例：如何使用代理进行决策\n",
        "observation = env.reset()  # 重置环境，获取初始观测\n",
        "action = agent.decide(observation)  # 使用代理的决策函数获取动作\n",
        "```\n",
        "\n",
        "在这个修改后的版本中，`decide` 方法现在接受一个三维的观测数组（尽管我们只使用了前两个元素，即角度和角速度），并输出一个在 `[-2.0, 2.0]` 范围内的连续动作值。这里我们使用了一个简单的 PD 控制器作为控制策略的例子，但您可以根据需要替换为更复杂的控制逻辑或学习算法。\n",
        "\n",
        "请注意，这个代码示例没有实现学习功能（`learn` 方法是空的），因为您提供的原始代码也没有包含学习逻辑。如果您想实现学习功能，您需要在 `learn` 方法中添加相应的算法，并使用环境提供的反馈（例如奖励和新的观测）来更新代理的内部状态或参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz20zH142Yke"
      },
      "outputs": [],
      "source": [
        "class BespokeAgent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        # 可以初始化一些其他需要的参数或模型\n",
        "\n",
        "    def decide(self, observation): # 决策\n",
        "        ## observation 是一个包含 theta, theta_dot (可能还有 sin(theta), cos(theta)) 的数组\n",
        "        #theta, theta_dot = observation[:2]  # 我们只使用 theta 和 theta_dot\n",
        "        # observation 是一个包含 [cos(theta), sin(theta), theta_dot] 的数组\n",
        "        cos_theta, sin_theta, theta_dot = observation\n",
        "        theta = np.arctan2(sin_theta, cos_theta)  # 计算 theta\n",
        "\n",
        "        # 这里我们可以设计一个基于 theta 和 theta_dot 的控制策略\n",
        "        # 例如，使用一个简单的 PD 控制器（比例-微分控制器）\n",
        "        kp = -1.0  # 比例系数（需要调试）\n",
        "        kd = -0.1  # 微分系数（需要调试）\n",
        "        action = kp * theta + kd * theta_dot\n",
        "\n",
        "        # 限制动作在 [-2.0, 2.0] 范围内（这是 Pendulum-v1 的常见动作范围）\n",
        "        action = np.clip(action, -2.0, 2.0)\n",
        "\n",
        "        #return action # 返回动作\n",
        "        return [action]  # 返回动作，需要是一个列表\n",
        "\n",
        "    def learn(self, *args): # 学习\n",
        "        # 目前不实现学习功能\n",
        "        pass\n",
        "\n",
        "# 创建 Pendulum-v1 环境\n",
        "env = gym.make('Pendulum-v1')\n",
        "# 初始化代理\n",
        "agent = BespokeAgent(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n4aiuT2k3Pj"
      },
      "source": [
        "智能体与环境交互"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAcjBdQXnjcV"
      },
      "source": [
        "在Colab环境中，直接显示图形界面通常是不支持的，因为Colab运行在云端，而你无法直接查看或交互云端的图形界面。不过，你可以通过一些方法间接地查看图形输出，比如使用视频流或将图像保存为文件然后查看。\n",
        "\n",
        "对于强化学习环境，一个常见的做法是将环境的渲染输出转换为图像，并在Colab中显示这些图像。这通常涉及到修改环境代码或使用特定的库来捕获渲染输出。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkuTYJuJk32Q"
      },
      "outputs": [],
      "source": [
        "def play_montecarlo(env, agent, render=False, train=False):\n",
        "    episode_reward = 0. # 记录回合总奖励，初始化为0\n",
        "    observation = env.reset() # 重置游戏环境，开始新回合\n",
        "    while True: # 不断循环，直到回合结束\n",
        "        if render: # 判断是否显示\n",
        "            env.render() # 显示图形界面，图形界面可以用 env.close() 语句关闭\n",
        "        action = agent.decide(observation)\n",
        "        next_observation, reward, done, _ = env.step(action) # 执行动作\n",
        "        episode_reward += reward # 收集回合奖励\n",
        "        if train: # 判断是否训练智能体\n",
        "            agent.learn(observation, action, reward, done) # 学习\n",
        "        if done: # 回合结束，跳出循环\n",
        "            break\n",
        "        observation = next_observation\n",
        "    return episode_reward # 返回回合总奖励"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAIGpM7JnC4Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "\n",
        "def play_montecarlo(env, agent, render=False, train=False):\n",
        "    episode_reward = 0.  # 记录回合总奖励，初始化为0\n",
        "    observation = env.reset()  # 重置游戏环境，开始新回合\n",
        "\n",
        "    images = []  # 用于存储渲染图像的列表\n",
        "\n",
        "    while True:  # 不断循环，直到回合结束\n",
        "        if render:\n",
        "            # 捕获渲染输出为图像数组\n",
        "            img = env.render(mode='rgb_array')\n",
        "            images.append(img)  # 将图像添加到列表中\n",
        "\n",
        "        action = agent.decide(observation)\n",
        "        next_observation, reward, done, _ = env.step(action)  # 执行动作\n",
        "\n",
        "        episode_reward += reward  # 收集回合奖励\n",
        "\n",
        "        if train:  # 判断是否训练智能体\n",
        "            agent.learn(observation, action, reward, done)  # 学习\n",
        "\n",
        "        if done:  # 回合结束，跳出循环\n",
        "            break\n",
        "\n",
        "        observation = next_observation\n",
        "\n",
        "    if render:\n",
        "        # 在Colab中逐个显示图像\n",
        "        for img in images:\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            display(plt.gcf())  # 显示当前图像\n",
        "            time.sleep(0.1)  # 控制显示速度\n",
        "            clear_output(wait=True)  # 清除之前的输出\n",
        "            plt.close()  # 关闭图像窗口，避免内存泄漏\n",
        "\n",
        "    return episode_reward  # 返回回合总奖励\n",
        "\n",
        "# 注意：确保你的环境支持'rgb_array'模式，并且已经安装了必要的库（如matplotlib）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC2mqJf_lMmP"
      },
      "source": [
        "交互1回合，并图形化显示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7GKJb3Y6k7Rg",
        "outputId": "68d960f4-67bf-4040-ce95-6352d05b6c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "回合奖励 = -1500.760615988375\n"
          ]
        }
      ],
      "source": [
        "#env.seed(0) # 设置随机数种子，只是为了让结果可以精确复现，一般情况下可删去\n",
        "env.reset(seed=0)  # 新版本的 gym 中，使用 reset() 方法设置种子\n",
        "episode_reward = play_montecarlo(env, agent, render=True)\n",
        "print('回合奖励 = {}'.format(episode_reward))\n",
        "env.close() # 此语句可关闭图形界面"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm7ZHaSEoeNn"
      },
      "source": [
        "评估性能：交互10回合求平均\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "jNG4gm1QoEt2",
        "outputId": "2bebbe9c-314f-422b-ea79-2129ee290710"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "平均回合奖励 = -1241.8867404610673\n"
          ]
        }
      ],
      "source": [
        "episode_rewards = [play_montecarlo(env, agent, render=True) for _ in range(10)]\n",
        "print('平均回合奖励 = {}'.format(np.mean(episode_rewards)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMtWc2a8Vgncv/htUw9MU5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}