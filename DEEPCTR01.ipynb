{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHhQ1Vq/Y046lJ2aGl0vfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannasmile/colab_code_note/blob/main/DEEPCTR01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQfVc2LSMO0T",
        "outputId": "166a050e-275f-4887-efe8-197808edc1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepctr-torch in /usr/local/lib/python3.11/dist-packages (0.2.9)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from deepctr-torch) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepctr-torch) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from deepctr-torch) (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from deepctr-torch) (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deepctr-torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->deepctr-torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepctr-torch) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepctr-torch) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepctr-torch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepctr-torch) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->deepctr-torch) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->deepctr-torch) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->deepctr-torch) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->deepctr-torch) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->deepctr-torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->deepctr-torch) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->deepctr-torch) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->deepctr-torch) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U deepctr-torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/shenweichen/DeepCTR/refs/heads/master/examples/criteo_sample.txt -O ./criteo_sample.txt\n",
        "!head -5 ./criteo_sample.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_AJzUg7M8pR",
        "outputId": "0552935f-2464-4cfa-b9e4-0abec09abbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 08:38:09--  https://raw.githubusercontent.com/shenweichen/DeepCTR/refs/heads/master/examples/criteo_sample.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52518 (51K) [text/plain]\n",
            "Saving to: ‘./criteo_sample.txt’\n",
            "\n",
            "./criteo_sample.txt 100%[===================>]  51.29K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-19 08:38:09 (1.05 MB/s) - ‘./criteo_sample.txt’ saved [52518/52518]\n",
            "\n",
            "label,I1,I2,I3,I4,I5,I6,I7,I8,I9,I10,I11,I12,I13,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26\n",
            "0,,3,260.0,,17668.0,,,33.0,,,,0.0,,05db9164,08d6d899,9143c832,f56b7dd5,25c83c98,7e0ccccf,df5c2d18,0b153874,a73ee510,8f48ce11,a7b606c4,ae1bb660,eae197fd,b28479f6,bfef54b3,bad5ee18,e5ba7672,87c6f83c,,,0429f84b,,3a171ecb,c0d61a5c,,\n",
            "0,,-1,19.0,35.0,30251.0,247.0,1.0,35.0,160.0,,1.0,,35.0,68fd1e64,04e09220,95e13fd4,a1e6a194,25c83c98,fe6b92e5,f819e175,062b5529,a73ee510,ab9456b4,6153cf57,8882c6cd,769a1844,b28479f6,69f825dd,23056e4f,d4bb7bd8,6fc84bfb,,,5155d8a3,,be7c41b4,ded4aac9,,\n",
            "0,0.0,0,2.0,12.0,2013.0,164.0,6.0,35.0,523.0,0.0,3.0,,18.0,05db9164,38a947a1,3f55fb72,5de245c7,30903e74,7e0ccccf,b72ec13d,1f89b562,a73ee510,acce978c,3547565f,a5b0521a,12880350,b28479f6,c12fc269,95a8919c,e5ba7672,675c9258,,,2e01979f,,bcdee96c,6d5d1302,,\n",
            "0,,13,1.0,4.0,16836.0,200.0,5.0,4.0,29.0,,2.0,,4.0,05db9164,8084ee93,02cf9876,c18be181,25c83c98,,e14874c9,0b153874,7cc72ec2,2462946f,636405ac,8fe001f4,31b42deb,07d13a8f,422c8577,36103458,e5ba7672,52e44668,,,e587c466,,32c7478e,3b183c5c,,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#movielens_sample.txt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/shenweichen/DeepCTR/refs/heads/master/examples/movielens_sample.txt -O ./movielens_sample.txt\n",
        "!head -5 ./movielens_sample.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWvRhMH5Qd1N",
        "outputId": "37c9f2d9-eadc-4e07-fe0d-558ad29ccb2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 08:38:09--  https://raw.githubusercontent.com/shenweichen/DeepCTR/refs/heads/master/examples/movielens_sample.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15155 (15K) [text/plain]\n",
            "Saving to: ‘./movielens_sample.txt’\n",
            "\n",
            "./movielens_sample. 100%[===================>]  14.80K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-02-19 08:38:09 (5.26 MB/s) - ‘./movielens_sample.txt’ saved [15155/15155]\n",
            "\n",
            "user_id,movie_id,rating,timestamp,title,genres,gender,age,occupation,zip\n",
            "3299,235,4,968035345,Ed Wood (1994),Comedy|Drama,F,25,4,19119\n",
            "3630,3256,3,966536874,Patriot Games (1992),Action|Thriller,M,18,4,77005\n",
            "517,105,4,976203603,\"Bridges of Madison County, The (1995)\",Drama|Romance,F,25,14,55408\n",
            "785,2115,3,975430389,Indiana Jones and the Temple of Doom (1984),Action|Adventure,M,18,19,29307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#byterec_sample.txt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/shenweichen/DeepCTR-Torch/refs/heads/master/examples/byterec_sample.txt -O ./byterec_sample.txt\n",
        "!head -5 ./byterec_sample.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyMQz1QbUpW1",
        "outputId": "0a4c9e8c-0af1-46b7-903e-720a1ec4f412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 08:38:10--  https://raw.githubusercontent.com/shenweichen/DeepCTR-Torch/refs/heads/master/examples/byterec_sample.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11048 (11K) [text/plain]\n",
            "Saving to: ‘./byterec_sample.txt’\n",
            "\n",
            "./byterec_sample.tx 100%[===================>]  10.79K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-02-19 08:38:10 (8.22 MB/s) - ‘./byterec_sample.txt’ saved [11048/11048]\n",
            "\n",
            "37448\t115\t567569\t44888\t42\t0\t0\t0\t1699\t43981\t53085738314\t9\n",
            "8623\t82\t1209192\t10098\t106\t0\t1\t0\t-1\t11996\t53086444998\t8\n",
            "9629\t31\t1209193\t184752\t109\t0\t1\t0\t-1\t32093\t53085591140\t5\n",
            "52799\t175\t1209194\t109629\t101\t0\t1\t0\t-1\t33106\t53085915481\t6\n",
            "38008\t-1\t1209195\t456237\t11\t1\t0\t1\t56\t18558\t53085805030\t9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "\n",
        "data = pd.read_csv('./criteo_sample.txt')\n",
        "\n",
        "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
        "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
        "\n",
        "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
        "data[dense_features] = data[dense_features].fillna(0, )\n",
        "target = ['label']"
      ],
      "metadata": {
        "id": "7KlxbyUXMx3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for feat in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feat] = lbe.fit_transform(data[feat])"
      ],
      "metadata": {
        "id": "3EtwjsrJM0dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mms = MinMaxScaler(feature_range=(0,1))\n",
        "data[dense_features] = mms.fit_transform(data[dense_features])"
      ],
      "metadata": {
        "id": "5Q5lFMtNM7Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4)\n",
        "               for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
        "               for feat in dense_features]"
      ],
      "metadata": {
        "id": "RhQIRgy5NiLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_feature_columns = [feat for feat in fixlen_feature_columns if isinstance(feat, SparseFeat)]\n",
        "dense_feature_columns = [feat for feat in fixlen_feature_columns if isinstance(feat, DenseFeat)]\n"
      ],
      "metadata": {
        "id": "h9c4yvIZPBUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
        "linear_feature_columns = sparse_feature_columns + dense_feature_columns\n",
        "\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
      ],
      "metadata": {
        "id": "Y4ZxOxW-OjwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr_torch.models import *  # 导入所有模型\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 读取数据\n",
        "    data = pd.read_csv('./criteo_sample.txt')\n",
        "\n",
        "    # 定义稀疏特征和稠密特征\n",
        "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
        "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
        "\n",
        "    # 填充缺失值\n",
        "    data[sparse_features] = data[sparse_features].fillna('-1', )\n",
        "    data[dense_features] = data[dense_features].fillna(0, )\n",
        "\n",
        "    # 定义目标列\n",
        "    target = ['label']\n",
        "\n",
        "    # 对稀疏特征进行标签编码，对稠密特征进行归一化\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "    mms = MinMaxScaler(feature_range=(0, 1))\n",
        "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "    # 定义特征列\n",
        "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
        "                              for feat in sparse_features] + [DenseFeat(feat, 1, )\n",
        "                                                              for feat in dense_features]\n",
        "\n",
        "    # 定义DNN和线性模型的特征列\n",
        "    dnn_feature_columns = fixlen_feature_columns\n",
        "    linear_feature_columns = fixlen_feature_columns\n",
        "\n",
        "    # 获取特征名称\n",
        "    feature_names = get_feature_names(\n",
        "        linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    # 划分训练集和测试集\n",
        "    train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "    # 生成模型输入数据\n",
        "    train_model_input = {name: train[name] for name in feature_names}\n",
        "    test_model_input = {name: test[name] for name in feature_names}\n",
        "\n",
        "    # 设置设备\n",
        "    device = 'cpu'\n",
        "    use_cuda = True\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        print('cuda ready...')\n",
        "        device = 'cuda:0'\n",
        "\n",
        "    # 实例化 DeepFM 模型\n",
        "    model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n",
        "                   task='binary',\n",
        "                   l2_reg_embedding=1e-5, device=device)\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(\"adagrad\", \"binary_crossentropy\",\n",
        "                  metrics=[\"binary_crossentropy\", \"auc\"], )\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(train_model_input, train[target].values, batch_size=32, epochs=10, verbose=2, validation_split=0.0)\n",
        "\n",
        "    # 预测\n",
        "    pred_ans = model.predict(test_model_input, 256)\n",
        "    print(\"\")\n",
        "    print(\"测试集 LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
        "    print(\"测试集 AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMy_qfTfOlm-",
        "outputId": "e11cce19-9141-4873-ec73-543177f0c9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Train on 160 samples, validate on 0 samples, 5 steps per epoch\n",
            "Epoch 1/10\n",
            "0s - loss:  0.6049 - binary_crossentropy:  0.6049 - auc:  0.6198\n",
            "Epoch 2/10\n",
            "0s - loss:  0.4926 - binary_crossentropy:  0.4926 - auc:  0.9594\n",
            "Epoch 3/10\n",
            "0s - loss:  0.3798 - binary_crossentropy:  0.3798 - auc:  0.9854\n",
            "Epoch 4/10\n",
            "0s - loss:  0.2233 - binary_crossentropy:  0.2233 - auc:  0.9981\n",
            "Epoch 5/10\n",
            "0s - loss:  0.1210 - binary_crossentropy:  0.1210 - auc:  1.0000\n",
            "Epoch 6/10\n",
            "0s - loss:  0.0760 - binary_crossentropy:  0.0760 - auc:  1.0000\n",
            "Epoch 7/10\n",
            "0s - loss:  0.0464 - binary_crossentropy:  0.0464 - auc:  1.0000\n",
            "Epoch 8/10\n",
            "0s - loss:  0.0326 - binary_crossentropy:  0.0326 - auc:  1.0000\n",
            "Epoch 9/10\n",
            "0s - loss:  0.0241 - binary_crossentropy:  0.0241 - auc:  1.0000\n",
            "Epoch 10/10\n",
            "0s - loss:  0.0186 - binary_crossentropy:  0.0186 - auc:  1.0000\n",
            "\n",
            "测试集 LogLoss 0.6906\n",
            "测试集 AUC 0.5305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from deepctr_torch.inputs import SparseFeat, get_feature_names\n",
        "from deepctr_torch.models import DeepFM\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 读取数据\n",
        "    data = pd.read_csv(\"./movielens_sample.txt\")\n",
        "\n",
        "    # 定义稀疏特征和目标列\n",
        "    sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "    target = ['rating']\n",
        "\n",
        "    # 对稀疏特征进行标签编码\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "\n",
        "    # 定义特征列\n",
        "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
        "                              for feat in sparse_features]\n",
        "\n",
        "    # 线性部分和DNN部分共享特征列\n",
        "    linear_feature_columns = fixlen_feature_columns\n",
        "    dnn_feature_columns = fixlen_feature_columns\n",
        "\n",
        "    # 获取特征名称\n",
        "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    # 划分训练集和测试集\n",
        "    train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "    # 生成模型输入数据\n",
        "    train_model_input = {name: train[name] for name in feature_names}\n",
        "    test_model_input = {name: test[name] for name in feature_names}\n",
        "\n",
        "    # 设置设备\n",
        "    device = 'cpu'\n",
        "    use_cuda = True\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        print('cuda ready...')\n",
        "        device = 'cuda:0'\n",
        "\n",
        "    # 实例化 DeepFM 模型\n",
        "    model = DeepFM(linear_feature_columns, dnn_feature_columns,\n",
        "                   task='regression', device=device)\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
        "\n",
        "    # 训练模型\n",
        "    history = model.fit(train_model_input, train[target].values,\n",
        "              batch_size=256, epochs=10, verbose=2, validation_split=0.2)\n",
        "\n",
        "    # 预测\n",
        "    pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "\n",
        "    # 评估模型\n",
        "    print(\"test MSE\", round(mean_squared_error(test[target].values, pred_ans), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZSiuddYQsc2",
        "outputId": "9eb2716f-085c-4b17-c772-ff73bf4c0b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Train on 128 samples, validate on 32 samples, 1 steps per epoch\n",
            "Epoch 1/10\n",
            "0s - loss:  13.9808 - mse:  13.9808 - val_mse:  12.7248\n",
            "Epoch 2/10\n",
            "0s - loss:  13.6224 - mse:  13.6224 - val_mse:  12.4549\n",
            "Epoch 3/10\n",
            "0s - loss:  13.3178 - mse:  13.3178 - val_mse:  12.2009\n",
            "Epoch 4/10\n",
            "0s - loss:  13.0299 - mse:  13.0299 - val_mse:  11.9613\n",
            "Epoch 5/10\n",
            "0s - loss:  12.7569 - mse:  12.7569 - val_mse:  11.7313\n",
            "Epoch 6/10\n",
            "0s - loss:  12.4935 - mse:  12.4935 - val_mse:  11.4927\n",
            "Epoch 7/10\n",
            "0s - loss:  12.2205 - mse:  12.2205 - val_mse:  11.2453\n",
            "Epoch 8/10\n",
            "0s - loss:  11.9378 - mse:  11.9378 - val_mse:  10.9888\n",
            "Epoch 9/10\n",
            "0s - loss:  11.6449 - mse:  11.6449 - val_mse:  10.7232\n",
            "Epoch 10/10\n",
            "0s - loss:  11.3416 - mse:  11.3416 - val_mse:  10.4484\n",
            "test MSE 12.3667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.nn.utils.rnn import pad_sequence  # 使用 PyTorch 的 pad_sequence\n",
        "\n",
        "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names\n",
        "from deepctr_torch.models import DeepFM\n",
        "\n",
        "\n",
        "def split(x):\n",
        "    \"\"\"\n",
        "    将字符串按 '|' 分割，并将每个子字符串编码为数字索引。\n",
        "\n",
        "    Args:\n",
        "        x (str): 待分割的字符串。\n",
        "\n",
        "    Returns:\n",
        "        list: 编码后的数字索引列表。\n",
        "    \"\"\"\n",
        "    key_ans = x.split('|')\n",
        "    for key in key_ans:\n",
        "        if key not in key2index:\n",
        "            # 输入值 0 用作特殊填充，因此不用 0 编码有效特征\n",
        "            key2index[key] = len(key2index) + 1\n",
        "    return list(map(lambda x: key2index[x], key_ans))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 读取数据\n",
        "    data = pd.read_csv(\"./movielens_sample.txt\")\n",
        "    # 定义稀疏特征和目标列\n",
        "    sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "    target = ['rating']\n",
        "\n",
        "    # 1. 对稀疏特征进行标签编码，并处理序列特征\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "\n",
        "    # 预处理序列特征\n",
        "    key2index = {}\n",
        "    genres_list = list(map(split, data['genres'].values))\n",
        "    genres_length = np.array(list(map(len, genres_list)))\n",
        "    max_len = max(genres_length)\n",
        "\n",
        "    # 使用 pad_sequence 进行填充，注意 padding='post'\n",
        "    genres_list = pad_sequence([torch.tensor(seq) for seq in genres_list],\n",
        "                               batch_first=True, padding_value=0)\n",
        "    genres_list = genres_list.numpy()  # 将填充后的序列转换回 numpy 数组\n",
        "\n",
        "    # 2. 统计每个稀疏字段的唯一特征数量，并生成序列特征的特征配置\n",
        "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n",
        "                              for feat in sparse_features]\n",
        "\n",
        "    varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres',\n",
        "                                  vocabulary_size=len(key2index) + 1,\n",
        "                                  embedding_dim=4),\n",
        "                                  maxlen=max_len,\n",
        "                                  combiner='mean')]\n",
        "    # 注意：值 0 用于序列输入特征的填充\n",
        "\n",
        "\n",
        "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "\n",
        "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    # 3. 生成模型输入数据\n",
        "    model_input = {name: data[name] for name in sparse_features}\n",
        "    model_input[\"genres\"] = genres_list\n",
        "\n",
        "    # 4. 定义模型、编译和训练\n",
        "    device = 'cpu'\n",
        "    use_cuda = True\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        print('cuda ready...')\n",
        "        device = 'cuda:0'\n",
        "\n",
        "    model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
        "\n",
        "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
        "    history = model.fit(model_input, data[target].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F8LmrFPUFZj",
        "outputId": "ec20517c-70b0-4a77-c60e-e33d3ec8795f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Train on 160 samples, validate on 40 samples, 1 steps per epoch\n",
            "Epoch 1/10\n",
            "0s - loss:  14.1966 - mse:  14.1966 - val_mse:  13.0705\n",
            "Epoch 2/10\n",
            "0s - loss:  13.8377 - mse:  13.8377 - val_mse:  12.7593\n",
            "Epoch 3/10\n",
            "0s - loss:  13.4977 - mse:  13.4977 - val_mse:  12.4681\n",
            "Epoch 4/10\n",
            "0s - loss:  13.1783 - mse:  13.1783 - val_mse:  12.2118\n",
            "Epoch 5/10\n",
            "0s - loss:  12.8950 - mse:  12.8950 - val_mse:  11.9611\n",
            "Epoch 6/10\n",
            "0s - loss:  12.6174 - mse:  12.6174 - val_mse:  11.7014\n",
            "Epoch 7/10\n",
            "0s - loss:  12.3304 - mse:  12.3304 - val_mse:  11.4324\n",
            "Epoch 8/10\n",
            "0s - loss:  12.0336 - mse:  12.0336 - val_mse:  11.1540\n",
            "Epoch 9/10\n",
            "0s - loss:  11.7269 - mse:  11.7269 - val_mse:  10.8661\n",
            "Epoch 10/10\n",
            "0s - loss:  11.4098 - mse:  11.4098 - val_mse:  10.5684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr_torch.models import *  # 导入所有模型\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 读取数据\n",
        "    data = pd.read_csv('./byterec_sample.txt', sep='\\t',\n",
        "                       names=[\"uid\", \"user_city\", \"item_id\", \"author_id\", \"item_city\", \"channel\", \"finish\", \"like\", \"music_id\", \"device\", \"time\", \"duration_time\"])\n",
        "\n",
        "    # 定义稀疏特征和稠密特征\n",
        "    sparse_features = [\"uid\", \"user_city\", \"item_id\", \"author_id\", \"item_city\", \"channel\", \"music_id\", \"device\"]\n",
        "    dense_features = [\"duration_time\"]\n",
        "\n",
        "    # 定义目标列\n",
        "    target = ['finish', 'like']\n",
        "\n",
        "    # 1. 对稀疏特征进行标签编码，对稠密特征进行归一化\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "    mms = MinMaxScaler(feature_range=(0, 1))\n",
        "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "    # 2. 统计每个稀疏字段的唯一特征数量，并记录稠密特征字段名称\n",
        "    fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].max() + 1, embedding_dim=4) for feat in sparse_features] \\\n",
        "                   + [DenseFeat(feat, 1, ) for feat in dense_features]\n",
        "\n",
        "    # 定义DNN和线性模型的特征列\n",
        "    dnn_feature_columns = fixlen_feature_columns\n",
        "    linear_feature_columns = fixlen_feature_columns\n",
        "\n",
        "    # 获取特征名称\n",
        "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    # 3. 生成模型输入数据\n",
        "    split_boundary = int(data.shape[0] * 0.8)\n",
        "    train, test = data[:split_boundary], data[split_boundary:]\n",
        "    train_model_input = {name: train[name] for name in feature_names}\n",
        "    test_model_input = {name: test[name] for name in feature_names}\n",
        "\n",
        "    # 4. 定义模型、编译和训练\n",
        "    device = 'cpu'\n",
        "    use_cuda = True\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        print('cuda ready...')\n",
        "        device = 'cuda:0'\n",
        "\n",
        "    model = MMOE(dnn_feature_columns, task_types=['binary', 'binary'], l2_reg_embedding=1e-5, task_names=target, device=device)\n",
        "    model.compile(\"adagrad\", loss=[\"binary_crossentropy\", \"binary_crossentropy\"], metrics=['binary_crossentropy'], )\n",
        "\n",
        "    history = model.fit(train_model_input, train[target].values, batch_size=32, epochs=10, verbose=2)\n",
        "    pred_ans = model.predict(test_model_input, 256)\n",
        "    print(\"\")\n",
        "    for i, target_name in enumerate(target):\n",
        "        print(\"%s test LogLoss\" % target_name, round(log_loss(test[target[i]].values, pred_ans[:, i]), 4))\n",
        "        print(\"%s test AUC\" % target_name, round(roc_auc_score(test[target[i]].values, pred_ans[:, i]), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDaAiNZDWQTD",
        "outputId": "96119f13-c64d-4fd0-8a32-1f6fbaccd3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Train on 160 samples, validate on 0 samples, 5 steps per epoch\n",
            "Epoch 1/10\n",
            "0s - loss:  1.2010 - binary_crossentropy:  0.3464\n",
            "Epoch 2/10\n",
            "0s - loss:  0.8224 - binary_crossentropy:  0.4682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10\n",
            "0s - loss:  0.7603 - binary_crossentropy:  0.4649\n",
            "Epoch 4/10\n",
            "0s - loss:  0.7151 - binary_crossentropy:  0.4720\n",
            "Epoch 5/10\n",
            "0s - loss:  0.6240 - binary_crossentropy:  0.4508\n",
            "Epoch 6/10\n",
            "0s - loss:  0.5370 - binary_crossentropy:  0.4022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10\n",
            "0s - loss:  0.4642 - binary_crossentropy:  0.3761\n",
            "Epoch 8/10\n",
            "0s - loss:  0.4122 - binary_crossentropy:  0.3443\n",
            "Epoch 9/10\n",
            "0s - loss:  0.3710 - binary_crossentropy:  0.3159\n",
            "Epoch 10/10\n",
            "0s - loss:  0.3381 - binary_crossentropy:  0.2989\n",
            "\n",
            "finish test LogLoss 0.8588\n",
            "finish test AUC 0.5303\n",
            "like test LogLoss 0.3686\n",
            "like test AUC 0.6842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}