{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4gr11qVqbA+/phHyomyh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannasmile/colab_code_note/blob/main/SIMFLW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wSkGQrMboP0j"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "''' Operation classes in computational graph.\n",
        "'''\n",
        "from queue import Queue\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Operation(object):\n",
        "    ''' Base class for all operations in simpleflow.\n",
        "    An operation is a node in computational graph receiving zero or more nodes\n",
        "    as input and produce zero or more nodes as output. Vertices could be an\n",
        "    operation, variable or placeholder.\n",
        "    '''\n",
        "    def __init__(self, *input_nodes, name=None):\n",
        "        ''' Operation constructor.\n",
        "        :param input_nodes: Input nodes for the operation node.\n",
        "        :type input_nodes: Objects of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The operation name.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        # Nodes received by this operation.\n",
        "        self.input_nodes = input_nodes\n",
        "\n",
        "        # Nodes that receive this operation node as input.\n",
        "        self.output_nodes = []\n",
        "\n",
        "        # Output value of this operation in session execution.\n",
        "        self.output_value = None\n",
        "\n",
        "        # Operation name.\n",
        "        self.name = name\n",
        "\n",
        "        # Graph the operation belongs to.\n",
        "        self.graph = DEFAULT_GRAPH\n",
        "\n",
        "        # Add this operation node to destination lists in its input nodes.\n",
        "        for node in input_nodes:\n",
        "            node.output_nodes.append(self)\n",
        "\n",
        "        # Add this operation to default graph.\n",
        "        self.graph.operations.append(self)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the output value of the operation.\n",
        "        '''\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute and return the gradient of the operation wrt inputs.\n",
        "        '''\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return Add(self, other)\n",
        "\n",
        "    def __neg__(self):\n",
        "        return Negative(self)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        return Add(self, Negative(other))\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        return Multiply(self, other)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Addition operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Add(Operation):\n",
        "    ''' An addition operation.\n",
        "    '''\n",
        "    def __init__(self, x, y, name=None):\n",
        "        ''' Addition constructor.\n",
        "        :param x: The first input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param y: The second input node.\n",
        "        :type y: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The operation name.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x, y, name=name)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the value of addition operation.\n",
        "        '''\n",
        "        x, y = self.input_nodes\n",
        "        self.output_value = np.add(x.output_value, y.output_value)\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute the gradients for this operation wrt input values.\n",
        "        :param grad: The gradient of other operation wrt the addition output.\n",
        "        :type grad: number or a ndarray, default value is 1.0.\n",
        "        '''\n",
        "        x, y = [node.output_value for node in self.input_nodes]\n",
        "\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "\n",
        "        grad_wrt_x = grad\n",
        "        while np.ndim(grad_wrt_x) > len(np.shape(x)):\n",
        "            grad_wrt_x = np.sum(grad_wrt_x, axis=0)\n",
        "        for axis, size in enumerate(np.shape(x)):\n",
        "            if size == 1:\n",
        "                grad_wrt_x = np.sum(grad_wrt_x, axis=axis, keepdims=True)\n",
        "\n",
        "        grad_wrt_y = grad\n",
        "        while np.ndim(grad_wrt_y) > len(np.shape(y)):\n",
        "            grad_wrt_y = np.sum(grad_wrt_y, axis=0)\n",
        "        for axis, size in enumerate(np.shape(y)):\n",
        "            if size == 1:\n",
        "                grad_wrt_y = np.sum(grad_wrt_y, axis=axis, keepdims=True)\n",
        "\n",
        "        return [grad_wrt_x, grad_wrt_y]\n",
        "\n",
        "def add(x, y, name=None):\n",
        "    ''' Returns x + y element-wise.\n",
        "    '''\n",
        "    return Add(x, y, name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Multiplication operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Multiply(Operation):\n",
        "    ''' Multiplication operation.\n",
        "    '''\n",
        "    def __init__(self, x, y, name=None):\n",
        "        ''' Multiplication constructor.\n",
        "        :param x: The first input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param y: The second input node.\n",
        "        :type y: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The operation name.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x, y, name=name)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the multiplication operation result.\n",
        "        '''\n",
        "        x, y = self.input_nodes\n",
        "        self.output_value = np.multiply(x.output_value, y.output_value)\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute and return gradients for this operation wrt input values.\n",
        "        :param grad: The gradient of other operation wrt the mutiply output.\n",
        "        :type grad: number or a ndarray.\n",
        "        '''\n",
        "        x, y = [node.output_value for node in self.input_nodes]\n",
        "\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "\n",
        "        grad_wrt_x = grad*y\n",
        "        while np.ndim(grad_wrt_x) > len(np.shape(x)):\n",
        "            grad_wrt_x = np.sum(grad_wrt_x, axis=0)\n",
        "        for axis, size in enumerate(np.shape(x)):\n",
        "            if size == 1:\n",
        "                grad_wrt_x = np.sum(grad_wrt_x, axis=axis, keepdims=True)\n",
        "\n",
        "        grad_wrt_y = grad*x\n",
        "        while np.ndim(grad_wrt_y) > len(np.shape(y)):\n",
        "            grad_wrt_y = np.sum(grad_wrt_y, axis=0)\n",
        "        for axis, size in enumerate(np.shape(y)):\n",
        "            if size == 1:\n",
        "                grad_wrt_y = np.sum(grad_wrt_y, axis=axis, keepdims=True)\n",
        "\n",
        "        return [grad_wrt_x, grad_wrt_y]\n",
        "\n",
        "def multiply(x, y, name=None):\n",
        "    ''' Returns x * y element-wise.\n",
        "    '''\n",
        "    return Multiply(x, y, name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Matrix multiplication operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class MatMul(Operation):\n",
        "    ''' Matrix multiplication operation.\n",
        "    '''\n",
        "    def __init__(self, x, y, name=None):\n",
        "        ''' MatMul constructor.\n",
        "        :param x: The first input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param y: The second input node.\n",
        "        :type y: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The operation name.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x, y, name=name)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the multiplication operation result.\n",
        "        '''\n",
        "        x, y = self.input_nodes\n",
        "        self.output_value = np.dot(x.output_value, y.output_value)\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute and return the gradient for matrix multiplication.\n",
        "        :param grad: The gradient of other operation wrt the matmul output.\n",
        "        :type grad: number or a ndarray, default value is 1.0.\n",
        "        '''\n",
        "        # Get input values.\n",
        "        x, y = [node.output_value for node in self.input_nodes]\n",
        "\n",
        "        # Default gradient wrt the matmul output.\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "\n",
        "        # Gradients wrt inputs.\n",
        "        dfdx = np.dot(grad, np.transpose(y))\n",
        "        dfdy = np.dot(np.transpose(x), grad)\n",
        "\n",
        "        return [dfdx, dfdy]\n",
        "\n",
        "def matmul(x, y, name=None):\n",
        "    ''' Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
        "    '''\n",
        "    return MatMul(x, y, name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Sigmoid operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Sigmoid(Operation):\n",
        "    ''' Sigmoid operation.\n",
        "    '''\n",
        "    def __init__(self, x, name=None):\n",
        "        ''' Sigmoid operation constructor.\n",
        "        :param x: The input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The operation name.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x, name=name)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the value of sigmoid function.\n",
        "        '''\n",
        "        x, = self.input_nodes\n",
        "        self.output_value = 1/(1 + np.exp(-x.output_value))\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute the gradient for sigmoid operation wrt input value.\n",
        "        :param grad: The gradient of other operation wrt the sigmoid output.\n",
        "        :type grad: ndarray.\n",
        "        '''\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "        return grad*self.output_value*(1 - self.output_value)\n",
        "\n",
        "def sigmoid(x, name=None):\n",
        "    ''' Computes sigmoid of `x` element-wise.\n",
        "    '''\n",
        "    return Sigmoid(x, name=name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Logarithm operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Log(Operation):\n",
        "    ''' Natural logarithm operation.\n",
        "    '''\n",
        "    def __init__(self, x, name=None):\n",
        "        ''' Logarithm constructor.\n",
        "        :param x: The input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The operation name.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x, name=name)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the value of sigmoid function.\n",
        "        '''\n",
        "        x, = self.input_nodes\n",
        "        self.output_value = np.log(x.output_value)\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute the gradient for natural logarithm operation wrt input value.\n",
        "        :param grad: The gradient of other operation wrt the logarithm output.\n",
        "        :type grad: ndarray.\n",
        "        '''\n",
        "        x = self.input_nodes[0].output_value\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "        return grad*1/x\n",
        "\n",
        "def log(x, name=None):\n",
        "    ''' Computes the natural logarithm of x element-wise.\n",
        "    '''\n",
        "    return Log(x, name=name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Negative operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Negative(Operation):\n",
        "    ''' Negative operation.\n",
        "    '''\n",
        "    def __init__(self, x, name=None):\n",
        "        ''' Operation constructor.\n",
        "        :param x: The input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The operation name.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x, name=name)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the value of sigmoid function.\n",
        "        '''\n",
        "        x, = self.input_nodes\n",
        "        self.output_value = -x.output_value\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute the gradient for negative operation wrt input value.\n",
        "        :param grad: The gradient of other operation wrt the negative output.\n",
        "        :type grad: ndarray.\n",
        "        '''\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "        return -grad\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Reduce sum operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class ReduceSum(Operation):\n",
        "    ''' Reduce sum operation.\n",
        "    '''\n",
        "    def __init__(self, x, axis=None):\n",
        "        ''' Operation constructor.\n",
        "        :param x: The input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param axis: The dimensions to reduce. If `None`, reduces all dimensions.\n",
        "        :type axis: int.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x)\n",
        "        self.axis = axis\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the value of sigmoid function.\n",
        "        '''\n",
        "        x, = self.input_nodes\n",
        "        self.output_value = np.sum(x.output_value, self.axis)\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute the gradient for negative operation wrt input value.\n",
        "        :param grad: The gradient of other operation wrt the negative output.\n",
        "        :type grad: ndarray.\n",
        "        '''\n",
        "        input_value = self.input_nodes[0].output_value\n",
        "\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "\n",
        "        output_shape = np.array(np.shape(input_value))\n",
        "        output_shape[self.axis] = 1.0\n",
        "        tile_scaling = np.shape(input_value) // output_shape\n",
        "        grad = np.reshape(grad, output_shape)\n",
        "        return np.tile(grad, tile_scaling)\n",
        "\n",
        "def reduce_sum(x, axis=None):\n",
        "    ''' Computes the sum of elements across dimensions of a tensor.\n",
        "    '''\n",
        "    return ReduceSum(x, axis=axis)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Square operation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Square(Operation):\n",
        "    ''' Square operation.\n",
        "    '''\n",
        "    def __init__(self, x, name=None):\n",
        "        ''' Operation constructor.\n",
        "        :param x: The input node.\n",
        "        :type x: Object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param name: The name of the operation.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        super(self.__class__, self).__init__(x, name=name)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the value of square function.\n",
        "        '''\n",
        "        x, = self.input_nodes\n",
        "        self.output_value = np.square(x.output_value)\n",
        "        return self.output_value\n",
        "\n",
        "    def compute_gradient(self, grad=None):\n",
        "        ''' Compute the gradient for square operation wrt input value.\n",
        "        :param grad: The gradient of other operation wrt the square output.\n",
        "        :type grad: ndarray.\n",
        "        '''\n",
        "        input_value = self.input_nodes[0].output_value\n",
        "\n",
        "        if grad is None:\n",
        "            grad = np.ones_like(self.output_value)\n",
        "\n",
        "        return grad*np.multiply(2.0, input_value)\n",
        "\n",
        "def square(x, name=None):\n",
        "    ''' Computes square of x element-wise.\n",
        "    '''\n",
        "    return Square(x, name=name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Constant node\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Constant(object):\n",
        "    ''' Constant node in computational graph.\n",
        "    '''\n",
        "    def __init__(self, value, name=None):\n",
        "        ''' Cosntant constructor.\n",
        "        '''\n",
        "        # Constant value.\n",
        "        self.value = value\n",
        "\n",
        "        # Output value of this operation in session.\n",
        "        self.output_value = None\n",
        "\n",
        "        # Nodes that receive this variable node as input.\n",
        "        self.output_nodes = []\n",
        "\n",
        "        # Operation name.\n",
        "        self.name = name\n",
        "\n",
        "        # Add to graph.\n",
        "        DEFAULT_GRAPH.constants.append(self)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the constant value.\n",
        "        '''\n",
        "        if self.output_value is None:\n",
        "            self.output_value = self.value\n",
        "        return self.output_value\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return Add(self, other)\n",
        "\n",
        "    def __neg__(self):\n",
        "        return Negative(self)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        return Add(self, Negative(other))\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        return Multiply(self, other)\n",
        "\n",
        "def constant(value, name=None):\n",
        "    ''' Create a constant node.\n",
        "    '''\n",
        "    return Constant(value, name=name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Variable node\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Variable(object):\n",
        "    ''' Variable node in computational graph.\n",
        "    '''\n",
        "    def __init__(self, initial_value=None, name=None, trainable=True): \n",
        "        ''' Variable constructor.\n",
        "        :param initial_value: The initial value of the variable.\n",
        "        :type initial_value: number or a ndarray.\n",
        "        :param name: Name of the variable.\n",
        "        :type name: str.\n",
        "        '''\n",
        "        # Variable initial value.\n",
        "        self.initial_value = initial_value\n",
        "\n",
        "        # Output value of this operation in session execution.\n",
        "        self.output_value = None\n",
        "\n",
        "        # Nodes that receive this variable node as input.\n",
        "        self.output_nodes = []\n",
        "\n",
        "        # Variable name.\n",
        "        self.name = name\n",
        "\n",
        "        # Graph the variable belongs to.\n",
        "        self.graph = DEFAULT_GRAPH\n",
        "\n",
        "        # Add to the currently active default graph.\n",
        "        self.graph.variables.append(self)\n",
        "        if trainable:\n",
        "            self.graph.trainable_variables.append(self)\n",
        "\n",
        "    def compute_output(self):\n",
        "        ''' Compute and return the variable value.\n",
        "        '''\n",
        "        if self.output_value is None:\n",
        "            self.output_value = self.initial_value\n",
        "        return self.output_value\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return Add(self, other)\n",
        "\n",
        "    def __neg__(self):\n",
        "        return Negative(self)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        return Add(self, Negative(other))\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        return Multiply(self, other)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Placeholder node\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class Placeholder(object):\n",
        "    ''' Placeholder node in computational graph. It has to be provided a value when\n",
        "        when computing the output of a graph.\n",
        "    '''\n",
        "    def __init__(self, name=None):\n",
        "        ''' Placeholdef constructor.\n",
        "        '''\n",
        "        # Output value of this operation in session execution.\n",
        "        self.output_value = None\n",
        "\n",
        "        # Nodes that receive this placeholder node as input.\n",
        "        self.output_nodes = []\n",
        "\n",
        "        # Placeholder node name.\n",
        "        self.name = name\n",
        "\n",
        "        # Graph the placeholder node belongs to.\n",
        "        self.graph = DEFAULT_GRAPH\n",
        "\n",
        "        # Add to the currently active default graph.\n",
        "        self.graph.placeholders.append(self)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return Add(self, other)\n",
        "\n",
        "    def __neg__(self):\n",
        "        return Negative(self)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        return Add(self, Negative(other))\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        return Multiply(self, other)\n",
        "\n",
        "def placeholder(name=None):\n",
        "    ''' Inserts a placeholder for a node that will be always fed.\n",
        "    '''\n",
        "    return Placeholder(name=name)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Function for gradients computation.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def compute_gradients(target_op):\n",
        "    ''' Backpropagation implementation computing gradient of target operation wrt\n",
        "        all the other connected nodes.\n",
        "    :param target_op: The target operation whose gradient wrt other nodes would\n",
        "                      be computed.\n",
        "    :type target_op: Any operation type.\n",
        "    :return grad_table: A table containing node objects and gradients.\n",
        "    :type grad_table: dict.\n",
        "    '''\n",
        "    # A dict containing a mapping between node and gradient value of target_op wrt the node's output.\n",
        "    # NOTE: It is the gradient wrt the node's OUTPUT NOT input.\n",
        "    grad_table = {}\n",
        "\n",
        "    # The gradient wrt target_op itself is 1.\n",
        "    grad_table[target_op] = np.ones_like(target_op.output_value)\n",
        "\n",
        "    # Perform a breadth-first search staring from the target_op in graph.\n",
        "    # Queue for node traverasl.\n",
        "    queue = Queue()\n",
        "    queue.put(target_op)\n",
        "\n",
        "    # Set for visited nodes.\n",
        "    visited = set()\n",
        "    visited.add(target_op)\n",
        "\n",
        "    while not queue.empty():\n",
        "        node = queue.get()\n",
        "\n",
        "        # Compute gradient wrt the node's output.\n",
        "        if node != target_op:\n",
        "            grads_wrt_node_output = []\n",
        "\n",
        "            for output_node in node.output_nodes:\n",
        "                # Retrieve the gradient wrt output_node's OUTPUT.\n",
        "                grad_wrt_output_node_output = grad_table[output_node]\n",
        "\n",
        "                # Compute the gradient wrt current node's output.\n",
        "                grad_wrt_node_output = output_node.compute_gradient(grad_wrt_output_node_output)\n",
        "                if len(output_node.input_nodes) > 1:\n",
        "                    input_node_index = output_node.input_nodes.index(node)\n",
        "                    grads_wrt_node_output.append(grad_wrt_node_output[input_node_index])\n",
        "                else:\n",
        "                    grads_wrt_node_output.append(grad_wrt_node_output)\n",
        "\n",
        "            # Sum all gradients wrt node's output.\n",
        "            tot_grad_wrt_node_output = sum(grads_wrt_node_output)\n",
        "            grad_table[node] = tot_grad_wrt_node_output\n",
        "\n",
        "        # Put adjecent nodes to queue.\n",
        "        if hasattr(node, 'input_nodes'):\n",
        "            for input_node in node.input_nodes:\n",
        "                if input_node not in visited:\n",
        "                    visited.add(input_node)\n",
        "                    queue.put(input_node)\n",
        "\n",
        "    return grad_table\n",
        "\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "''' Computational graph definition.\n",
        "'''\n",
        "\n",
        "class Graph(object):\n",
        "    ''' Graph containing all computing nodes.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        ''' Graph constructor.\n",
        "        '''\n",
        "        self.operations, self.constants, self.placeholders = [], [], []\n",
        "        self.variables, self.trainable_variables = [], []\n",
        "\n",
        "    def __enter__(self):\n",
        "        ''' Reset default graph.\n",
        "        '''\n",
        "        global DEFAULT_GRAPH\n",
        "        self.old_graph = DEFAULT_GRAPH\n",
        "        DEFAULT_GRAPH = self\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
        "        ''' Recover default graph.\n",
        "        '''\n",
        "        global DEFAULT_GRAPH\n",
        "        DEFAULT_GRAPH = self.old_graph\n",
        "\n",
        "    def as_default(self):\n",
        "        ''' Set this graph as global default graph.\n",
        "        '''\n",
        "        return self\n",
        "\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "''' Session to execute a computational graph.\n",
        "'''\n",
        "from functools import reduce\n",
        "\n",
        "#from .operations import Operation, Variable, Placeholder\n",
        "\n",
        "class Session(object):\n",
        "    ''' A session to compute a particular graph.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        ''' Session constructor.\n",
        "        '''\n",
        "        # Graph the session computes for.\n",
        "        self.graph = DEFAULT_GRAPH\n",
        "\n",
        "    def __enter__(self):\n",
        "        ''' Context management protocal method called before `with-block`.\n",
        "        '''\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
        "        ''' Context management protocal method called after `with-block`.\n",
        "        '''\n",
        "        self.close()\n",
        "\n",
        "    def close(self):\n",
        "        ''' Free all output values in nodes.\n",
        "        '''\n",
        "        all_nodes = (self.graph.constants + self.graph.variables +\n",
        "                     self.graph.placeholders + self.graph.operations +\n",
        "                     self.graph.trainable_variables)\n",
        "        for node in all_nodes:\n",
        "            node.output_value = None\n",
        "\n",
        "    def run(self, operation, feed_dict=None):\n",
        "        ''' Compute the output of an operation.\n",
        "        :param operation: A specific operation to be computed.\n",
        "        :type operation: object of `Operation`, `Variable` or `Placeholder`.\n",
        "        :param feed_dict: A mapping between placeholder and its actual value for the session.\n",
        "        :type feed_dict: dict.\n",
        "        '''\n",
        "        # Get all prerequisite nodes using postorder traversal.\n",
        "        postorder_nodes = _get_prerequisite(operation)\n",
        "\n",
        "        for node in postorder_nodes:\n",
        "            if type(node) is Placeholder:\n",
        "                node.output_value = feed_dict[node]\n",
        "            else:  # Operation and variable\n",
        "                node.compute_output()\n",
        "\n",
        "        return operation.output_value\n",
        "\n",
        "def _get_prerequisite(operation):\n",
        "    ''' Perform a post-order traversal to get a list of nodes to be computed in order.\n",
        "    '''\n",
        "    postorder_nodes = []\n",
        "\n",
        "    # Collection nodes recursively.\n",
        "    def postorder_traverse(operation):\n",
        "        if isinstance(operation, Operation):\n",
        "            for input_node in operation.input_nodes:\n",
        "                postorder_traverse(input_node)\n",
        "        postorder_nodes.append(operation)\n",
        "\n",
        "    postorder_traverse(operation)\n",
        "\n",
        "    return postorder_nodes\n",
        "\n",
        "\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "''' Optimizer classes for parameters optimization.\n",
        "'''\n",
        "#from .operations import Operation, compute_gradients\n",
        "\n",
        "class GradientDescentOptimizer(object):\n",
        "    ''' Optimizer that implements the gradient descent algorithm.\n",
        "    '''\n",
        "    def __init__(self, learning_rate):\n",
        "        ''' Construct a new gradient descent optimizer\n",
        "        :param learning_rate: learning rate of optimizier.\n",
        "        :type learning_rate: float\n",
        "        '''\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def minimize(self, loss):\n",
        "        ''' Generate an gradient descent optimization operation for loss.\n",
        "        :param loss: The loss operation to be optimized.\n",
        "        :type loss: Object of `Operation`\n",
        "        '''\n",
        "        learning_rate = self.learning_rate\n",
        "\n",
        "        class MinimizationOperation(Operation):\n",
        "            def compute_output(self):\n",
        "                # Get gradient table.\n",
        "                grad_table = compute_gradients(loss)\n",
        "\n",
        "                # Iterate all trainable variables in graph.\n",
        "                for var in DEFAULT_GRAPH.trainable_variables:\n",
        "                    if var in grad_table:\n",
        "                        grad = grad_table[var]\n",
        "\n",
        "                    # Update its output value.\n",
        "                    var.output_value -= learning_rate*grad\n",
        "\n",
        "        return MinimizationOperation()\n",
        "\n",
        "\n",
        "\n",
        "import builtins\n",
        "DEFAULT_GRAPH = builtins.DEFAULT_GRAPH = Graph()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import simpleflow as sf\n",
        "\n",
        "# Create a graph\n",
        "with Graph().as_default():\n",
        "    a = constant(1.0, name='a')\n",
        "    b = constant(2.0, name='b')\n",
        "    result = add(a, b, name='a+b')\n",
        "\n",
        "    # Create a session to run the graph \n",
        "    with Session() as sess:\n",
        "        print(sess.run(result))\n",
        "\n",
        "\n",
        "\n",
        "#import simpleflow as sf\n",
        "#\n",
        "## Create a graph\n",
        "#with sf.Graph().as_default():\n",
        "#    a = sf.constant(1.0, name='a')\n",
        "#    b = sf.constant(2.0, name='b')\n",
        "#    result = sf.add(a, b, name='a+b')\n",
        "#\n",
        "#    # Create a session to run the graph \n",
        "#    with sf.Session() as sess:\n",
        "#        print(sess.run(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae3kI__Xrtol",
        "outputId": "074c4e68-01d8-4e25-8de8-5ed4d6ea0bee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0\n"
          ]
        }
      ]
    }
  ]
}