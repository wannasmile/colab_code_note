{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMbo0C3iC+d/D/2MSoC0xM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannasmile/colab_code_note/blob/main/RL001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p2mqo3wlhKKY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import pandas as pd\n",
        "import gym"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码的目的是创建一个包含各种强化学习环境（来自`gym`库）特定信息的DataFrame。下面是对代码的详细解释：\n",
        "\n",
        "1. **初始化DataFrame列**：\n",
        "   ```python\n",
        "   space_names = ['观测空间', '动作空间', '奖励范围', '最大步数']\n",
        "   df = pd.DataFrame(columns=space_names)\n",
        "   ```\n",
        "   这里定义了一个名为`space_names`的列表，包含四个元素，分别代表DataFrame的列名。然后，使用这些列名创建一个空的DataFrame `df`。\n",
        "\n",
        "2. **获取所有注册的环境**：\n",
        "   ```python\n",
        "   env_specs = gym.envs.registry.all()\n",
        "   ```\n",
        "   通过调用`gym.envs.registry.all()`获取所有在`gym`库中注册的环境规格。`env_specs`是一个包含所有环境规格的列表。\n",
        "\n",
        "3. **遍历所有环境规格**：\n",
        "   ```python\n",
        "   for env_spec in env_specs:\n",
        "       env_id = env_spec.id\n",
        "   ```\n",
        "   遍历`env_specs`列表，每次迭代中获取环境的ID（`env_id`）。\n",
        "\n",
        "4. **尝试创建环境并记录信息**：\n",
        "   ```python\n",
        "   try:\n",
        "       env = gym.make(env_id)\n",
        "       observation_space = env.observation_space\n",
        "       action_space = env.action_space\n",
        "       reward_range = env.reward_range\n",
        "       max_episode_steps = None\n",
        "       if isinstance(env, gym.wrappers.time_limit.TimeLimit):\n",
        "           max_episode_steps = env._max_episode_steps\n",
        "       df.loc[env_id] = [observation_space, action_space, reward_range, max_episode_steps]\n",
        "   except:\n",
        "       pass\n",
        "   ```\n",
        "   在`try`块中，尝试使用`gym.make(env_id)`创建环境实例`env`。然后，从环境实例中提取以下信息：\n",
        "   - `observation_space`：观测空间，描述环境状态的格式和范围。\n",
        "   - `action_space`：动作空间，描述可以采取的动作的格式和范围。\n",
        "   - `reward_range`：奖励范围，一个元组，表示奖励的最小值和最大值。\n",
        "   - `max_episode_steps`：最大步数，如果环境是时间限制的（`TimeLimit`包装器），则提取`_max_episode_steps`属性；否则设置为`None`。\n",
        "\n",
        "   提取这些信息后，将它们作为一行添加到DataFrame `df`中，行索引为`env_id`。\n",
        "\n",
        "   如果在尝试创建环境或提取信息时发生错误，`except`块会捕获异常并跳过当前环境。\n",
        "\n",
        "5. **显示DataFrame**：\n",
        "   ```python\n",
        "   with pd.option_context('display.max_rows', None):\n",
        "       display(df)\n",
        "   ```\n",
        "   使用`pd.option_context`设置显示选项，使得DataFrame在输出时不限制行数。然后，使用`display`函数显示整个DataFrame。\n",
        "\n",
        "总之，这段代码的目的是遍历`gym`库中所有注册的环境，提取每个环境的观测空间、动作空间、奖励范围和最大步数，并将这些信息存储在一个DataFrame中以便查看和分析。"
      ],
      "metadata": {
        "id": "takoF-rUiWXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在强化学习中，观测空间、动作空间、奖励范围和最大步数是几个核心概念，它们共同定义了智能体与环境交互的基本框架。下面分别解释这些概念，并给出相应的例子。\n",
        "\n",
        "### 1. 观测空间（Observation Space）\n",
        "\n",
        "观测空间指的是智能体从环境中接收到的所有可能观测的集合。这些观测可以是环境的直接状态，也可以是经过某种处理（如传感器数据、图像处理等）后的信息。观测空间可以是连续的（如连续的图像数据）或离散的（如有限个传感器读数）。\n",
        "\n",
        "**例子**：在自动驾驶汽车的场景中，观测空间可能包括摄像头捕捉到的连续图像数据、激光雷达扫描结果、以及车辆自身的速度、加速度等传感器数据。智能体需要根据这些观测数据来做出决策。\n",
        "\n",
        "### 2. 动作空间（Action Space）\n",
        "\n",
        "动作空间是智能体可以采取的所有可能动作的集合。动作空间同样可以是连续的（如控制机械臂的连续角度变化）或离散的（如游戏中的移动指令上、下、左、右）。\n",
        "\n",
        "**例子**：在雅达利游戏Pong中，智能体的动作空间是离散的，包括向左移动挡板、向右移动挡板、不移动等。智能体需要根据当前的观测（如球和挡板的位置）来从这些动作中选择一个执行。\n",
        "\n",
        "### 3. 奖励范围（Reward Range）\n",
        "\n",
        "奖励范围是指智能体在执行动作后从环境中接收到的奖励值的范围。奖励是环境对智能体动作的一种即时反馈，用于指导智能体的学习。奖励范围可以是任意的实数区间，但通常为了简化问题，会将其限制在一个特定的范围内，如[-1, 1]或[0, 100]。\n",
        "\n",
        "**例子**：在迷宫探索任务中，智能体每走一步可能获得的奖励是-1（表示消耗了能量或时间），而当智能体找到出口时，可能获得一个较大的正奖励，如100。这样，智能体的目标就是通过学习找到一条从起点到出口的路径，使得累积奖励最大化。\n",
        "\n",
        "### 4. 最大步数（Maximum Episode Length）\n",
        "\n",
        "最大步数是指一个训练或测试回合中，智能体与环境交互的最大步数限制。这是为了避免智能体陷入无限循环或与环境的交互时间过长。当达到最大步数时，回合会强制结束，无论智能体是否完成了任务。\n",
        "\n",
        "**例子**：在玩超级玛丽兄弟这款游戏时，我们可以设定每个回合的最大步数为一定数量的游戏帧或时间单位。如果智能体在这么多步内未能通关或达到其他目标，回合就会结束，并计算该回合的累积奖励。\n",
        "\n",
        "综上所述，观测空间、动作空间、奖励范围和最大步数是强化学习中定义智能体与环境交互方式的关键要素。它们共同构成了强化学习问题的基本框架，使得智能体能够在复杂且不确定的环境中进行学习和决策。"
      ],
      "metadata": {
        "id": "CcuXC8R1jN8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space_names = ['观测空间', '动作空间', '奖励范围', '最大步数']\n",
        "df = pd.DataFrame(columns=space_names)\n",
        "\n",
        "env_specs = gym.envs.registry.all()\n",
        "for env_spec in env_specs:\n",
        "    env_id = env_spec.id\n",
        "    try:\n",
        "        env = gym.make(env_id)\n",
        "        observation_space = env.observation_space\n",
        "        action_space = env.action_space\n",
        "        reward_range = env.reward_range\n",
        "        max_episode_steps = None\n",
        "        if isinstance(env, gym.wrappers.time_limit.TimeLimit):\n",
        "            max_episode_steps = env._max_episode_steps\n",
        "        df.loc[env_id] = [observation_space, action_space, reward_range, max_episode_steps]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "with pd.option_context('display.max_rows', None):\n",
        "    display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "csb4EhHuhvNd",
        "outputId": "00758ac7-bcf0-41b4-80af-9ad47b4396a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:421: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Reacher-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Pusher-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment InvertedPendulum-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment InvertedDoublePendulum-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment HalfCheetah-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment HalfCheetah-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Hopper-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Hopper-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Swimmer-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Swimmer-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Walker2d-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Walker2d-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Ant-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Ant-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Humanoid-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment Humanoid-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment HumanoidStandup-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                       观测空间  \\\n",
              "CartPole-v0               Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...   \n",
              "CartPole-v1               Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...   \n",
              "MountainCar-v0               Box([-1.2  -0.07], [0.6  0.07], (2,), float32)   \n",
              "MountainCarContinuous-v0     Box([-1.2  -0.07], [0.6  0.07], (2,), float32)   \n",
              "Pendulum-v1                   Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)   \n",
              "Acrobot-v1                Box([ -1.        -1.        -1.        -1.    ...   \n",
              "Blackjack-v1                      (Discrete(32), Discrete(11), Discrete(2))   \n",
              "FrozenLake-v1                                                  Discrete(16)   \n",
              "FrozenLake8x8-v1                                               Discrete(64)   \n",
              "CliffWalking-v0                                                Discrete(48)   \n",
              "Taxi-v3                                                       Discrete(500)   \n",
              "\n",
              "                                                   动作空间         奖励范围  最大步数  \n",
              "CartPole-v0                                 Discrete(2)  (-inf, inf)   200  \n",
              "CartPole-v1                                 Discrete(2)  (-inf, inf)   500  \n",
              "MountainCar-v0                              Discrete(3)  (-inf, inf)   200  \n",
              "MountainCarContinuous-v0  Box(-1.0, 1.0, (1,), float32)  (-inf, inf)   999  \n",
              "Pendulum-v1               Box(-2.0, 2.0, (1,), float32)  (-inf, inf)   200  \n",
              "Acrobot-v1                                  Discrete(3)  (-inf, inf)   500  \n",
              "Blackjack-v1                                Discrete(2)  (-inf, inf)  None  \n",
              "FrozenLake-v1                               Discrete(4)       (0, 1)   100  \n",
              "FrozenLake8x8-v1                            Discrete(4)       (0, 1)   200  \n",
              "CliffWalking-v0                             Discrete(4)  (-inf, inf)  None  \n",
              "Taxi-v3                                     Discrete(6)  (-inf, inf)   200  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1686ae6-3c29-45e7-8563-54945297d0e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>观测空间</th>\n",
              "      <th>动作空间</th>\n",
              "      <th>奖励范围</th>\n",
              "      <th>最大步数</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CartPole-v0</th>\n",
              "      <td>Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...</td>\n",
              "      <td>Discrete(2)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CartPole-v1</th>\n",
              "      <td>Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e...</td>\n",
              "      <td>Discrete(2)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MountainCar-v0</th>\n",
              "      <td>Box([-1.2  -0.07], [0.6  0.07], (2,), float32)</td>\n",
              "      <td>Discrete(3)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MountainCarContinuous-v0</th>\n",
              "      <td>Box([-1.2  -0.07], [0.6  0.07], (2,), float32)</td>\n",
              "      <td>Box(-1.0, 1.0, (1,), float32)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pendulum-v1</th>\n",
              "      <td>Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)</td>\n",
              "      <td>Box(-2.0, 2.0, (1,), float32)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acrobot-v1</th>\n",
              "      <td>Box([ -1.        -1.        -1.        -1.    ...</td>\n",
              "      <td>Discrete(3)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Blackjack-v1</th>\n",
              "      <td>(Discrete(32), Discrete(11), Discrete(2))</td>\n",
              "      <td>Discrete(2)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FrozenLake-v1</th>\n",
              "      <td>Discrete(16)</td>\n",
              "      <td>Discrete(4)</td>\n",
              "      <td>(0, 1)</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FrozenLake8x8-v1</th>\n",
              "      <td>Discrete(64)</td>\n",
              "      <td>Discrete(4)</td>\n",
              "      <td>(0, 1)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CliffWalking-v0</th>\n",
              "      <td>Discrete(48)</td>\n",
              "      <td>Discrete(4)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Taxi-v3</th>\n",
              "      <td>Discrete(500)</td>\n",
              "      <td>Discrete(6)</td>\n",
              "      <td>(-inf, inf)</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1686ae6-3c29-45e7-8563-54945297d0e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1686ae6-3c29-45e7-8563-54945297d0e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1686ae6-3c29-45e7-8563-54945297d0e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1aa8dec2-5211-4974-96f0-819a43477ca5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aa8dec2-5211-4974-96f0-819a43477ca5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1aa8dec2-5211-4974-96f0-819a43477ca5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: -inf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 小车上山 MountainCar-v0\n",
        "环境：Gym库的 MountainCar-v0"
      ],
      "metadata": {
        "id": "wgRLGxCMkOWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在下面代码中，使用`gym`库来创建一个名为`MountainCar-v0`的环境实例，并打印出该环境的观测空间、动作空间以及观测范围和动作数的相关信息。下面是代码的解释和输出示例：\n",
        "\n",
        "1. **创建环境实例**：\n",
        "   ```python\n",
        "   env = gym.make('MountainCar-v0')\n",
        "   ```\n",
        "   这行代码使用`gym.make`函数创建了一个`MountainCar-v0`环境的实例，并将其赋值给变量`env`。\n",
        "\n",
        "2. **打印观测空间**：\n",
        "   ```python\n",
        "   print('观测空间 = {}'.format(env.observation_space))\n",
        "   ```\n",
        "   这行代码打印出环境的观测空间。对于`MountainCar-v0`环境，观测空间通常是一个包含位置和速度的二维向量，因此输出可能类似于`Box(2,)`，表示这是一个二维的连续空间。\n",
        "\n",
        "3. **打印动作空间**：\n",
        "   ```python\n",
        "   print('动作空间 = {}'.format(env.action_space))\n",
        "   ```\n",
        "   这行代码打印出环境的动作空间。对于`MountainCar-v0`环境，动作空间通常是离散的，包含有限个动作（通常是向左或向右推动小车），因此输出可能类似于`Discrete(3)`，表示有三个不同的动作可以选择。\n",
        "\n",
        "4. **打印观测范围**：\n",
        "   ```python\n",
        "   print('观测范围 = {} ~ {}'.format(env.observation_space.low, env.observation_space.high))\n",
        "   ```\n",
        "   这两行代码打印出观测空间的范围，即观测值的最小值和最大值。对于`MountainCar-v0`环境，输出可能类似于`观测范围 = [-1.2  -0.07] ~ [0.6  0.07]`，表示位置和速度的最小值和最大值。\n",
        "\n",
        "5. **打印动作数**：\n",
        "   ```python\n",
        "   print('动作数 = {}'.format(env.action_space.n))\n",
        "   ```\n",
        "   这行代码打印出动作空间中的动作数量。对于`MountainCar-v0`环境，如果动作空间是离散的，输出将是一个整数，表示可以选择的动作数量。例如，如果输出是`动作数 = 3`，则表示有三个不同的动作。\n",
        "\n",
        "综上所述，当您运行这段代码时，输出可能类似于以下内容：\n",
        "\n",
        "```\n",
        "观测空间 = Box(2,)\n",
        "动作空间 = Discrete(3)\n",
        "观测范围 = [-1.2  -0.07] ~ [0.6  0.07]\n",
        "动作数 = 3\n",
        "```\n",
        "\n",
        "请注意，实际的输出值可能会因`gym`版本或环境的具体实现而有所不同。如果您得到的输出与上述示例不完全一致，请参考您正在使用的`gym`版本的文档以获取更准确的信息。"
      ],
      "metadata": {
        "id": "3IkthcselmId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "print('观测空间 = {}'.format(env.observation_space))\n",
        "print('动作空间 = {}'.format(env.action_space))\n",
        "print('观测范围 = {} ~ {}'.format(env.observation_space.low,\n",
        "        env.observation_space.high))\n",
        "print('动作数 = {}'.format(env.action_space.n))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur2eoTmWkRCZ",
        "outputId": "48628ce1-cfc3-4ac3-e2b3-c0a2ab574553"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "观测空间 = Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
            "动作空间 = Discrete(3)\n",
            "观测范围 = [-1.2  -0.07] ~ [0.6  0.07]\n",
            "动作数 = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码定义了一个名为 `BespokeAgent` 的类，该类似乎被设计用于在某个环境（通过 `env` 参数指定）中做出决策。以下是对代码的详细解释：\n",
        "\n",
        "### 类定义：`BespokeAgent`\n",
        "\n",
        "1. **初始化方法：`__init__`**\n",
        "    ```python\n",
        "    def __init__(self, env):\n",
        "        pass\n",
        "    ```\n",
        "    - 这个方法是类的构造函数，用于初始化对象的状态。在这里，它接收一个参数 `env`，但并未对其进行任何操作（使用了 `pass` 语句）。可能的设计意图是在未来扩展初始化过程，目前只是一个占位符。\n",
        "\n",
        "2. **决策方法：`decide`**\n",
        "    ```python\n",
        "    def decide(self, observation):\n",
        "        position, velocity = observation\n",
        "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
        "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
        "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
        "        if lb < velocity < ub:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 0\n",
        "        return action\n",
        "    ```\n",
        "    - 这个方法用于根据当前的 `observation`（观测值）来做出决策。\n",
        "    - `observation` 被解构为两个变量：`position`（位置）和 `velocity`（速度）。\n",
        "    - 计算两个界限值 `lb`（下界）和 `ub`（上界）。这些界限值是基于位置的复杂数学表达式计算得出的。\n",
        "    - 如果速度 `velocity` 位于 `lb` 和 `ub` 之间，则采取动作 `2`；否则，采取动作 `0`。\n",
        "    - 最终返回所选择的动作。\n",
        "\n",
        "3. **学习方法：`learn`**\n",
        "    ```python\n",
        "    def learn(self, *args):\n",
        "        pass\n",
        "    ```\n",
        "    - 这个方法设计为用于学习，但目前未实现任何功能（使用了 `pass` 语句）。它接收任意数量的参数（通过 `*args`），可能用于未来添加学习相关的逻辑。\n",
        "\n",
        "### 创建 `BespokeAgent` 实例\n",
        "\n",
        "```python\n",
        "agent = BespokeAgent(env)\n",
        "```\n",
        "- 这行代码创建了一个 `BespokeAgent` 类的实例，并将其赋值给变量 `agent`。\n",
        "- `env` 是传递给构造函数的参数，代表智能体所处的环境。尽管在 `__init__` 方法中未对 `env` 进行任何操作，但通常这样的设计意味着未来可能会在这个环境中使用或存储相关信息。\n",
        "\n",
        "### 总结\n",
        "\n",
        "这个 `BespokeAgent` 类目前主要实现了一个基于位置和速度观测值进行决策的简单逻辑。学习功能尚未实现，可能是为将来的扩展预留的。代码中的数学表达式和逻辑可能特定于某个应用场景（如物理模拟、控制系统等），需要根据具体背景进一步理解。"
      ],
      "metadata": {
        "id": "dKzktz-ekmXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BespokeAgent:\n",
        "    def __init__(self, env):\n",
        "        pass\n",
        "\n",
        "    def decide(self, observation): # 决策\n",
        "        position, velocity = observation\n",
        "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
        "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
        "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
        "        if lb < velocity < ub:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 0\n",
        "        return action # 返回动作\n",
        "\n",
        "    def learn(self, *args): # 学习\n",
        "        pass\n",
        "\n",
        "agent = BespokeAgent(env)"
      ],
      "metadata": {
        "id": "ZPE1KpJSkizM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "智能体与环境交互"
      ],
      "metadata": {
        "id": "4n4aiuT2k3Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码定义了一个名为 `play_montecarlo` 的函数，用于在一个给定的环境（`env`）中使用一个智能体（`agent`）进行一轮（或称为一个“回合”）的模拟或训练。这个函数主要用于蒙特卡洛树搜索（Monte Carlo Tree Search, MCTS）或类似的强化学习任务的执行。以下是代码的详细解释：\n",
        "\n",
        "### 函数定义\n",
        "\n",
        "```python\n",
        "def play_montecarlo(env, agent, render=False, train=False):\n",
        "```\n",
        "\n",
        "- `env`：一个环境对象，通常具有 `reset`、`step` 和 `render` 等方法，用于模拟智能体与环境之间的交互。\n",
        "- `agent`：一个智能体对象，具有 `decide`（决策）和可能还有 `learn`（学习）方法。\n",
        "- `render`：一个布尔值，指定是否显示环境的图形界面。默认为 `False`。\n",
        "- `train`：一个布尔值，指定是否在这一轮中训练智能体。默认为 `False`。\n",
        "\n",
        "### 初始化\n",
        "\n",
        "```python\n",
        "episode_reward = 0. # 记录回合总奖励，初始化为0\n",
        "observation = env.reset() # 重置游戏环境，开始新回合\n",
        "```\n",
        "\n",
        "- `episode_reward`：初始化为 0，用于记录当前回合的总奖励。\n",
        "- `observation`：通过调用 `env.reset()` 重置环境，并获得初始的观测值。\n",
        "\n",
        "### 主循环\n",
        "\n",
        "```python\n",
        "while True: # 不断循环，直到回合结束\n",
        "```\n",
        "\n",
        "- 进入一个无限循环，直到回合结束（`done` 为 `True`）。\n",
        "\n",
        "### 显示环境\n",
        "\n",
        "```python\n",
        "if render: # 判断是否显示\n",
        "    env.render() # 显示图形界面，图形界面可以用 env.close() 语句关闭\n",
        "```\n",
        "\n",
        "- 如果 `render` 为 `True`，则调用 `env.render()` 显示环境的图形界面。\n",
        "\n",
        "### 决策与执行动作\n",
        "\n",
        "```python\n",
        "action = agent.decide(observation)\n",
        "next_observation, reward, done, _ = env.step(action) # 执行动作\n",
        "episode_reward += reward # 收集回合奖励\n",
        "```\n",
        "\n",
        "- `action`：智能体根据当前观测值 `observation` 做出决策。\n",
        "- `env.step(action)`：执行动作，并获得下一个观测值 `next_observation`、奖励 `reward`、是否结束回合的标志 `done` 以及其他可能的信息（这里用 `_` 忽略）。\n",
        "- `episode_reward += reward`：将当前奖励累加到回合总奖励中。\n",
        "\n",
        "### 训练智能体\n",
        "\n",
        "```python\n",
        "if train: # 判断是否训练智能体\n",
        "    agent.learn(observation, action, reward, done) # 学习\n",
        "```\n",
        "\n",
        "- 如果 `train` 为 `True`，则调用智能体的 `learn` 方法进行训练，传入当前的观测值、动作、奖励以及是否结束回合的标志。\n",
        "\n",
        "### 检查回合是否结束\n",
        "\n",
        "```python\n",
        "if done: # 回合结束，跳出循环\n",
        "    break\n",
        "```\n",
        "\n",
        "- 如果 `done` 为 `True`，表示回合结束，跳出循环。\n",
        "\n",
        "### 更新观测值\n",
        "\n",
        "```python\n",
        "observation = next_observation\n",
        "```\n",
        "\n",
        "- 将下一个观测值 `next_observation` 赋值给 `observation`，以便在下一次循环中使用。\n",
        "\n",
        "### 返回回合总奖励\n",
        "\n",
        "```python\n",
        "return episode_reward # 返回回合总奖励\n",
        "```\n",
        "\n",
        "- 返回当前回合的总奖励 `episode_reward`。\n",
        "\n",
        "### 总结\n",
        "\n",
        "这个函数实现了一个标准的强化学习回合流程，包括环境重置、观测值获取、决策、动作执行、奖励累加、训练（如果启用）以及回合结束检查。通过设置 `render` 和 `train` 参数，可以控制是否显示图形界面和是否进行训练。"
      ],
      "metadata": {
        "id": "El27UCDtm1gU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在Colab环境中，直接显示图形界面通常是不支持的，因为Colab运行在云端，而你无法直接查看或交互云端的图形界面。不过，你可以通过一些方法间接地查看图形输出，比如使用视频流或将图像保存为文件然后查看。\n",
        "\n",
        "对于强化学习环境，一个常见的做法是将环境的渲染输出转换为图像，并在Colab中显示这些图像。这通常涉及到修改环境代码或使用特定的库来捕获渲染输出。\n",
        "\n"
      ],
      "metadata": {
        "id": "cAcjBdQXnjcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def play_montecarlo(env, agent, render=False, train=False):\n",
        "    episode_reward = 0. # 记录回合总奖励，初始化为0\n",
        "    observation = env.reset() # 重置游戏环境，开始新回合\n",
        "    while True: # 不断循环，直到回合结束\n",
        "        if render: # 判断是否显示\n",
        "            env.render() # 显示图形界面，图形界面可以用 env.close() 语句关闭\n",
        "        action = agent.decide(observation)\n",
        "        next_observation, reward, done, _ = env.step(action) # 执行动作\n",
        "        episode_reward += reward # 收集回合奖励\n",
        "        if train: # 判断是否训练智能体\n",
        "            agent.learn(observation, action, reward, done) # 学习\n",
        "        if done: # 回合结束，跳出循环\n",
        "            break\n",
        "        observation = next_observation\n",
        "    return episode_reward # 返回回合总奖励"
      ],
      "metadata": {
        "id": "MkuTYJuJk32Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "\n",
        "def play_montecarlo(env, agent, render=False, train=False):\n",
        "    episode_reward = 0.  # 记录回合总奖励，初始化为0\n",
        "    observation = env.reset()  # 重置游戏环境，开始新回合\n",
        "\n",
        "    images = []  # 用于存储渲染图像的列表\n",
        "\n",
        "    while True:  # 不断循环，直到回合结束\n",
        "        if render:\n",
        "            # 捕获渲染输出为图像数组\n",
        "            img = env.render(mode='rgb_array')\n",
        "            images.append(img)  # 将图像添加到列表中\n",
        "\n",
        "        action = agent.decide(observation)\n",
        "        next_observation, reward, done, _ = env.step(action)  # 执行动作\n",
        "        episode_reward += reward  # 收集回合奖励\n",
        "\n",
        "        if train:  # 判断是否训练智能体\n",
        "            agent.learn(observation, action, reward, done)  # 学习\n",
        "\n",
        "        if done:  # 回合结束，跳出循环\n",
        "            break\n",
        "\n",
        "        observation = next_observation\n",
        "\n",
        "    if render:\n",
        "        # 在Colab中逐个显示图像\n",
        "        for img in images:\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            display(plt.gcf())  # 显示当前图像\n",
        "            time.sleep(0.1)  # 控制显示速度\n",
        "            clear_output(wait=True)  # 清除之前的输出\n",
        "            plt.close()  # 关闭图像窗口，避免内存泄漏\n",
        "\n",
        "    return episode_reward  # 返回回合总奖励\n",
        "\n",
        "# 注意：确保你的环境支持'rgb_array'模式，并且已经安装了必要的库（如matplotlib）"
      ],
      "metadata": {
        "id": "fAIGpM7JnC4Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "交互1回合，并图形化显示"
      ],
      "metadata": {
        "id": "gC2mqJf_lMmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.seed(0) # 设置随机数种子，只是为了让结果可以精确复现，一般情况下可删去\n",
        "episode_reward = play_montecarlo(env, agent, render=True)\n",
        "print('回合奖励 = {}'.format(episode_reward))\n",
        "env.close() # 此语句可关闭图形界面"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7GKJb3Y6k7Rg",
        "outputId": "572a5795-5331-47ec-d472-e60ba6acd488"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "回合奖励 = -123.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "评估性能：交互10回合求平均\n",
        "\n"
      ],
      "metadata": {
        "id": "xm7ZHaSEoeNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episode_rewards = [play_montecarlo(env, agent, render=True) for _ in range(10)]\n",
        "print('平均回合奖励 = {}'.format(np.mean(episode_rewards)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jNG4gm1QoEt2",
        "outputId": "d4f6e603-71ff-415e-d924-dc4d7c7f9aa7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "平均回合奖励 = -107.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在Colab（Google Colaboratory）环境中，直接显示图形界面通常是不支持的，因为Colab运行在云端，而你无法直接查看或交互云端的图形界面。不过，你可以通过一些方法间接地查看图形输出，比如使用视频流或将图像保存为文件然后查看。\n",
        "\n",
        "对于强化学习环境，一个常见的做法是将环境的渲染输出转换为图像，并在Colab中显示这些图像。这通常涉及到修改环境代码或使用特定的库来捕获渲染输出。\n",
        "\n",
        "如果你的环境支持将渲染输出为图像（例如，使用`gym`的`render`方法中的`mode='rgb_array'`），你可以修改`play_montecarlo`函数来捕获这些图像，并使用Colab支持的显示方法显示它们。\n",
        "\n",
        "下面是一个修改后的示例，它假设你的环境支持以图像数组的形式返回渲染输出：\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "\n",
        "def play_montecarlo(env, agent, render=False, train=False):\n",
        "    episode_reward = 0.  # 记录回合总奖励，初始化为0\n",
        "    observation = env.reset()  # 重置游戏环境，开始新回合\n",
        "    \n",
        "    images = []  # 用于存储渲染图像的列表\n",
        "\n",
        "    while True:  # 不断循环，直到回合结束\n",
        "        if render:\n",
        "            # 捕获渲染输出为图像数组\n",
        "            img = env.render(mode='rgb_array')\n",
        "            images.append(img)  # 将图像添加到列表中\n",
        "\n",
        "        action = agent.decide(observation)\n",
        "        next_observation, reward, done, _ = env.step(action)  # 执行动作\n",
        "        episode_reward += reward  # 收集回合奖励\n",
        "\n",
        "        if train:  # 判断是否训练智能体\n",
        "            agent.learn(observation, action, reward, done)  # 学习\n",
        "\n",
        "        if done:  # 回合结束，跳出循环\n",
        "            break\n",
        "\n",
        "        observation = next_observation\n",
        "\n",
        "    if render:\n",
        "        # 在Colab中显示图像\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i, img in enumerate(images):\n",
        "            plt.subplot(1, len(images), i + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "        plt.show()\n",
        "        # 或者使用IPython的display函数逐个显示图像\n",
        "        # for img in images:\n",
        "        #     display(plt.imshow(img))\n",
        "        #     display(plt.axis('off'))\n",
        "        #     time.sleep(0.1)  # 控制显示速度\n",
        "        #     clear_output(wait=True)  # 清除之前的输出（可选）\n",
        "\n",
        "    return episode_reward  # 返回回合总奖励\n",
        "\n",
        "# 注意：确保你的环境支持'rgb_array'模式，并且已经安装了必要的库（如matplotlib）\n",
        "```\n",
        "\n",
        "在这个修改后的函数中，如果`render`为`True`，则环境会以图像数组的形式返回渲染输出，并将这些图像存储在`images`列表中。回合结束后，使用`matplotlib`在Colab中显示这些图像。\n",
        "\n",
        "然而，请注意这种方法的一个限制是：它只能在回合结束后显示图像，而不能实时显示。如果你需要实时查看渲染输出，你可能需要考虑使用其他方法，比如将图像流传输到本地机器或使用支持实时渲染的远程桌面解决方案。\n",
        "\n",
        "另外，如果你的环境不支持以图像数组的形式返回渲染输出，你可能需要查找特定于该环境的解决方案或修改环境代码以支持此功能。"
      ],
      "metadata": {
        "id": "1KnQrVP2sMwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "由于每个图像的尺寸很大，使用`subplot`方式在一个图中展示导致图像看不清，我们可以修改代码以逐个显示图像，或者使用更大的图形窗口来显示图像。以下是两种修改方案：\n",
        "\n",
        "### 方案一：逐个显示图像\n",
        "\n",
        "我们可以使用`IPython.display`的`display`和`clear_output`函数来逐个显示图像，并控制显示速度。这样，用户可以清晰地看到每一帧图像。\n",
        "\n",
        "```python\n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt  \n",
        "from IPython.display import display, clear_output  \n",
        "import time  \n",
        "  \n",
        "def play_montecarlo(env, agent, render=False, train=False):  \n",
        "    episode_reward = 0.  # 记录回合总奖励，初始化为0  \n",
        "    observation = env.reset()  # 重置游戏环境，开始新回合  \n",
        "      \n",
        "    images = []  # 用于存储渲染图像的列表  \n",
        "  \n",
        "    while True:  # 不断循环，直到回合结束  \n",
        "        if render:  \n",
        "            # 捕获渲染输出为图像数组  \n",
        "            img = env.render(mode='rgb_array')  \n",
        "            images.append(img)  # 将图像添加到列表中  \n",
        "  \n",
        "        action = agent.decide(observation)  \n",
        "        next_observation, reward, done, _ = env.step(action)  # 执行动作  \n",
        "        episode_reward += reward  # 收集回合奖励  \n",
        "  \n",
        "        if train:  # 判断是否训练智能体  \n",
        "            agent.learn(observation, action, reward, done)  # 学习  \n",
        "  \n",
        "        if done:  # 回合结束，跳出循环  \n",
        "            break  \n",
        "  \n",
        "        observation = next_observation  \n",
        "  \n",
        "    if render:  \n",
        "        # 在Colab中逐个显示图像  \n",
        "        for img in images:  \n",
        "            plt.imshow(img)  \n",
        "            plt.axis('off')  \n",
        "            display(plt.gcf())  # 显示当前图像  \n",
        "            time.sleep(0.1)  # 控制显示速度  \n",
        "            clear_output(wait=True)  # 清除之前的输出  \n",
        "            plt.close()  # 关闭图像窗口，避免内存泄漏  \n",
        "  \n",
        "    return episode_reward  # 返回回合总奖励  \n",
        "\n",
        "# 注意：确保你的环境支持'rgb_array'模式，并且已经安装了必要的库（如matplotlib）\n",
        "```\n",
        "\n",
        "### 方案二：使用更大的图形窗口显示图像\n",
        "\n",
        "如果我们想要在一个窗口中显示所有图像，但希望图像更大更清晰，我们可以增加`subplot`的行数或列数，并调整图形窗口的大小。然而，由于图像很大，这可能会导致图形窗口变得非常大，不便于查看。因此，这种方法可能不是最佳选择。\n",
        "\n",
        "更好的方法是使用一个可以滚动的窗口来显示图像，但`matplotlib`本身并不直接支持这种功能。我们可以使用`IPython.display`的`HTML`和`Javascript`输出来实现一个简单的滚动效果，但这通常比较复杂。\n",
        "\n",
        "### 推荐的解决方案\n",
        "\n",
        "对于大多数情况，逐个显示图像是更简单且更有效的方法。它允许用户清晰地查看每一帧，并且可以通过调整显示速度来控制查看的节奏。\n",
        "\n",
        "如果你确实需要在一个窗口中显示所有图像，并且图像数量不是很多，你可以考虑使用`GridSpec`来创建一个更灵活的网格布局，并调整图像的大小以适应子图。但是，请注意，这可能会导致图像失真或变得不清晰，特别是当图像被缩小到很小的尺寸时。\n",
        "\n",
        "最终，选择哪种方法取决于你的具体需求和图像的尺寸。如果图像非常大且数量多，逐个显示通常是更好的选择。"
      ],
      "metadata": {
        "id": "dJvHDs0gsROW"
      }
    }
  ]
}