{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJKZ7mmhiwsNdstPulbsv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannasmile/colab_code_note/blob/main/BI0005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABCMeta\n",
        "from abc import abstractmethod\n",
        "from typing import Union\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from scipy import stats\n",
        "from statsmodels.stats.power import NormalIndPower\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "\n",
        "class BaseMetric:\n",
        "    __metaclass__ = ABCMeta\n",
        "    mde: float\n",
        "\n",
        "    def __init__(self, mde: float, alternative: str):\n",
        "        self.mde = mde\n",
        "        self.alternative = alternative\n",
        "\n",
        "    @property\n",
        "    @abstractmethod\n",
        "    def power_analysis_instance(self) -> Union[NormalIndPower, TTestIndPower]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    @abstractmethod\n",
        "    def variance(self) -> float:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @staticmethod\n",
        "    def check_positive(number: float, name: str) -> float:\n",
        "        if number < 0:\n",
        "            raise ValueError(f\"Error: Please provide a positive number for {name}.\")\n",
        "        else:\n",
        "            return number\n",
        "\n",
        "    def generate_p_values(\n",
        "        self, true_alt: npt.NDArray[np.bool_], sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        \"\"\"\n",
        "        This method simulates any registered metric's p-value. The output will\n",
        "        later be applied to BH procedure\n",
        "\n",
        "        Parameters:\n",
        "            true_alt: A boolean array of shape (m hypotheses x replications).\n",
        "            Each element represents whether the alternative hypothesis is true\n",
        "            for an individual hypothesis sample_size: sample size used for simulations\n",
        "            sample_size: an integer used to generate\n",
        "            random_state: random state to generate fixed output for any given input\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            p-value: A float array of shape (m hypotheses x replications) of\n",
        "            simulated p-values\n",
        "        \"\"\"\n",
        "        total_alt = true_alt.sum()\n",
        "        total_null = true_alt.size - total_alt\n",
        "\n",
        "        p_values = np.empty(true_alt.shape)\n",
        "        p_values[true_alt] = self._generate_alt_p_values(total_alt, sample_size, random_state)\n",
        "        p_values[~true_alt] = stats.uniform.rvs(0, 1, total_null, random_state=random_state)\n",
        "\n",
        "        return p_values\n",
        "\n",
        "    @abstractmethod\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class BooleanMetric(BaseMetric):\n",
        "    probability: float\n",
        "    mde: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        probability: float,\n",
        "        mde: float,\n",
        "        alternative: str,\n",
        "    ):\n",
        "        super(BooleanMetric, self).__init__(mde, alternative)\n",
        "        self.probability = self._check_probability(probability)\n",
        "\n",
        "    @property\n",
        "    def variance(self) -> float:\n",
        "        return self.probability * (1 - self.probability)\n",
        "\n",
        "    @property\n",
        "    def power_analysis_instance(self) -> NormalIndPower:\n",
        "        return NormalIndPower()\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_probability(probability: float) -> float:\n",
        "        if 0 <= probability <= 1:\n",
        "            return probability\n",
        "        else:\n",
        "            raise ValueError(\"Error: Please provide a float between 0 and 1 for probability.\")\n",
        "\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        effect_size = self.mde / np.sqrt(2 * self.variance / sample_size)\n",
        "        z_alt = stats.norm.rvs(loc=effect_size, size=size, random_state=random_state)\n",
        "        p_values: npt.NDArray[np.float_] = stats.norm.sf(np.abs(z_alt))\n",
        "        if self.alternative == \"two-sided\":\n",
        "            p_values *= 2\n",
        "        return p_values\n",
        "\n",
        "\n",
        "class NumericMetric(BaseMetric):\n",
        "    mde: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        variance: float,\n",
        "        mde: float,\n",
        "        alternative: str,\n",
        "    ):\n",
        "        super(NumericMetric, self).__init__(mde, alternative)\n",
        "        self._variance = self.check_positive(variance, \"variance\")\n",
        "\n",
        "    @property\n",
        "    def variance(self) -> float:\n",
        "        return self._variance\n",
        "\n",
        "    @property\n",
        "    def power_analysis_instance(self) -> TTestIndPower:\n",
        "        return TTestIndPower()\n",
        "\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        nc = np.sqrt(sample_size / 2 / self.variance) * self.mde\n",
        "        t_alt = stats.nct.rvs(nc=nc, df=2 * (sample_size - 1), size=size, random_state=random_state)\n",
        "        p_values: npt.NDArray[np.float_] = stats.t.sf(np.abs(t_alt), 2 * (sample_size - 1))\n",
        "        # Todo: use accurate p-value calculation due to nct's asymmetric distribution\n",
        "        if self.alternative == \"two-sided\":\n",
        "            p_values *= 2\n",
        "        return p_values\n",
        "\n",
        "\n",
        "class RatioMetric(BaseMetric):\n",
        "    numerator_mean: float\n",
        "    numerator_variance: float\n",
        "    denominator_mean: float\n",
        "    denominator_variance: float\n",
        "    covariance: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        numerator_mean: float,\n",
        "        numerator_variance: float,\n",
        "        denominator_mean: float,\n",
        "        denominator_variance: float,\n",
        "        covariance: float,\n",
        "        mde: float,\n",
        "        alternative: str,\n",
        "    ):\n",
        "        super(RatioMetric, self).__init__(mde, alternative)\n",
        "        # TODO: add check for Cauchy-Schwarz inequality\n",
        "        self.numerator_mean = numerator_mean\n",
        "        self.numerator_variance = self.check_positive(numerator_variance, \"numerator variance\")\n",
        "        self.denominator_mean = denominator_mean\n",
        "        self.denominator_variance = self.check_positive(denominator_variance, \"denominator variance\")\n",
        "        self.covariance = covariance\n",
        "\n",
        "    @property\n",
        "    def variance(self) -> float:\n",
        "        variance = (\n",
        "            self.numerator_variance / self.denominator_mean**2\n",
        "            + self.denominator_variance * self.numerator_mean**2 / self.denominator_mean**4\n",
        "            - 2 * self.covariance * self.numerator_mean / self.denominator_mean**3\n",
        "        )\n",
        "\n",
        "        return variance\n",
        "\n",
        "    @property\n",
        "    def power_analysis_instance(self) -> NormalIndPower:\n",
        "        return NormalIndPower()\n",
        "\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        effect_size = self.mde / np.sqrt(2 * self.variance / sample_size)\n",
        "        z_alt = stats.norm.rvs(loc=effect_size, size=size, random_state=random_state)\n",
        "        p_values: npt.NDArray[np.float_] = stats.norm.sf(np.abs(z_alt))\n",
        "        if self.alternative == \"two-sided\":\n",
        "            p_values *= 2\n",
        "        return p_values"
      ],
      "metadata": {
        "id": "8OADOmdPLbP9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "#from sample_size.metrics import BaseMetric\n",
        "\n",
        "DEFAULT_REPLICATION: int = 400\n",
        "DEFAULT_EPSILON: float = 0.01\n",
        "DEFAULT_MAX_RECURSION: int = 20\n",
        "\n",
        "\n",
        "class MultipleTestingMixin:\n",
        "    \"\"\"\n",
        "    This class calculates sample size required under the case of multiple testing\n",
        "\n",
        "    Attributes:\n",
        "    metrics: a list of BaseMetric registered by users\n",
        "    variants: number of variants, including control\n",
        "    alpha: statistical significance\n",
        "    power: average power, calculated as #correct rejections/#true alternative hypotheses\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    metrics: List[BaseMetric]\n",
        "    alpha: float\n",
        "    power: float\n",
        "    variants: int\n",
        "\n",
        "    def get_multiple_sample_size(\n",
        "        self,\n",
        "        lower: float,\n",
        "        upper: float,\n",
        "        random_state: np.random.RandomState,\n",
        "        depth: int = 0,\n",
        "        replication: int = DEFAULT_REPLICATION,\n",
        "        epsilon: float = DEFAULT_EPSILON,\n",
        "        max_recursion_depth: int = DEFAULT_MAX_RECURSION,\n",
        "    ) -> int:\n",
        "        \"\"\"\n",
        "        This method finds minimum required sample size per cohort that generates\n",
        "        average power higher than required\n",
        "\n",
        "        Attributes:\n",
        "            lower: lower bound of sample size search\n",
        "            upper: upper bound of sample size search\n",
        "            depth: number of recursions\n",
        "            replication: number of Monte Carlo simulations to calculate empirical power\n",
        "            epsilon: absolute difference between our estimate for power and desired power\n",
        "                needed before we will return\n",
        "            max_recursion_depth: how many recursive calls can be made before the\n",
        "                search is abandoned\n",
        "\n",
        "        Returns\n",
        "            minimum required sample size per cohort\n",
        "        \"\"\"\n",
        "\n",
        "        if depth > max_recursion_depth:\n",
        "            raise RecursionError(f\"Couldn't find a sample size that satisfies the power you requested: {self.power}\")\n",
        "\n",
        "        candidate = int(np.sqrt(lower * upper))\n",
        "        expected_power = self._expected_average_power(candidate, random_state, replication)\n",
        "        if np.isclose(self.power, expected_power, atol=epsilon):\n",
        "            return candidate\n",
        "        elif lower == upper:\n",
        "            raise RecursionError(f\"Couldn't find a sample size that satisfies the power you requested: {self.power}\")\n",
        "\n",
        "        if expected_power > self.power:\n",
        "            return self.get_multiple_sample_size(lower, candidate, random_state, depth + 1)\n",
        "        else:\n",
        "            return self.get_multiple_sample_size(candidate, upper, random_state, depth + 1)\n",
        "\n",
        "    def _expected_average_power(\n",
        "        self, sample_size: int, random_state: np.random.RandomState, replication: int = DEFAULT_REPLICATION\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        This method calculates expected average power of multiple testings. For each possible number of true null\n",
        "        hypothesis, we simulate each metric/treatment variant's test statistics and calculate their p-values,\n",
        "        then calculate expected average power = number of True rejection/ true alternative hypotheses\n",
        "\n",
        "        Attributes:\n",
        "        sample size: determines the variance/ degrees of freedom of the distribution we sample test statistics from\n",
        "        replication: number of times we repeat the simulation process\n",
        "\n",
        "        Returns value expected average power\n",
        "        \"\"\"\n",
        "        true_alt_count = 0.0\n",
        "        true_discovery_count = 0.0\n",
        "\n",
        "        # a metric for each test we would conduct\n",
        "        metrics = self.metrics * (self.variants - 1)\n",
        "\n",
        "        def fdr_bh(a: npt.NDArray[np.float_]) -> npt.NDArray[np.bool_]:\n",
        "            rejected: npt.NDArray[np.bool_] = multipletests(a, alpha=self.alpha, method=\"fdr_bh\")[0]\n",
        "            return rejected\n",
        "\n",
        "        for num_true_alt in range(1, len(metrics) + 1):\n",
        "            true_alt = np.array([random_state.permutation(len(metrics)) < num_true_alt for _ in range(replication)]).T\n",
        "            p_values = []\n",
        "            for i, m in enumerate(metrics):\n",
        "                p_values.append(m.generate_p_values(true_alt[i], sample_size, random_state))\n",
        "\n",
        "            rejected = np.apply_along_axis(fdr_bh, 0, np.array(p_values))  # type: ignore[no-untyped-call]\n",
        "\n",
        "            true_discoveries = rejected & true_alt\n",
        "\n",
        "            true_discovery_count += true_discoveries.sum()\n",
        "            true_alt_count += true_alt.sum()\n",
        "\n",
        "        avg_power = true_discovery_count / true_alt_count\n",
        "\n",
        "        return avg_power"
      ],
      "metadata": {
        "id": "kcOgr70XMPQH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_schema_json_file = open('metrics_schema.json', 'w')\n",
        "\n",
        "metrics_schema_json = '''\n",
        "{\n",
        "    \"type\": \"array\",\n",
        "    \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"metric_type\": {\n",
        "                \"type\": \"string\",\n",
        "                \"enum\": [\"boolean\", \"numeric\", \"ratio\"]\n",
        "            }\n",
        "        },\n",
        "        \"allOf\": [\n",
        "            {\n",
        "                \"if\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_type\": {\"const\": \"boolean\"}\n",
        "                    }\n",
        "                },\n",
        "                \"then\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_metadata\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"alternative\": {\"type\": \"string\"},\n",
        "                                \"mde\": {\"type\": \"number\"},\n",
        "                                \"probability\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\"mde\", \"probability\"]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"if\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_type\": {\"const\": \"numeric\"}\n",
        "                    }\n",
        "                },\n",
        "                \"then\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_metadata\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"alternative\": {\"type\": \"string\"},\n",
        "                                \"mde\": {\"type\": \"number\"},\n",
        "                                \"variance\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\"mde\", \"variance\"]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"if\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_type\": {\"const\": \"ratio\"}\n",
        "                    }\n",
        "                },\n",
        "                \"then\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_metadata\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"alternative\": {\"type\": \"string\"},\n",
        "                                \"mde\": {\"type\": \"number\"},\n",
        "                                \"numerator_mean\": {\"type\": \"number\"},\n",
        "                                \"numerator_variance\": {\"type\": \"number\"},\n",
        "                                \"denominator_mean\": {\"type\": \"number\"},\n",
        "                                \"denominator_variance\": {\"type\": \"number\"},\n",
        "                                \"covariance\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\n",
        "                                \"mde\",\n",
        "                                \"numerator_mean\",\n",
        "                                \"numerator_variance\",\n",
        "                                \"denominator_mean\",\n",
        "                                \"denominator_variance\",\n",
        "                                \"covariance\"\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"required\": [\"metric_type\", \"metric_metadata\"]\n",
        "    },\n",
        "    \"minItems\": 1\n",
        "}\n",
        "'''\n",
        "\n",
        "metrics_schema_json_file.write(metrics_schema_json)\n",
        "\n",
        "metrics_schema_json_file.close()"
      ],
      "metadata": {
        "id": "e3fdQXT4MUE-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from jsonschema import validate\n",
        "\n",
        "#from sample_size.metrics import BaseMetric\n",
        "#from sample_size.metrics import BooleanMetric\n",
        "#from sample_size.metrics import NumericMetric\n",
        "#from sample_size.metrics import RatioMetric\n",
        "#from sample_size.multiple_testing import MultipleTestingMixin\n",
        "\n",
        "DEFAULT_ALPHA = 0.05\n",
        "DEFAULT_POWER = 0.8\n",
        "DEFAULT_VARIANTS = 2\n",
        "RANDOM_STATE = np.random.RandomState(1)\n",
        "STATE = RANDOM_STATE.get_state()\n",
        "\n",
        "schema_file_path = Path(\"metrics_schema.json\")\n",
        "#schema_file_path = Path(Path(__file__).parent, \"metrics_schema.json\")\n",
        "with open(str(schema_file_path), \"r\") as schema_file:\n",
        "    METRICS_SCHEMA = json.load(schema_file)\n",
        "\n",
        "\n",
        "class SampleSizeCalculator(MultipleTestingMixin):\n",
        "    \"\"\"\n",
        "    This class is to calculate sample size based on metric type\n",
        "\n",
        "    Attributes:\n",
        "    alpha: statistical significance\n",
        "    power: statistical power\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha: float = DEFAULT_ALPHA, variants: int = DEFAULT_VARIANTS, power: float = DEFAULT_POWER):\n",
        "        self.alpha = alpha\n",
        "        self.power = power\n",
        "        self.metrics: List[BaseMetric] = []\n",
        "        self.variants: int = variants\n",
        "\n",
        "    def _get_single_sample_size(self, metric: BaseMetric, alpha: float) -> float:\n",
        "        effect_size = metric.mde / float(np.sqrt(metric.variance))\n",
        "        power_analysis = metric.power_analysis_instance\n",
        "        sample_size = int(\n",
        "            power_analysis.solve_power(\n",
        "                effect_size=effect_size,\n",
        "                alpha=alpha,\n",
        "                power=self.power,\n",
        "                ratio=1,\n",
        "                alternative=metric.alternative,\n",
        "            )\n",
        "        )\n",
        "        return sample_size\n",
        "\n",
        "    def get_sample_size(self) -> float:\n",
        "        if len(self.metrics) * (self.variants - 1) < 2:\n",
        "            return self._get_single_sample_size(self.metrics[0], self.alpha)\n",
        "\n",
        "        num_tests = len(self.metrics) * (self.variants - 1)\n",
        "        lower = min([self._get_single_sample_size(metric, self.alpha) for metric in self.metrics])\n",
        "        upper = max([self._get_single_sample_size(metric, self.alpha / num_tests) for metric in self.metrics])\n",
        "\n",
        "        RANDOM_STATE.set_state(STATE)\n",
        "        return self.get_multiple_sample_size(lower, upper, RANDOM_STATE)\n",
        "\n",
        "    def register_metrics(self, metrics: List[Dict[str, Any]]) -> None:\n",
        "        METRIC_REGISTER_MAP = {\n",
        "            \"boolean\": BooleanMetric,\n",
        "            \"numeric\": NumericMetric,\n",
        "            \"ratio\": RatioMetric,\n",
        "        }\n",
        "\n",
        "        validate(instance=metrics, schema=METRICS_SCHEMA)\n",
        "\n",
        "        for metric in metrics:\n",
        "            metric_class = METRIC_REGISTER_MAP[metric[\"metric_type\"]]\n",
        "            registered_metric = metric_class(**metric[\"metric_metadata\"])\n",
        "            self.metrics.append(registered_metric)"
      ],
      "metadata": {
        "id": "JaSZU0jmLgk_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install parameterized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B758kTsKO8xy",
        "outputId": "6af02e3f-3c21-40dd-ffe1-6f796229e89a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from itertools import combinations_with_replacement as combos\n",
        "from itertools import product\n",
        "from unittest.mock import MagicMock\n",
        "from unittest.mock import patch\n",
        "\n",
        "import numpy as np\n",
        "from numpy.testing import assert_array_equal\n",
        "from parameterized import parameterized\n",
        "from statsmodels.stats.power import NormalIndPower\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "#from sample_size.metrics import BaseMetric\n",
        "#from sample_size.metrics import BooleanMetric\n",
        "#from sample_size.metrics import NumericMetric\n",
        "#from sample_size.metrics import RatioMetric\n",
        "#from sample_size.sample_size_calculator import RANDOM_STATE\n",
        "\n",
        "ALTERNATIVE = \"two-sided\"\n",
        "TEST_ALTERNATIVES = (\"two-sided\", \"smaller\", \"larger\")\n",
        "\n",
        "\n",
        "class DummyMetric(BaseMetric):\n",
        "    def power_analysis_instance(self):\n",
        "        return MagicMock()\n",
        "\n",
        "    def variance(self):\n",
        "        return MagicMock()\n",
        "\n",
        "    def _generate_alt_p_values(self, size, sample_size, RANDOM_STATE):\n",
        "        return MagicMock()\n",
        "\n",
        "\n",
        "class BaseMetricTestCase(unittest.TestCase):\n",
        "    def test_check_positive(self):\n",
        "        test_negative_number = -10\n",
        "        test_name = \"test\"\n",
        "\n",
        "        with self.assertRaises(Exception) as context:\n",
        "            BaseMetric.check_positive(test_negative_number, test_name)\n",
        "\n",
        "        self.assertEqual(\n",
        "            str(context.exception),\n",
        "            f\"Error: Please provide a positive number for {test_name}.\",\n",
        "        )\n",
        "\n",
        "    @parameterized.expand([(np.array(c),) for r in range(2, 5) for c in combos([True, False], r)])\n",
        "    @patch(\"sample_size.metrics.stats\")\n",
        "    @patch(\"tests.sample_size.test_metrics.DummyMetric._generate_alt_p_values\")\n",
        "    def test_generate_p_values(self, true_alt, mock_alt_p_values, mock_stats):\n",
        "        mde = 0.5\n",
        "        sample_size = 10\n",
        "\n",
        "        null_p_value = 1\n",
        "        alt_p_value = 0\n",
        "\n",
        "        mock_alt_p_values.side_effect = lambda size, __, random_state: np.array([alt_p_value] * size)\n",
        "        mock_stats.uniform.rvs.side_effect = lambda _, __, size, random_state: np.array([null_p_value] * size)\n",
        "\n",
        "        metric = DummyMetric(mde, ALTERNATIVE)\n",
        "\n",
        "        p_values = metric.generate_p_values(true_alt, sample_size, RANDOM_STATE)\n",
        "\n",
        "        mock_alt_p_values.assert_called_once()\n",
        "        mock_stats.uniform.rvs.assert_called_once()\n",
        "\n",
        "        assert_array_equal(p_values, np.where(true_alt, alt_p_value, null_p_value))\n",
        "\n",
        "\n",
        "class BooleanMetricTestCase(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.DEFAULT_ALTERNATIVE = ALTERNATIVE\n",
        "        self.DEFAULT_MDE = 0.01\n",
        "        self.DEFAULT_PROBABILITY = 0.05\n",
        "        self.DEFAULT_MOCK_VARIANCE = 99\n",
        "\n",
        "    @patch(\"sample_size.metrics.BooleanMetric._check_probability\")\n",
        "    @patch(\"sample_size.metrics.BooleanMetric.variance\")\n",
        "    def test_boolean_metric_constructor_sets_params(self, mock_variance, mock_check_probability):\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_MOCK_VARIANCE)\n",
        "        mock_check_probability.return_value = self.DEFAULT_PROBABILITY\n",
        "        boolean = BooleanMetric(self.DEFAULT_PROBABILITY, self.DEFAULT_MDE, self.DEFAULT_ALTERNATIVE)\n",
        "\n",
        "        mock_check_probability.assert_called_once_with(self.DEFAULT_PROBABILITY)\n",
        "        self.assertEqual(boolean.probability, self.DEFAULT_PROBABILITY)\n",
        "        self.assertEqual(boolean.variance, self.DEFAULT_MOCK_VARIANCE)\n",
        "        self.assertEqual(boolean.mde, self.DEFAULT_MDE)\n",
        "        self.assertIsInstance(boolean.power_analysis_instance, NormalIndPower)\n",
        "\n",
        "    def test_boolean_metric_variance(self):\n",
        "        boolean = BooleanMetric(self.DEFAULT_PROBABILITY, self.DEFAULT_MDE, self.DEFAULT_ALTERNATIVE)\n",
        "\n",
        "        self.assertEqual(boolean.variance, 0.0475)\n",
        "\n",
        "    def test_boolean_metric_get_probability(self):\n",
        "        probability = BooleanMetric._check_probability(self.DEFAULT_PROBABILITY)\n",
        "\n",
        "        self.assertEqual(probability, self.DEFAULT_PROBABILITY)\n",
        "\n",
        "    def test_boolean_metric_get_probability_too_large(self):\n",
        "        test_probability = 5\n",
        "\n",
        "        with self.assertRaises(Exception) as context:\n",
        "            BooleanMetric._check_probability(test_probability)\n",
        "\n",
        "        self.assertEqual(\n",
        "            str(context.exception),\n",
        "            \"Error: Please provide a float between 0 and 1 for probability.\",\n",
        "        )\n",
        "\n",
        "    def test_boolean_metric_get_probability_too_small(self):\n",
        "        test_probability = -0.1\n",
        "\n",
        "        with self.assertRaises(Exception) as context:\n",
        "            BooleanMetric._check_probability(test_probability)\n",
        "\n",
        "        self.assertEqual(\n",
        "            str(context.exception),\n",
        "            \"Error: Please provide a float between 0 and 1 for probability.\",\n",
        "        )\n",
        "\n",
        "    @parameterized.expand(product((1, 2, 10), (2, 10), TEST_ALTERNATIVES))\n",
        "    @patch(\"sample_size.metrics.BooleanMetric.variance\")\n",
        "    @patch(\"scipy.stats.norm\")\n",
        "    def test_boolean__generate_alt_p_values(self, size, sample_size, alternative, mock_norm, mock_variance):\n",
        "        p_value_generator = mock_norm.sf\n",
        "        p_values = MagicMock()\n",
        "        mock_norm.rvs.return_value = -ord(\"ðŸŒ®\")\n",
        "        p_value_generator.return_value = p_values\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_MOCK_VARIANCE)\n",
        "\n",
        "        metric = BooleanMetric(self.DEFAULT_PROBABILITY, self.DEFAULT_MDE, alternative)\n",
        "        p = metric._generate_alt_p_values(size, sample_size, RANDOM_STATE)\n",
        "\n",
        "        effect_sample_size = self.DEFAULT_MDE / np.sqrt(2 * self.DEFAULT_MOCK_VARIANCE / sample_size)\n",
        "        mock_norm.rvs.assert_called_once_with(loc=effect_sample_size, size=size, random_state=RANDOM_STATE)\n",
        "        mock_norm.sf.assert_called_once_with(np.abs(mock_norm.rvs.return_value))\n",
        "        expected_p_values = p_values if alternative != \"two-sided\" else 2 * p_values\n",
        "        assert_array_equal(p, expected_p_values)\n",
        "\n",
        "\n",
        "class NumericMetricTestCase(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.DEFAULT_MDE = 5\n",
        "        self.DEFAULT_VARIANCE = 5000\n",
        "        self.DEFAULT_ALTERNATIVE = ALTERNATIVE\n",
        "\n",
        "    def test_numeric_metric_constructor_sets_params(self):\n",
        "        numeric = NumericMetric(self.DEFAULT_VARIANCE, self.DEFAULT_MDE, self.DEFAULT_ALTERNATIVE)\n",
        "\n",
        "        self.assertEqual(numeric.variance, self.DEFAULT_VARIANCE)\n",
        "        self.assertEqual(numeric.mde, self.DEFAULT_MDE)\n",
        "        self.assertEqual(numeric.alternative, self.DEFAULT_ALTERNATIVE)\n",
        "        self.assertIsInstance(numeric.power_analysis_instance, TTestIndPower)\n",
        "\n",
        "    @parameterized.expand(product((1, 2, 10), (2, 10), TEST_ALTERNATIVES))\n",
        "    @patch(\"sample_size.metrics.NumericMetric.variance\")\n",
        "    @patch(\"scipy.stats.nct\")\n",
        "    @patch(\"scipy.stats.t\")\n",
        "    def test_numeric__generate_alt_p_values(self, size, sample_size, alternative, mock_t, mock_nct, mock_variance):\n",
        "        p_value_generator = mock_t.sf\n",
        "        p_values = MagicMock()\n",
        "        mock_nct.rvs.return_value = -ord(\"ðŸŒ®\")\n",
        "        p_value_generator.return_value = p_values\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_VARIANCE)\n",
        "\n",
        "        metric = NumericMetric(self.DEFAULT_VARIANCE, self.DEFAULT_MDE, alternative)\n",
        "        p = metric._generate_alt_p_values(size, sample_size, RANDOM_STATE)\n",
        "\n",
        "        effect_sample_size = np.sqrt(sample_size / 2 / self.DEFAULT_VARIANCE) * self.DEFAULT_MDE\n",
        "        df = 2 * (sample_size - 1)\n",
        "        mock_nct.rvs.assert_called_once_with(nc=effect_sample_size, df=df, size=size, random_state=RANDOM_STATE)\n",
        "        mock_t.sf.assert_called_once_with(np.abs(mock_nct.rvs.return_value), df)\n",
        "        expected_p_values = p_values if alternative != \"two-sided\" else 2 * p_values\n",
        "        assert_array_equal(p, expected_p_values)\n",
        "\n",
        "\n",
        "class RatioMetricTestCase(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.DEFAULT_MDE = 5\n",
        "        self.DEFAULT_NUMERATOR_MEAN = 2000\n",
        "        self.DEFAULT_NUMERATOR_VARIANCE = 100000\n",
        "        self.DEFAULT_DENOMINATOR_MEAN = 200\n",
        "        self.DEFAULT_DENOMINATOR_VARIANCE = 2000\n",
        "        self.DEFAULT_COVARIANCE = 5000\n",
        "        self.DEFAULT_VARIANCE = 99\n",
        "        self.DEFAULT_ALTERNATIVE = ALTERNATIVE\n",
        "\n",
        "    @patch(\"sample_size.metrics.RatioMetric.variance\")\n",
        "    def test_ratio_metric_constructor_sets_params(self, mock_variance):\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_VARIANCE)\n",
        "        ratio = RatioMetric(\n",
        "            self.DEFAULT_NUMERATOR_MEAN,\n",
        "            self.DEFAULT_NUMERATOR_VARIANCE,\n",
        "            self.DEFAULT_DENOMINATOR_MEAN,\n",
        "            self.DEFAULT_DENOMINATOR_VARIANCE,\n",
        "            self.DEFAULT_COVARIANCE,\n",
        "            self.DEFAULT_MDE,\n",
        "            self.DEFAULT_ALTERNATIVE,\n",
        "        )\n",
        "\n",
        "        self.assertEqual(ratio.numerator_mean, self.DEFAULT_NUMERATOR_MEAN)\n",
        "        self.assertEqual(ratio.numerator_variance, self.DEFAULT_NUMERATOR_VARIANCE)\n",
        "        self.assertEqual(ratio.denominator_mean, self.DEFAULT_DENOMINATOR_MEAN)\n",
        "        self.assertEqual(ratio.denominator_variance, self.DEFAULT_DENOMINATOR_VARIANCE)\n",
        "        self.assertEqual(ratio.covariance, self.DEFAULT_COVARIANCE)\n",
        "        self.assertEqual(ratio.variance, self.DEFAULT_VARIANCE)\n",
        "        self.assertEqual(ratio.mde, self.DEFAULT_MDE)\n",
        "        self.assertIsInstance(ratio.power_analysis_instance, NormalIndPower)\n",
        "\n",
        "    def test_ratio_metric_variance(self):\n",
        "        ratio = RatioMetric(\n",
        "            self.DEFAULT_NUMERATOR_MEAN,\n",
        "            self.DEFAULT_NUMERATOR_VARIANCE,\n",
        "            self.DEFAULT_DENOMINATOR_MEAN,\n",
        "            self.DEFAULT_DENOMINATOR_VARIANCE,\n",
        "            self.DEFAULT_COVARIANCE,\n",
        "            self.DEFAULT_MDE,\n",
        "            self.DEFAULT_ALTERNATIVE,\n",
        "        )\n",
        "\n",
        "        self.assertEqual(ratio.variance, 5.0)\n",
        "\n",
        "    @parameterized.expand(product((1, 2, 10), (2, 10), TEST_ALTERNATIVES))\n",
        "    @patch(\"sample_size.metrics.RatioMetric.variance\")\n",
        "    @patch(\"scipy.stats.norm\")\n",
        "    def test_ratio__generate_alt_p_values(self, size, sample_size, alternative, mock_norm, mock_variance):\n",
        "        p_value_generator = mock_norm.sf\n",
        "        p_values = MagicMock()\n",
        "        mock_norm.rvs.return_value = -ord(\"ðŸŒ®\")\n",
        "        p_value_generator.return_value = p_values\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_VARIANCE)\n",
        "\n",
        "        metric = RatioMetric(\n",
        "            self.DEFAULT_NUMERATOR_MEAN,\n",
        "            self.DEFAULT_NUMERATOR_VARIANCE,\n",
        "            self.DEFAULT_DENOMINATOR_MEAN,\n",
        "            self.DEFAULT_DENOMINATOR_VARIANCE,\n",
        "            self.DEFAULT_COVARIANCE,\n",
        "            self.DEFAULT_MDE,\n",
        "            self.DEFAULT_ALTERNATIVE,\n",
        "        )\n",
        "\n",
        "        p = metric._generate_alt_p_values(size, sample_size, RANDOM_STATE)\n",
        "\n",
        "        effect_sample_size = self.DEFAULT_MDE / np.sqrt(2 * self.DEFAULT_VARIANCE / sample_size)\n",
        "        mock_norm.rvs.assert_called_once_with(loc=effect_sample_size, size=size, random_state=RANDOM_STATE)\n",
        "        mock_norm.sf.assert_called_once_with(np.abs(mock_norm.rvs.return_value))\n",
        "        expected_p_values = p_values if alternative != \"two-sided\" else 2 * p_values\n",
        "        assert_array_equal(p, expected_p_values)"
      ],
      "metadata": {
        "id": "ftfDu7rKPRMe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from unittest.mock import call\n",
        "from unittest.mock import patch\n",
        "\n",
        "from parameterized import parameterized\n",
        "\n",
        "#from sample_size.metrics import BooleanMetric\n",
        "#from sample_size.metrics import NumericMetric\n",
        "#from sample_size.metrics import RatioMetric\n",
        "#from sample_size.sample_size_calculator import DEFAULT_ALPHA\n",
        "#from sample_size.sample_size_calculator import DEFAULT_POWER\n",
        "#from sample_size.sample_size_calculator import DEFAULT_VARIANTS\n",
        "#from sample_size.sample_size_calculator import RANDOM_STATE\n",
        "#from sample_size.sample_size_calculator import SampleSizeCalculator\n",
        "#from tests.sample_size.test_metrics import ALTERNATIVE\n",
        "\n",
        "\n",
        "class SampleSizeCalculatorTestCase(unittest.TestCase):\n",
        "    def test_sample_size_calculator_constructor_sets_params(self):\n",
        "        test_alpha = 0.1\n",
        "        test_variants = 2\n",
        "        test_power = 0.9\n",
        "        calculator = SampleSizeCalculator(\n",
        "            test_alpha,\n",
        "            test_variants,\n",
        "            test_power,\n",
        "        )\n",
        "\n",
        "        self.assertEqual(calculator.alpha, test_alpha)\n",
        "        self.assertEqual(calculator.power, test_power)\n",
        "        self.assertEqual(calculator.metrics, [])\n",
        "\n",
        "    def test_sample_size_calculator_constructor_sets_params_with_default_params(self):\n",
        "        calculator = SampleSizeCalculator()\n",
        "\n",
        "        self.assertEqual(calculator.alpha, DEFAULT_ALPHA)\n",
        "        self.assertEqual(calculator.variants, DEFAULT_VARIANTS)\n",
        "        self.assertEqual(calculator.power, DEFAULT_POWER)\n",
        "        self.assertEqual(calculator.metrics, [])\n",
        "\n",
        "    @patch(\"statsmodels.stats.power.NormalIndPower.solve_power\")\n",
        "    def test_get_single_sample_size_normal(self, mock_solve_power):\n",
        "        test_probability = 0.05\n",
        "        test_mde = 0.02\n",
        "        test_sample_size = 2000\n",
        "        test_metric = BooleanMetric(\n",
        "            test_probability,\n",
        "            test_mde,\n",
        "            ALTERNATIVE,\n",
        "        )\n",
        "        mock_solve_power.return_value = test_sample_size\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        sample_size = calculator._get_single_sample_size(test_metric, calculator.alpha)\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        mock_solve_power.assert_called_once_with(\n",
        "            effect_size=0.09176629354822471,\n",
        "            alpha=DEFAULT_ALPHA,\n",
        "            power=DEFAULT_POWER,\n",
        "            ratio=1,\n",
        "            alternative=\"two-sided\",\n",
        "        )\n",
        "\n",
        "    @patch(\"statsmodels.stats.power.TTestIndPower.solve_power\")\n",
        "    def test_get_single_sample_size_ttest(self, mock_solve_power):\n",
        "        test_variance = 1000\n",
        "        test_mde = 5\n",
        "        test_sample_size = 2000\n",
        "        test_metric = NumericMetric(\n",
        "            test_variance,\n",
        "            test_mde,\n",
        "            ALTERNATIVE,\n",
        "        )\n",
        "        mock_solve_power.return_value = test_sample_size\n",
        "        calculator = SampleSizeCalculator()\n",
        "\n",
        "        sample_size = calculator._get_single_sample_size(test_metric, calculator.alpha)\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        mock_solve_power.assert_called_once_with(\n",
        "            effect_size=0.15811388300841897,\n",
        "            alpha=DEFAULT_ALPHA,\n",
        "            power=DEFAULT_POWER,\n",
        "            ratio=1,\n",
        "            alternative=\"two-sided\",\n",
        "        )\n",
        "\n",
        "    @parameterized.expand(\n",
        "        [\n",
        "            (\"boolean\", {\"probability\": 0.05, \"mde\": 0.02, \"alternative\": \"two-sided\"}),\n",
        "            (\"numeric\", {\"variance\": 500, \"mde\": 5, \"alternative\": \"smaller\"}),\n",
        "            (\n",
        "                \"ratio\",\n",
        "                {\n",
        "                    \"numerator_mean\": 2000,\n",
        "                    \"numerator_variance\": 100000,\n",
        "                    \"denominator_mean\": 200,\n",
        "                    \"denominator_variance\": 2000,\n",
        "                    \"covariance\": 5000,\n",
        "                    \"mde\": 10,\n",
        "                    \"alternative\": \"larger\",\n",
        "                },\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator.get_multiple_sample_size\")\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator._get_single_sample_size\")\n",
        "    def test_get_sample_size_single(\n",
        "        self, metric_type, metadata, mock_get_single_sample_size, mock_get_multiple_sample_size\n",
        "    ):\n",
        "        test_metric_type = metric_type\n",
        "        test_sample_size = 2000\n",
        "        mock_get_single_sample_size.return_value = test_sample_size\n",
        "\n",
        "        test_mde = metadata[\"mde\"]\n",
        "        test_metric_metadata = metadata\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "\n",
        "        sample_size = calculator.get_sample_size()\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        mock_get_multiple_sample_size.assert_not_called()\n",
        "        mock_get_single_sample_size.assert_called_once()\n",
        "        self.assertEqual(mock_get_single_sample_size.call_args[0][0], calculator.metrics[0])\n",
        "        self.assertEqual(mock_get_single_sample_size.call_args[0][0].mde, test_mde)\n",
        "\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator.get_multiple_sample_size\")\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator._get_single_sample_size\")\n",
        "    def test_get_sample_size_multiple(self, mock_get_single_sample_size, mock_get_multiple_sample_size):\n",
        "        test_metric_type = \"boolean\"\n",
        "        test_sample_size = 2000\n",
        "        mock_get_multiple_sample_size.return_value = test_sample_size\n",
        "        mock_get_single_sample_size.return_value = test_sample_size\n",
        "        test_metric_metadata = {\"probability\": 0.05, \"mde\": 0.02, \"alternative\": ALTERNATIVE}\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics(\n",
        "            [\n",
        "                {\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata},\n",
        "                {\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata},\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        sample_size = calculator.get_sample_size()\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        self.assertEqual(mock_get_single_sample_size.call_count, 4)\n",
        "        mock_get_single_sample_size.assert_has_calls(\n",
        "            [\n",
        "                call(calculator.metrics[0], calculator.alpha),\n",
        "                call(calculator.metrics[1], calculator.alpha),\n",
        "                call(calculator.metrics[0], calculator.alpha / 2),\n",
        "                call(calculator.metrics[1], calculator.alpha / 2),\n",
        "            ]\n",
        "        )\n",
        "        mock_get_multiple_sample_size.assert_called_once_with(test_sample_size, test_sample_size, RANDOM_STATE)\n",
        "\n",
        "    # TODO: parameterize register metric functions\n",
        "    def test_register_metric_boolean(self):\n",
        "        test_metric_type = \"boolean\"\n",
        "        test_probability = 0.05\n",
        "        test_mde = 0.02\n",
        "        test_metric_metadata = {\"probability\": test_probability, \"mde\": test_mde, \"alternative\": \"larger\"}\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertIsInstance(calculator.metrics[0], BooleanMetric)\n",
        "        self.assertEqual(len(calculator.metrics), 1)\n",
        "        self.assertEqual(calculator.metrics[0].variance, 0.0475)\n",
        "        self.assertEqual(calculator.metrics[0].mde, test_mde)\n",
        "\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertEqual(len(calculator.metrics), 2)\n",
        "\n",
        "    def test_register_metric_numeric(self):\n",
        "        test_metric_type = \"numeric\"\n",
        "        test_variance = 5000.0\n",
        "        test_mde = 5.0\n",
        "        test_metric_metadata = {\"variance\": test_variance, \"mde\": test_mde, \"alternative\": \"two-sided\"}\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertIsInstance(calculator.metrics[0], NumericMetric)\n",
        "        self.assertEqual(len(calculator.metrics), 1)\n",
        "        self.assertEqual(calculator.metrics[0].variance, test_variance)\n",
        "        self.assertEqual(calculator.metrics[0].mde, test_mde)\n",
        "\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertEqual(len(calculator.metrics), 2)\n",
        "\n",
        "    def test_register_metric_ratio(self):\n",
        "        test_metric_type = \"ratio\"\n",
        "        test_numerator_mean = 2000.0\n",
        "        test_numerator_variance = 100000.0\n",
        "        test_denominator_mean = 200.0\n",
        "        test_denominator_variance = 2000.0\n",
        "        test_covariance = 5000.0\n",
        "        test_mde = 5.0\n",
        "        test_variance = 5\n",
        "        test_metric_metadata = {\n",
        "            \"numerator_mean\": test_numerator_mean,\n",
        "            \"numerator_variance\": test_numerator_variance,\n",
        "            \"denominator_mean\": test_denominator_mean,\n",
        "            \"denominator_variance\": test_denominator_variance,\n",
        "            \"covariance\": test_covariance,\n",
        "            \"mde\": test_mde,\n",
        "            \"alternative\": \"smaller\",\n",
        "        }\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertIsInstance(calculator.metrics[0], RatioMetric)\n",
        "        self.assertEqual(len(calculator.metrics), 1)\n",
        "        self.assertEqual(calculator.metrics[0].variance, test_variance)\n",
        "        self.assertEqual(calculator.metrics[0].mde, test_mde)\n",
        "\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertEqual(len(calculator.metrics), 2)\n",
        "\n",
        "    def test_register_metric_invalid_metadata(self):\n",
        "        test_metric_type = \"numeric\"\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        with self.assertRaises(Exception):\n",
        "            calculator.register_metrics([{\"metric_type\": test_metric_type}])"
      ],
      "metadata": {
        "id": "DonfBRY2NVRN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tester = SampleSizeCalculatorTestCase()\n",
        "tester.test_sample_size_calculator_constructor_sets_params()"
      ],
      "metadata": {
        "id": "Lstha0CFPaqz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Baseline Conversion Rate\n",
        "\n",
        "Your control group's expected conversion rate.\n",
        "\n",
        "\n",
        "\n",
        "> Minimum Detectable Effect\n",
        "\n",
        "The minimum relative change in conversion rate you would like to be able to detect.\n",
        "\n",
        "\n",
        "> Statistical Significance\n",
        "\n",
        "95% is an accepted standard for statistical significance, although Optimizely allows you to set your own threshold for significance based on your risk tolerance.\n",
        "\n"
      ],
      "metadata": {
        "id": "RxUbnxh9SgfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç¬¬ä¸€ç±»é”™è¯¯ï¼šåŽŸå‡è®¾ä¸ºçœŸçš„æ—¶å€™ï¼Œæ‹’ç»åŽŸå‡è®¾çš„æ¦‚çŽ‡ã€‚\n",
        "\n",
        "Î±ï¼šå‡è®¾ABæ²¡æœ‰å·®å¼‚æ—¶ï¼Œè§‚å¯Ÿåˆ°æœ‰å·®å¼‚çš„æ¦‚çŽ‡\n",
        "\n",
        "> Significance level Î±\n",
        "\n",
        "Percent of the time a difference will be detected, assuming one does NOT exist\n",
        "\n",
        "\n",
        "ç¬¬äºŒç±»é”™è¯¯ï¼šåŽŸå‡è®¾ä¸ºå‡çš„æ—¶å€™ï¼ŒæŽ¥å—åŽŸå‡è®¾çš„æ¦‚çŽ‡ã€‚\n",
        "\n",
        "Î²ï¼šå‡è®¾ABæœ‰å·®å¼‚æ—¶ï¼Œè§‚å¯Ÿåˆ°æ²¡æœ‰å·®å¼‚çš„æ¦‚çŽ‡\n",
        "\n",
        "> Statistical power 1âˆ’Î²\n",
        "\n",
        "Percent of the time the minimum effect size will be detected, assuming it exists\n",
        "\n"
      ],
      "metadata": {
        "id": "yCldNciVTDhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evan's Awesome A/B Tools:\n",
        "\n",
        "## Sample Size Calculator\n",
        "\n",
        "### Question: How many subjects are needed for an A/B test?\n",
        "\n",
        "Baseline conversion rate\n",
        "\n",
        "\n",
        "Minimum Detectable Effect:\n",
        "The Minimum Detectable Effect is the smallest effect that will be detected (1-Î²)% of the time.\n",
        "\n",
        "\n",
        "Statistical power 1âˆ’Î²:\n",
        "Percent of the time the minimum effect size will be detected, assuming it exists.\n",
        "\n",
        "Significance level Î±:\n",
        "Percent of the time a difference will be detected, assuming one does NOT exist.\n"
      ],
      "metadata": {
        "id": "zP2V_U-5ZOPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "def compute_sample_size(p0, mde, alpha=0.05, beta=0.2, tails=\"Two\"):\n",
        "    \"\"\"\n",
        "    Returns the sample size for a two-tailed AB test comparing conversion\n",
        "    rates.\n",
        "\n",
        "    The sample size equation is for binomial distributions only.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    p0 : float\n",
        "        Baseline conversion rate\n",
        "\n",
        "    mde : float or int\n",
        "        Minimum detectable effect. This is the 'sensitivity' of the test or\n",
        "        the relative difference in conversion rates that you want to be able\n",
        "        to detect.\n",
        "\n",
        "    alpha : float\n",
        "        The chances of a Type I error. Tests are normally run to a 95%\n",
        "        significance meaning an alpha of 1 - 0.95 = 0.05. Default = 0.05.\n",
        "\n",
        "    beta : float\n",
        "        The chances of a Type II error. For sample sizing, a beta of 0.2 is\n",
        "        acceptable and provides the test with 80% statistical power as is\n",
        "        standard.\n",
        "\n",
        "    tails : str\n",
        "        One or two tails to specify what type of hypothesis test this is.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Minimum number of observations required per variant.\n",
        "    \"\"\"\n",
        "\n",
        "    # Conditional alpha value based on whether one or two tail test\n",
        "    if tails == \"Two\":\n",
        "        computed_alpha = alpha / 2\n",
        "    else:\n",
        "        computed_alpha = alpha\n",
        "\n",
        "    p1 = p0 * (1 + mde)\n",
        "    N = (\n",
        "        (norm.ppf(1 - computed_alpha) + norm.ppf(1 - beta)) ** 2\n",
        "        * (p0 * (1 - p0) + p1 * (1 - p1))\n",
        "        / ((p0 - p1) ** 2)\n",
        "    )\n",
        "    return int(N)"
      ],
      "metadata": {
        "id": "SeUQA_DBS56Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_sample_size(0.89, 0.0011, 0.05, 0.2, \"Two\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMvi6xOjWo6B",
        "outputId": "d70fa45c-f06a-4878-98e1-3e0311ca27ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1597187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_sample_size(0.89, 0.0011, 0.05, 0.2, \"One\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVgrElanYSKV",
        "outputId": "5eab0757-bbf4-492c-a44d-ab9cdabd3c58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1258103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-Squared Test\n",
        "\n",
        "### Question: Does the rate of success differ across two groups?\n",
        "\n",
        "If the experiment is repeated many times, the confidence level is the percent of the time each sample's success rate will fall within the reported confidence interval.\n",
        "\n",
        "It is also the percent of the time no difference will be detected between the two groups, assuming no difference exists."
      ],
      "metadata": {
        "id": "1icuuzPZaTCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest as ztest\n",
        "import numpy as np\n",
        "\n",
        "ztest(count=np.array([3000,3200]), nobs=np.array([10000,10000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_yJ5VtygPwH",
        "outputId": "1039d053-2d49-47ec-adad-6cb5da6c2a75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.057803726183795, 0.0022296556161908814)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¯¹ç…§ç»„ï¼šå‚ä¸Žäººæ•° 10000ï¼Œè½¬åŒ–äººæ•° 3000\n",
        "\n",
        "å®žéªŒç»„ï¼šå‚ä¸Žäººæ•° 10000ï¼Œè½¬åŒ–äººæ•° 3200\n",
        "\n",
        "æ˜¾è‘—æ€§æ°´å¹³ï¼š0.05\n",
        "\n",
        "\n",
        "ç¬¬1ä¸ªå€¼ä¸ºzåˆ†æ•°ï¼Œç¬¬2ä¸ªå€¼ä¸ºpå€¼ã€‚\n",
        "på€¼<0.05ï¼Œä»Žè€Œå¯çŸ¥ä¸¤ç»„å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå®žéªŒç»“æžœæå‡æ˜¯æ˜¾è‘—çš„ã€‚\n"
      ],
      "metadata": {
        "id": "OusCmZ40gzoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([3200,3000]), nobs=np.array([10000,10000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENx66XHaiy0J",
        "outputId": "030a75f9-c2cc-4a88-b7f2-8332e772a2cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.057803726183795, 0.0022296556161908814)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([320,3000]), nobs=np.array([1000,10000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG7sirwMi5MK",
        "outputId": "d6cf202d-65e7-4f84-9143-5e8d3d53f2f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.3136409747118007, 0.18896705292826543)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([125810*(0.89-0.0011),1258103*0.89]), nobs=np.array([125810,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwCKaXxWhAJQ",
        "outputId": "6448e828-2e4e-4dd7-8588-d564a77ad939"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.1884740633049435, 0.23464669236156277)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([1258103*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5H6awyTiGt6",
        "outputId": "3368acb2-1917-4882-f52d-c6786ddd7e1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-2.782246745764699, 0.005398397957847781)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([2000000*(0.89-0.0011),2000000*0.89]), nobs=np.array([2000000,2000000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNytFl5Eic5G",
        "outputId": "1c3dd5f7-2f54-456d-8241-d366b8588ce4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.5079431131165877, 0.0004515856033560191)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=1\n",
        "z,p = ztest(count=np.array([1258103*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103,1258103]))\n",
        "while p<=0.05:\n",
        "  r=r-0.1\n",
        "  z,p = ztest(count=np.array([1258103*r*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103*r,1258103]))\n",
        "\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iluIn-7LkJVO",
        "outputId": "76d8d3be-9b7a-428c-d903-ee28ecc47d0c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30000000000000016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([1258103*0.4*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103*0.4,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlRzpZ38kt5x",
        "outputId": "74de4e65-605c-4ec3-84d5-d0c20a4b2709"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-2.105147713673478, 0.035278451987355554)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([1258103*0.1*(0.89-0.01),1258103*0.89]), nobs=np.array([1258103*0.1,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhWNEoN8k8zn",
        "outputId": "c69bd4c6-56c3-4257-dcac-5f08e021e20d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-10.76973702446419, 4.783655666578137e-27)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Sampling\n",
        "\n",
        "### Question: How many conversions are needed for a sequential A/B test?\n",
        "\n",
        "\n",
        "\n",
        "åºè´¯æŠ½æ ·æ–¹æ¡ˆæ˜¯æŒ‡åœ¨æŠ½æ ·æ—¶ï¼Œä¸äº‹å…ˆè§„å®šæ€»çš„æŠ½æ ·ä¸ªæ•°ï¼ˆè§‚æµ‹æˆ–å®žéªŒæ¬¡æ•°ï¼‰ï¼Œè€Œæ˜¯å…ˆæŠ½å°‘é‡æ ·æœ¬ï¼Œæ ¹æ®å…¶ç»“æžœï¼Œå†å†³å®šåœæ­¢æŠ½æ ·æˆ–ç»§ç»­æŠ½æ ·ã€æŠ½å¤šå°‘ï¼Œè¿™æ ·ä¸‹åŽ»ï¼Œç›´è‡³å†³å®šåœæ­¢æŠ½æ ·ä¸ºæ­¢ã€‚\n",
        "\n",
        "\n",
        "ä¾‹å¦‚ï¼Œä¸€ä¸ªäº§å“æŠ½æ ·æ£€éªŒæ–¹æ¡ˆè§„å®šæŒ‰æ‰¹æŠ½æ ·å“20ä»¶ï¼Œè‹¥å…¶ä¸­ä¸åˆæ ¼å“ä»¶æ•°ä¸è¶…è¿‡3ï¼Œåˆ™æŽ¥æ”¶è¯¥æ‰¹ï¼Œå¦åˆ™æ‹’æ”¶ã€‚åœ¨æ­¤ï¼ŒæŠ½æ ·ä¸ªæ•°20æ˜¯é¢„å®šçš„ï¼Œæ˜¯å›ºå®šæŠ½æ ·ã€‚\n",
        "\n",
        "è‹¥æ–¹æ¡ˆè§„å®šä¸ºï¼šç¬¬ä¸€æ‰¹æŠ½å‡º3ä¸ªï¼Œè‹¥å…¨ä¸ºä¸åˆæ ¼å“ï¼Œæ‹’æ”¶è¯¥æ‰¹ï¼Œè‹¥å…¶ä¸­ä¸åˆæ ¼å“ä»¶æ•°ä¸º x1<3ï¼Œåˆ™ç¬¬äºŒæ‰¹å†æŠ½ 3-x1 ä¸ªï¼Œè‹¥å…¨ä¸ºä¸åˆæ ¼å“ï¼Œåˆ™æ‹’æ”¶è¯¥æ‰¹ï¼Œè‹¥å…¶ä¸­ä¸åˆæ ¼å“æ•°ä¸º x2<3-x1ï¼Œåˆ™ç¬¬ä¸‰æ‰¹å†æŠ½ 3-x1-x2 ä¸ªï¼Œè¿™æ ·ä¸‹åŽ»ï¼Œç›´åˆ°æŠ½æ»¡20ä»¶æˆ–æŠ½å¾—3ä¸ªä¸åˆæ ¼å“ä¸ºæ­¢ã€‚è¿™æ˜¯ä¸€ä¸ªåºè´¯æŠ½æ ·æ–¹æ¡ˆï¼Œå…¶æ•ˆæžœä¸Žå‰è¿°å›ºå®šæŠ½æ ·æ–¹æ¡ˆç›¸åŒï¼Œä½†æŠ½æ ·ä¸ªæ•°å¹³å‡è®²è¦èŠ‚çœäº›ã€‚"
      ],
      "metadata": {
        "id": "8QFpmmOQbgez"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lxXQhcbbEt07"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Sample T-Test\n",
        "\n",
        "### Question: Does the average value differ across two groups?"
      ],
      "metadata": {
        "id": "KXYYSjuDb0ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pingouin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jB4SRHFHCBA",
        "outputId": "973abbc4-9483-447c-e60a-934d8be8a12e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pingouin in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from pingouin) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.11 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.12.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.13.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.2.2)\n",
            "Requirement already satisfied: pandas-flavor>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.5.0)\n",
            "Requirement already satisfied: outdated in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.8.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pingouin) (2022.7.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin) (2022.12.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin) (0.2)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (2.27.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basic datascience/data manipulation libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy.random as npr\n",
        "import scipy.stats as stats\n",
        "\n",
        "# graphs\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# formulat interface to statsmodels (standard linear models)\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# easy-to-use traditional psychological stats (t-test, anova)\n",
        "import pingouin as pg\n",
        "\n",
        "# hate these things\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "hZqXXQ14G7tq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "drug = np.array([101,100,102,104,102,97,105,105,98,101,100,123,105,103,100,95,102,106,\n",
        "        109,102,82,102,100,102,102,101,102,102,103,103,97,97,103,101,97,104,\n",
        "        96,103,124,101,101,100,101,101,104,100,101])\n",
        "placebo = np.array([99,101,100,101,102,100,97,101,104,101,102,102,100,105,88,101,100,\n",
        "           104,100,100,100,101,102,103,97,101,101,100,101,99,101,100,100,\n",
        "           101,100,99,101,100,102,99,100,99])\n",
        "\n",
        "\n",
        "# packing the data into a tidy dataframe can be nice\n",
        "exp_df = pd.DataFrame(dict(group=[0]*len(drug)+[1]*len(placebo), score=np.r_[drug,placebo]))\n",
        "\n",
        "exp_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tQ_v29d4HGzD",
        "outputId": "16fc1150-9b21-41f3-9816-840387b8d8e9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   group  score\n",
              "0      0    101\n",
              "1      0    100\n",
              "2      0    102\n",
              "3      0    104\n",
              "4      0    102"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-203729c3-0ea2-4482-9b6d-5d03b7e40105\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-203729c3-0ea2-4482-9b6d-5d03b7e40105')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-203729c3-0ea2-4482-9b6d-5d03b7e40105 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-203729c3-0ea2-4482-9b6d-5d03b7e40105');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the mean of the drug group different than the mean of the placebo group?"
      ],
      "metadata": {
        "id": "5ZRG5BBvHwCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean of drug group:\", drug.mean())\n",
        "print(\"Mean of placebo group:\", placebo.mean())\n",
        "print(\"The difference in means is: \", drug.mean()-placebo.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrPrfG5lHnb1",
        "outputId": "c37030d7-b59e-4ab5-9599-689347356b6c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of drug group: 101.91489361702128\n",
            "Mean of placebo group: 100.35714285714286\n",
            "The difference in means is:  1.5577507598784166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The look close but not identical. However, \"look\" isn't enough.\n",
        "\n",
        "Lets begin with a two-sample, independent samples t-test. We will assume that both groups have equal variance here."
      ],
      "metadata": {
        "id": "hd-WRPkKH8_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pg.ttest(x=drug, y=placebo, paired=False, alternative='two-sided', correction=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "_SZukA-7H24s",
        "outputId": "399cd2ef-ab30-44b3-a712-acdd4f401c7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               T  dof alternative     p-val          CI95%   cohen-d   BF10  \\\n",
              "T-test  1.558695   87   two-sided  0.122699  [-0.43, 3.54]  0.330965  0.642   \n",
              "\n",
              "           power  \n",
              "T-test  0.338035  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c0476a5-9b15-41a7-830a-040e85f2277a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>dof</th>\n",
              "      <th>alternative</th>\n",
              "      <th>p-val</th>\n",
              "      <th>CI95%</th>\n",
              "      <th>cohen-d</th>\n",
              "      <th>BF10</th>\n",
              "      <th>power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-test</th>\n",
              "      <td>1.558695</td>\n",
              "      <td>87</td>\n",
              "      <td>two-sided</td>\n",
              "      <td>0.122699</td>\n",
              "      <td>[-0.43, 3.54]</td>\n",
              "      <td>0.330965</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.338035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c0476a5-9b15-41a7-830a-040e85f2277a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c0476a5-9b15-41a7-830a-040e85f2277a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c0476a5-9b15-41a7-830a-040e85f2277a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We specified group `x` as `drug` and `y` as `placebo` (arbitrarily, you could flip that).\n",
        "\n",
        "We used 'two-sided' which is the traditionally more conservative test which you use unless you have a strong a-priori belief one group is going to have a higher mean value.\n",
        "\n",
        "We did not apply a correction known as the Welch-Satterthwaite correction for unequal variances.\n",
        "\n",
        "We will try that later."
      ],
      "metadata": {
        "id": "8INS1aAiJAqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that the t-value for the mean difference is 1.599.\n",
        "\n",
        "The test has 87 degrees of freedom.\n",
        "\n",
        "The p-value is 0.122699 which is greater than the traditional \"alpha\" cut off at p=0.05.\n",
        "\n",
        "Therefore this test is not significant.\n",
        "\n",
        "The 95% confidence interval for the differences between the means is -0.43 on the low end to 3.54 with (1.5577 the center).\n",
        "\n",
        "The effect size (Cohen's d) is 0.331.\n",
        "\n",
        "The Bayes Factor in favor of the alternative hypothesis (that the means are difference) is lower than one (0.642).\n",
        "\n",
        "The post-hoc power of the test is 0.338.\n",
        "\n",
        "All of this is consistent with there being basically no differences between these two groups.\n"
      ],
      "metadata": {
        "id": "s_qCEyTlJbpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Survival Times\n",
        "\n",
        "### Question: Does the hazard rate differ across two groups?"
      ],
      "metadata": {
        "id": "no3WLdXnb_8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lifelines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkmnXLhVPaOs",
        "outputId": "91c554b7-5669-4a59-90ca-4107519f9095"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.6.1)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines) (0.6.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines) (0.18.3)\n",
            "Requirement already satisfied: astor>=0.8 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (0.8.1)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.6.3)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->lifelines) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lifelines.datasets import load_waltons\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines.utils import median_survival_times\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# æ•°æ®è½½å…¥\n",
        "df = load_waltons()\n",
        "print(df.head(),'\\n')\n",
        "print(df['T'].min(),df['T'].max(),'\\n')\n",
        "print(df['E'].value_counts(),'\\n')\n",
        "print(df['group'].value_counts(),'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqZqSVz3QIWb",
        "outputId": "401371e2-9266-44c7-8356-55c663340deb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      T  E    group\n",
            "0   6.0  1  miR-137\n",
            "1  13.0  1  miR-137\n",
            "2  13.0  1  miR-137\n",
            "3  13.0  1  miR-137\n",
            "4  19.0  1  miR-137 \n",
            "\n",
            "6.0 75.0 \n",
            "\n",
            "1    156\n",
            "0      7\n",
            "Name: E, dtype: int64 \n",
            "\n",
            "control    129\n",
            "miR-137     34\n",
            "Name: group, dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¯ä»¥çœ‹åˆ°æ•°æ®æœ‰ä¸‰åˆ—ï¼Œå…¶ä¸­Tä»£è¡¨min(D,O)ï¼Œå…¶ä¸­Dä¸ºæ­»äº¡æ—¶é—´ï¼ŒOä¸ºè§‚æµ‹æˆªæ­¢æ—¶é—´ã€‚\n",
        "\n",
        "Eä»£è¡¨æ˜¯å¦è§‚å¯Ÿåˆ°â€œæ­»äº¡â€ï¼Œ1ä»£è¡¨è§‚æµ‹åˆ°äº†ï¼Œ0ä»£è¡¨æœªè§‚æµ‹åˆ°ï¼Œå³ç”Ÿå­˜åˆ†æžä¸­çš„åˆ å¤±æ•°æ®ï¼Œå…±7ä¸ªã€‚\n",
        "\n",
        "groupä»£è¡¨æ˜¯å¦å­˜åœ¨ç—…æ¯’ï¼ŒmiR-137ä»£è¡¨å­˜åœ¨ç—…æ¯’ï¼Œcontrolä»£è¡¨ä¸ºä¸å­˜åœ¨å³å¯¹ç…§ç»„ï¼Œæ ¹æ®ç»Ÿè®¡ï¼Œå­˜åœ¨miR-137ç—…æ¯’äººæ•°34äººï¼Œä¸å­˜åœ¨129äººã€‚\n",
        "\n",
        "éœ€è¦æ³¨æ„ï¼Œè¯¥æ ¼å¼å¹¶éžä¸¥æ ¼çš„å¯¿å‘½è¡¨ã€‚"
      ],
      "metadata": {
        "id": "IkJVCyn0QeWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logrankæ£€éªŒçš„é›¶å‡è®¾æ˜¯æŒ‡ä¸¤ç»„çš„ç”Ÿå­˜æ—¶é—´åˆ†å¸ƒå®Œå…¨ä¸€è‡´ï¼Œå½“æˆ‘ä»¬é€šè¿‡è®¡ç®—æ‹’ç»é›¶å‡è®¾æ—¶ï¼Œå°±å¯ä»¥è®¤ä¸ºä¸¤ç»„çš„ç”Ÿå­˜æ—¶é—´åˆ†å¸ƒå­˜åœ¨ç»Ÿè®¡å­¦å·®å¼‚ã€‚"
      ],
      "metadata": {
        "id": "fHfZB6pVPnc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lifelines.statistics import logrank_test\n",
        "\n",
        "T = df['T']\n",
        "E = df['E']\n",
        "\n",
        "dem = (df['group'] == 'miR-137')\n",
        "\n",
        "results = logrank_test(T[dem], T[~dem], E[dem], E[~dem], alpha=.99)\n",
        "results.print_summary()\n",
        "print(results.p_value)\n",
        "print(results.test_statistic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "rxRoBVk-Pclx",
        "outputId": "3424e008-821b-46cc-c651-cc28937ffb61"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<lifelines.StatisticalResult: logrank_test>\n",
              "               t_0 = -1\n",
              " null_distribution = chi squared\n",
              "degrees_of_freedom = 1\n",
              "             alpha = 0.99\n",
              "         test_name = logrank_test\n",
              "\n",
              "---\n",
              " test_statistic      p  -log2(p)\n",
              "         122.25 <0.005     91.99"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>t_0</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>null_distribution</th>\n",
              "      <td>chi squared</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>degrees_of_freedom</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha</th>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_name</th>\n",
              "      <td>logrank_test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_statistic</th>\n",
              "      <th>p</th>\n",
              "      <th>-log2(p)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122.25</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>91.99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/latex": "\\begin{tabular}{lrrr}\n & test_statistic & p & -log2(p) \\\\\n0 & 122.25 & 0.00 & 91.99 \\\\\n\\end{tabular}\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0359832222854986e-28\n",
            "122.2491255730062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "På€¼å°äºŽ0.05ï¼Œæ‹’ç»åŽŸå‡è®¾ï¼Œå­˜åœ¨å·®å¼‚ã€‚"
      ],
      "metadata": {
        "id": "Yw-QFsiLR1go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count Data\n",
        "\n",
        "### Question: Does the rate of arrival differ across two time periods?"
      ],
      "metadata": {
        "id": "PZ2YG882bpPn"
      }
    }
  ]
}