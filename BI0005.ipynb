{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJKZ7mmhiwsNdstPulbsv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannasmile/colab_code_note/blob/main/BI0005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABCMeta\n",
        "from abc import abstractmethod\n",
        "from typing import Union\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from scipy import stats\n",
        "from statsmodels.stats.power import NormalIndPower\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "\n",
        "class BaseMetric:\n",
        "    __metaclass__ = ABCMeta\n",
        "    mde: float\n",
        "\n",
        "    def __init__(self, mde: float, alternative: str):\n",
        "        self.mde = mde\n",
        "        self.alternative = alternative\n",
        "\n",
        "    @property\n",
        "    @abstractmethod\n",
        "    def power_analysis_instance(self) -> Union[NormalIndPower, TTestIndPower]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    @abstractmethod\n",
        "    def variance(self) -> float:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @staticmethod\n",
        "    def check_positive(number: float, name: str) -> float:\n",
        "        if number < 0:\n",
        "            raise ValueError(f\"Error: Please provide a positive number for {name}.\")\n",
        "        else:\n",
        "            return number\n",
        "\n",
        "    def generate_p_values(\n",
        "        self, true_alt: npt.NDArray[np.bool_], sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        \"\"\"\n",
        "        This method simulates any registered metric's p-value. The output will\n",
        "        later be applied to BH procedure\n",
        "\n",
        "        Parameters:\n",
        "            true_alt: A boolean array of shape (m hypotheses x replications).\n",
        "            Each element represents whether the alternative hypothesis is true\n",
        "            for an individual hypothesis sample_size: sample size used for simulations\n",
        "            sample_size: an integer used to generate\n",
        "            random_state: random state to generate fixed output for any given input\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            p-value: A float array of shape (m hypotheses x replications) of\n",
        "            simulated p-values\n",
        "        \"\"\"\n",
        "        total_alt = true_alt.sum()\n",
        "        total_null = true_alt.size - total_alt\n",
        "\n",
        "        p_values = np.empty(true_alt.shape)\n",
        "        p_values[true_alt] = self._generate_alt_p_values(total_alt, sample_size, random_state)\n",
        "        p_values[~true_alt] = stats.uniform.rvs(0, 1, total_null, random_state=random_state)\n",
        "\n",
        "        return p_values\n",
        "\n",
        "    @abstractmethod\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class BooleanMetric(BaseMetric):\n",
        "    probability: float\n",
        "    mde: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        probability: float,\n",
        "        mde: float,\n",
        "        alternative: str,\n",
        "    ):\n",
        "        super(BooleanMetric, self).__init__(mde, alternative)\n",
        "        self.probability = self._check_probability(probability)\n",
        "\n",
        "    @property\n",
        "    def variance(self) -> float:\n",
        "        return self.probability * (1 - self.probability)\n",
        "\n",
        "    @property\n",
        "    def power_analysis_instance(self) -> NormalIndPower:\n",
        "        return NormalIndPower()\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_probability(probability: float) -> float:\n",
        "        if 0 <= probability <= 1:\n",
        "            return probability\n",
        "        else:\n",
        "            raise ValueError(\"Error: Please provide a float between 0 and 1 for probability.\")\n",
        "\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        effect_size = self.mde / np.sqrt(2 * self.variance / sample_size)\n",
        "        z_alt = stats.norm.rvs(loc=effect_size, size=size, random_state=random_state)\n",
        "        p_values: npt.NDArray[np.float_] = stats.norm.sf(np.abs(z_alt))\n",
        "        if self.alternative == \"two-sided\":\n",
        "            p_values *= 2\n",
        "        return p_values\n",
        "\n",
        "\n",
        "class NumericMetric(BaseMetric):\n",
        "    mde: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        variance: float,\n",
        "        mde: float,\n",
        "        alternative: str,\n",
        "    ):\n",
        "        super(NumericMetric, self).__init__(mde, alternative)\n",
        "        self._variance = self.check_positive(variance, \"variance\")\n",
        "\n",
        "    @property\n",
        "    def variance(self) -> float:\n",
        "        return self._variance\n",
        "\n",
        "    @property\n",
        "    def power_analysis_instance(self) -> TTestIndPower:\n",
        "        return TTestIndPower()\n",
        "\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        nc = np.sqrt(sample_size / 2 / self.variance) * self.mde\n",
        "        t_alt = stats.nct.rvs(nc=nc, df=2 * (sample_size - 1), size=size, random_state=random_state)\n",
        "        p_values: npt.NDArray[np.float_] = stats.t.sf(np.abs(t_alt), 2 * (sample_size - 1))\n",
        "        # Todo: use accurate p-value calculation due to nct's asymmetric distribution\n",
        "        if self.alternative == \"two-sided\":\n",
        "            p_values *= 2\n",
        "        return p_values\n",
        "\n",
        "\n",
        "class RatioMetric(BaseMetric):\n",
        "    numerator_mean: float\n",
        "    numerator_variance: float\n",
        "    denominator_mean: float\n",
        "    denominator_variance: float\n",
        "    covariance: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        numerator_mean: float,\n",
        "        numerator_variance: float,\n",
        "        denominator_mean: float,\n",
        "        denominator_variance: float,\n",
        "        covariance: float,\n",
        "        mde: float,\n",
        "        alternative: str,\n",
        "    ):\n",
        "        super(RatioMetric, self).__init__(mde, alternative)\n",
        "        # TODO: add check for Cauchy-Schwarz inequality\n",
        "        self.numerator_mean = numerator_mean\n",
        "        self.numerator_variance = self.check_positive(numerator_variance, \"numerator variance\")\n",
        "        self.denominator_mean = denominator_mean\n",
        "        self.denominator_variance = self.check_positive(denominator_variance, \"denominator variance\")\n",
        "        self.covariance = covariance\n",
        "\n",
        "    @property\n",
        "    def variance(self) -> float:\n",
        "        variance = (\n",
        "            self.numerator_variance / self.denominator_mean**2\n",
        "            + self.denominator_variance * self.numerator_mean**2 / self.denominator_mean**4\n",
        "            - 2 * self.covariance * self.numerator_mean / self.denominator_mean**3\n",
        "        )\n",
        "\n",
        "        return variance\n",
        "\n",
        "    @property\n",
        "    def power_analysis_instance(self) -> NormalIndPower:\n",
        "        return NormalIndPower()\n",
        "\n",
        "    def _generate_alt_p_values(\n",
        "        self, size: int, sample_size: int, random_state: np.random.RandomState\n",
        "    ) -> npt.NDArray[np.float_]:\n",
        "        effect_size = self.mde / np.sqrt(2 * self.variance / sample_size)\n",
        "        z_alt = stats.norm.rvs(loc=effect_size, size=size, random_state=random_state)\n",
        "        p_values: npt.NDArray[np.float_] = stats.norm.sf(np.abs(z_alt))\n",
        "        if self.alternative == \"two-sided\":\n",
        "            p_values *= 2\n",
        "        return p_values"
      ],
      "metadata": {
        "id": "8OADOmdPLbP9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "#from sample_size.metrics import BaseMetric\n",
        "\n",
        "DEFAULT_REPLICATION: int = 400\n",
        "DEFAULT_EPSILON: float = 0.01\n",
        "DEFAULT_MAX_RECURSION: int = 20\n",
        "\n",
        "\n",
        "class MultipleTestingMixin:\n",
        "    \"\"\"\n",
        "    This class calculates sample size required under the case of multiple testing\n",
        "\n",
        "    Attributes:\n",
        "    metrics: a list of BaseMetric registered by users\n",
        "    variants: number of variants, including control\n",
        "    alpha: statistical significance\n",
        "    power: average power, calculated as #correct rejections/#true alternative hypotheses\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    metrics: List[BaseMetric]\n",
        "    alpha: float\n",
        "    power: float\n",
        "    variants: int\n",
        "\n",
        "    def get_multiple_sample_size(\n",
        "        self,\n",
        "        lower: float,\n",
        "        upper: float,\n",
        "        random_state: np.random.RandomState,\n",
        "        depth: int = 0,\n",
        "        replication: int = DEFAULT_REPLICATION,\n",
        "        epsilon: float = DEFAULT_EPSILON,\n",
        "        max_recursion_depth: int = DEFAULT_MAX_RECURSION,\n",
        "    ) -> int:\n",
        "        \"\"\"\n",
        "        This method finds minimum required sample size per cohort that generates\n",
        "        average power higher than required\n",
        "\n",
        "        Attributes:\n",
        "            lower: lower bound of sample size search\n",
        "            upper: upper bound of sample size search\n",
        "            depth: number of recursions\n",
        "            replication: number of Monte Carlo simulations to calculate empirical power\n",
        "            epsilon: absolute difference between our estimate for power and desired power\n",
        "                needed before we will return\n",
        "            max_recursion_depth: how many recursive calls can be made before the\n",
        "                search is abandoned\n",
        "\n",
        "        Returns\n",
        "            minimum required sample size per cohort\n",
        "        \"\"\"\n",
        "\n",
        "        if depth > max_recursion_depth:\n",
        "            raise RecursionError(f\"Couldn't find a sample size that satisfies the power you requested: {self.power}\")\n",
        "\n",
        "        candidate = int(np.sqrt(lower * upper))\n",
        "        expected_power = self._expected_average_power(candidate, random_state, replication)\n",
        "        if np.isclose(self.power, expected_power, atol=epsilon):\n",
        "            return candidate\n",
        "        elif lower == upper:\n",
        "            raise RecursionError(f\"Couldn't find a sample size that satisfies the power you requested: {self.power}\")\n",
        "\n",
        "        if expected_power > self.power:\n",
        "            return self.get_multiple_sample_size(lower, candidate, random_state, depth + 1)\n",
        "        else:\n",
        "            return self.get_multiple_sample_size(candidate, upper, random_state, depth + 1)\n",
        "\n",
        "    def _expected_average_power(\n",
        "        self, sample_size: int, random_state: np.random.RandomState, replication: int = DEFAULT_REPLICATION\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        This method calculates expected average power of multiple testings. For each possible number of true null\n",
        "        hypothesis, we simulate each metric/treatment variant's test statistics and calculate their p-values,\n",
        "        then calculate expected average power = number of True rejection/ true alternative hypotheses\n",
        "\n",
        "        Attributes:\n",
        "        sample size: determines the variance/ degrees of freedom of the distribution we sample test statistics from\n",
        "        replication: number of times we repeat the simulation process\n",
        "\n",
        "        Returns value expected average power\n",
        "        \"\"\"\n",
        "        true_alt_count = 0.0\n",
        "        true_discovery_count = 0.0\n",
        "\n",
        "        # a metric for each test we would conduct\n",
        "        metrics = self.metrics * (self.variants - 1)\n",
        "\n",
        "        def fdr_bh(a: npt.NDArray[np.float_]) -> npt.NDArray[np.bool_]:\n",
        "            rejected: npt.NDArray[np.bool_] = multipletests(a, alpha=self.alpha, method=\"fdr_bh\")[0]\n",
        "            return rejected\n",
        "\n",
        "        for num_true_alt in range(1, len(metrics) + 1):\n",
        "            true_alt = np.array([random_state.permutation(len(metrics)) < num_true_alt for _ in range(replication)]).T\n",
        "            p_values = []\n",
        "            for i, m in enumerate(metrics):\n",
        "                p_values.append(m.generate_p_values(true_alt[i], sample_size, random_state))\n",
        "\n",
        "            rejected = np.apply_along_axis(fdr_bh, 0, np.array(p_values))  # type: ignore[no-untyped-call]\n",
        "\n",
        "            true_discoveries = rejected & true_alt\n",
        "\n",
        "            true_discovery_count += true_discoveries.sum()\n",
        "            true_alt_count += true_alt.sum()\n",
        "\n",
        "        avg_power = true_discovery_count / true_alt_count\n",
        "\n",
        "        return avg_power"
      ],
      "metadata": {
        "id": "kcOgr70XMPQH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_schema_json_file = open('metrics_schema.json', 'w')\n",
        "\n",
        "metrics_schema_json = '''\n",
        "{\n",
        "    \"type\": \"array\",\n",
        "    \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"metric_type\": {\n",
        "                \"type\": \"string\",\n",
        "                \"enum\": [\"boolean\", \"numeric\", \"ratio\"]\n",
        "            }\n",
        "        },\n",
        "        \"allOf\": [\n",
        "            {\n",
        "                \"if\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_type\": {\"const\": \"boolean\"}\n",
        "                    }\n",
        "                },\n",
        "                \"then\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_metadata\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"alternative\": {\"type\": \"string\"},\n",
        "                                \"mde\": {\"type\": \"number\"},\n",
        "                                \"probability\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\"mde\", \"probability\"]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"if\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_type\": {\"const\": \"numeric\"}\n",
        "                    }\n",
        "                },\n",
        "                \"then\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_metadata\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"alternative\": {\"type\": \"string\"},\n",
        "                                \"mde\": {\"type\": \"number\"},\n",
        "                                \"variance\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\"mde\", \"variance\"]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"if\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_type\": {\"const\": \"ratio\"}\n",
        "                    }\n",
        "                },\n",
        "                \"then\": {\n",
        "                    \"properties\": {\n",
        "                        \"metric_metadata\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"alternative\": {\"type\": \"string\"},\n",
        "                                \"mde\": {\"type\": \"number\"},\n",
        "                                \"numerator_mean\": {\"type\": \"number\"},\n",
        "                                \"numerator_variance\": {\"type\": \"number\"},\n",
        "                                \"denominator_mean\": {\"type\": \"number\"},\n",
        "                                \"denominator_variance\": {\"type\": \"number\"},\n",
        "                                \"covariance\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\n",
        "                                \"mde\",\n",
        "                                \"numerator_mean\",\n",
        "                                \"numerator_variance\",\n",
        "                                \"denominator_mean\",\n",
        "                                \"denominator_variance\",\n",
        "                                \"covariance\"\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"required\": [\"metric_type\", \"metric_metadata\"]\n",
        "    },\n",
        "    \"minItems\": 1\n",
        "}\n",
        "'''\n",
        "\n",
        "metrics_schema_json_file.write(metrics_schema_json)\n",
        "\n",
        "metrics_schema_json_file.close()"
      ],
      "metadata": {
        "id": "e3fdQXT4MUE-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from jsonschema import validate\n",
        "\n",
        "#from sample_size.metrics import BaseMetric\n",
        "#from sample_size.metrics import BooleanMetric\n",
        "#from sample_size.metrics import NumericMetric\n",
        "#from sample_size.metrics import RatioMetric\n",
        "#from sample_size.multiple_testing import MultipleTestingMixin\n",
        "\n",
        "DEFAULT_ALPHA = 0.05\n",
        "DEFAULT_POWER = 0.8\n",
        "DEFAULT_VARIANTS = 2\n",
        "RANDOM_STATE = np.random.RandomState(1)\n",
        "STATE = RANDOM_STATE.get_state()\n",
        "\n",
        "schema_file_path = Path(\"metrics_schema.json\")\n",
        "#schema_file_path = Path(Path(__file__).parent, \"metrics_schema.json\")\n",
        "with open(str(schema_file_path), \"r\") as schema_file:\n",
        "    METRICS_SCHEMA = json.load(schema_file)\n",
        "\n",
        "\n",
        "class SampleSizeCalculator(MultipleTestingMixin):\n",
        "    \"\"\"\n",
        "    This class is to calculate sample size based on metric type\n",
        "\n",
        "    Attributes:\n",
        "    alpha: statistical significance\n",
        "    power: statistical power\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha: float = DEFAULT_ALPHA, variants: int = DEFAULT_VARIANTS, power: float = DEFAULT_POWER):\n",
        "        self.alpha = alpha\n",
        "        self.power = power\n",
        "        self.metrics: List[BaseMetric] = []\n",
        "        self.variants: int = variants\n",
        "\n",
        "    def _get_single_sample_size(self, metric: BaseMetric, alpha: float) -> float:\n",
        "        effect_size = metric.mde / float(np.sqrt(metric.variance))\n",
        "        power_analysis = metric.power_analysis_instance\n",
        "        sample_size = int(\n",
        "            power_analysis.solve_power(\n",
        "                effect_size=effect_size,\n",
        "                alpha=alpha,\n",
        "                power=self.power,\n",
        "                ratio=1,\n",
        "                alternative=metric.alternative,\n",
        "            )\n",
        "        )\n",
        "        return sample_size\n",
        "\n",
        "    def get_sample_size(self) -> float:\n",
        "        if len(self.metrics) * (self.variants - 1) < 2:\n",
        "            return self._get_single_sample_size(self.metrics[0], self.alpha)\n",
        "\n",
        "        num_tests = len(self.metrics) * (self.variants - 1)\n",
        "        lower = min([self._get_single_sample_size(metric, self.alpha) for metric in self.metrics])\n",
        "        upper = max([self._get_single_sample_size(metric, self.alpha / num_tests) for metric in self.metrics])\n",
        "\n",
        "        RANDOM_STATE.set_state(STATE)\n",
        "        return self.get_multiple_sample_size(lower, upper, RANDOM_STATE)\n",
        "\n",
        "    def register_metrics(self, metrics: List[Dict[str, Any]]) -> None:\n",
        "        METRIC_REGISTER_MAP = {\n",
        "            \"boolean\": BooleanMetric,\n",
        "            \"numeric\": NumericMetric,\n",
        "            \"ratio\": RatioMetric,\n",
        "        }\n",
        "\n",
        "        validate(instance=metrics, schema=METRICS_SCHEMA)\n",
        "\n",
        "        for metric in metrics:\n",
        "            metric_class = METRIC_REGISTER_MAP[metric[\"metric_type\"]]\n",
        "            registered_metric = metric_class(**metric[\"metric_metadata\"])\n",
        "            self.metrics.append(registered_metric)"
      ],
      "metadata": {
        "id": "JaSZU0jmLgk_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install parameterized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B758kTsKO8xy",
        "outputId": "6af02e3f-3c21-40dd-ffe1-6f796229e89a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from itertools import combinations_with_replacement as combos\n",
        "from itertools import product\n",
        "from unittest.mock import MagicMock\n",
        "from unittest.mock import patch\n",
        "\n",
        "import numpy as np\n",
        "from numpy.testing import assert_array_equal\n",
        "from parameterized import parameterized\n",
        "from statsmodels.stats.power import NormalIndPower\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "#from sample_size.metrics import BaseMetric\n",
        "#from sample_size.metrics import BooleanMetric\n",
        "#from sample_size.metrics import NumericMetric\n",
        "#from sample_size.metrics import RatioMetric\n",
        "#from sample_size.sample_size_calculator import RANDOM_STATE\n",
        "\n",
        "ALTERNATIVE = \"two-sided\"\n",
        "TEST_ALTERNATIVES = (\"two-sided\", \"smaller\", \"larger\")\n",
        "\n",
        "\n",
        "class DummyMetric(BaseMetric):\n",
        "    def power_analysis_instance(self):\n",
        "        return MagicMock()\n",
        "\n",
        "    def variance(self):\n",
        "        return MagicMock()\n",
        "\n",
        "    def _generate_alt_p_values(self, size, sample_size, RANDOM_STATE):\n",
        "        return MagicMock()\n",
        "\n",
        "\n",
        "class BaseMetricTestCase(unittest.TestCase):\n",
        "    def test_check_positive(self):\n",
        "        test_negative_number = -10\n",
        "        test_name = \"test\"\n",
        "\n",
        "        with self.assertRaises(Exception) as context:\n",
        "            BaseMetric.check_positive(test_negative_number, test_name)\n",
        "\n",
        "        self.assertEqual(\n",
        "            str(context.exception),\n",
        "            f\"Error: Please provide a positive number for {test_name}.\",\n",
        "        )\n",
        "\n",
        "    @parameterized.expand([(np.array(c),) for r in range(2, 5) for c in combos([True, False], r)])\n",
        "    @patch(\"sample_size.metrics.stats\")\n",
        "    @patch(\"tests.sample_size.test_metrics.DummyMetric._generate_alt_p_values\")\n",
        "    def test_generate_p_values(self, true_alt, mock_alt_p_values, mock_stats):\n",
        "        mde = 0.5\n",
        "        sample_size = 10\n",
        "\n",
        "        null_p_value = 1\n",
        "        alt_p_value = 0\n",
        "\n",
        "        mock_alt_p_values.side_effect = lambda size, __, random_state: np.array([alt_p_value] * size)\n",
        "        mock_stats.uniform.rvs.side_effect = lambda _, __, size, random_state: np.array([null_p_value] * size)\n",
        "\n",
        "        metric = DummyMetric(mde, ALTERNATIVE)\n",
        "\n",
        "        p_values = metric.generate_p_values(true_alt, sample_size, RANDOM_STATE)\n",
        "\n",
        "        mock_alt_p_values.assert_called_once()\n",
        "        mock_stats.uniform.rvs.assert_called_once()\n",
        "\n",
        "        assert_array_equal(p_values, np.where(true_alt, alt_p_value, null_p_value))\n",
        "\n",
        "\n",
        "class BooleanMetricTestCase(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.DEFAULT_ALTERNATIVE = ALTERNATIVE\n",
        "        self.DEFAULT_MDE = 0.01\n",
        "        self.DEFAULT_PROBABILITY = 0.05\n",
        "        self.DEFAULT_MOCK_VARIANCE = 99\n",
        "\n",
        "    @patch(\"sample_size.metrics.BooleanMetric._check_probability\")\n",
        "    @patch(\"sample_size.metrics.BooleanMetric.variance\")\n",
        "    def test_boolean_metric_constructor_sets_params(self, mock_variance, mock_check_probability):\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_MOCK_VARIANCE)\n",
        "        mock_check_probability.return_value = self.DEFAULT_PROBABILITY\n",
        "        boolean = BooleanMetric(self.DEFAULT_PROBABILITY, self.DEFAULT_MDE, self.DEFAULT_ALTERNATIVE)\n",
        "\n",
        "        mock_check_probability.assert_called_once_with(self.DEFAULT_PROBABILITY)\n",
        "        self.assertEqual(boolean.probability, self.DEFAULT_PROBABILITY)\n",
        "        self.assertEqual(boolean.variance, self.DEFAULT_MOCK_VARIANCE)\n",
        "        self.assertEqual(boolean.mde, self.DEFAULT_MDE)\n",
        "        self.assertIsInstance(boolean.power_analysis_instance, NormalIndPower)\n",
        "\n",
        "    def test_boolean_metric_variance(self):\n",
        "        boolean = BooleanMetric(self.DEFAULT_PROBABILITY, self.DEFAULT_MDE, self.DEFAULT_ALTERNATIVE)\n",
        "\n",
        "        self.assertEqual(boolean.variance, 0.0475)\n",
        "\n",
        "    def test_boolean_metric_get_probability(self):\n",
        "        probability = BooleanMetric._check_probability(self.DEFAULT_PROBABILITY)\n",
        "\n",
        "        self.assertEqual(probability, self.DEFAULT_PROBABILITY)\n",
        "\n",
        "    def test_boolean_metric_get_probability_too_large(self):\n",
        "        test_probability = 5\n",
        "\n",
        "        with self.assertRaises(Exception) as context:\n",
        "            BooleanMetric._check_probability(test_probability)\n",
        "\n",
        "        self.assertEqual(\n",
        "            str(context.exception),\n",
        "            \"Error: Please provide a float between 0 and 1 for probability.\",\n",
        "        )\n",
        "\n",
        "    def test_boolean_metric_get_probability_too_small(self):\n",
        "        test_probability = -0.1\n",
        "\n",
        "        with self.assertRaises(Exception) as context:\n",
        "            BooleanMetric._check_probability(test_probability)\n",
        "\n",
        "        self.assertEqual(\n",
        "            str(context.exception),\n",
        "            \"Error: Please provide a float between 0 and 1 for probability.\",\n",
        "        )\n",
        "\n",
        "    @parameterized.expand(product((1, 2, 10), (2, 10), TEST_ALTERNATIVES))\n",
        "    @patch(\"sample_size.metrics.BooleanMetric.variance\")\n",
        "    @patch(\"scipy.stats.norm\")\n",
        "    def test_boolean__generate_alt_p_values(self, size, sample_size, alternative, mock_norm, mock_variance):\n",
        "        p_value_generator = mock_norm.sf\n",
        "        p_values = MagicMock()\n",
        "        mock_norm.rvs.return_value = -ord(\"🌮\")\n",
        "        p_value_generator.return_value = p_values\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_MOCK_VARIANCE)\n",
        "\n",
        "        metric = BooleanMetric(self.DEFAULT_PROBABILITY, self.DEFAULT_MDE, alternative)\n",
        "        p = metric._generate_alt_p_values(size, sample_size, RANDOM_STATE)\n",
        "\n",
        "        effect_sample_size = self.DEFAULT_MDE / np.sqrt(2 * self.DEFAULT_MOCK_VARIANCE / sample_size)\n",
        "        mock_norm.rvs.assert_called_once_with(loc=effect_sample_size, size=size, random_state=RANDOM_STATE)\n",
        "        mock_norm.sf.assert_called_once_with(np.abs(mock_norm.rvs.return_value))\n",
        "        expected_p_values = p_values if alternative != \"two-sided\" else 2 * p_values\n",
        "        assert_array_equal(p, expected_p_values)\n",
        "\n",
        "\n",
        "class NumericMetricTestCase(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.DEFAULT_MDE = 5\n",
        "        self.DEFAULT_VARIANCE = 5000\n",
        "        self.DEFAULT_ALTERNATIVE = ALTERNATIVE\n",
        "\n",
        "    def test_numeric_metric_constructor_sets_params(self):\n",
        "        numeric = NumericMetric(self.DEFAULT_VARIANCE, self.DEFAULT_MDE, self.DEFAULT_ALTERNATIVE)\n",
        "\n",
        "        self.assertEqual(numeric.variance, self.DEFAULT_VARIANCE)\n",
        "        self.assertEqual(numeric.mde, self.DEFAULT_MDE)\n",
        "        self.assertEqual(numeric.alternative, self.DEFAULT_ALTERNATIVE)\n",
        "        self.assertIsInstance(numeric.power_analysis_instance, TTestIndPower)\n",
        "\n",
        "    @parameterized.expand(product((1, 2, 10), (2, 10), TEST_ALTERNATIVES))\n",
        "    @patch(\"sample_size.metrics.NumericMetric.variance\")\n",
        "    @patch(\"scipy.stats.nct\")\n",
        "    @patch(\"scipy.stats.t\")\n",
        "    def test_numeric__generate_alt_p_values(self, size, sample_size, alternative, mock_t, mock_nct, mock_variance):\n",
        "        p_value_generator = mock_t.sf\n",
        "        p_values = MagicMock()\n",
        "        mock_nct.rvs.return_value = -ord(\"🌮\")\n",
        "        p_value_generator.return_value = p_values\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_VARIANCE)\n",
        "\n",
        "        metric = NumericMetric(self.DEFAULT_VARIANCE, self.DEFAULT_MDE, alternative)\n",
        "        p = metric._generate_alt_p_values(size, sample_size, RANDOM_STATE)\n",
        "\n",
        "        effect_sample_size = np.sqrt(sample_size / 2 / self.DEFAULT_VARIANCE) * self.DEFAULT_MDE\n",
        "        df = 2 * (sample_size - 1)\n",
        "        mock_nct.rvs.assert_called_once_with(nc=effect_sample_size, df=df, size=size, random_state=RANDOM_STATE)\n",
        "        mock_t.sf.assert_called_once_with(np.abs(mock_nct.rvs.return_value), df)\n",
        "        expected_p_values = p_values if alternative != \"two-sided\" else 2 * p_values\n",
        "        assert_array_equal(p, expected_p_values)\n",
        "\n",
        "\n",
        "class RatioMetricTestCase(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.DEFAULT_MDE = 5\n",
        "        self.DEFAULT_NUMERATOR_MEAN = 2000\n",
        "        self.DEFAULT_NUMERATOR_VARIANCE = 100000\n",
        "        self.DEFAULT_DENOMINATOR_MEAN = 200\n",
        "        self.DEFAULT_DENOMINATOR_VARIANCE = 2000\n",
        "        self.DEFAULT_COVARIANCE = 5000\n",
        "        self.DEFAULT_VARIANCE = 99\n",
        "        self.DEFAULT_ALTERNATIVE = ALTERNATIVE\n",
        "\n",
        "    @patch(\"sample_size.metrics.RatioMetric.variance\")\n",
        "    def test_ratio_metric_constructor_sets_params(self, mock_variance):\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_VARIANCE)\n",
        "        ratio = RatioMetric(\n",
        "            self.DEFAULT_NUMERATOR_MEAN,\n",
        "            self.DEFAULT_NUMERATOR_VARIANCE,\n",
        "            self.DEFAULT_DENOMINATOR_MEAN,\n",
        "            self.DEFAULT_DENOMINATOR_VARIANCE,\n",
        "            self.DEFAULT_COVARIANCE,\n",
        "            self.DEFAULT_MDE,\n",
        "            self.DEFAULT_ALTERNATIVE,\n",
        "        )\n",
        "\n",
        "        self.assertEqual(ratio.numerator_mean, self.DEFAULT_NUMERATOR_MEAN)\n",
        "        self.assertEqual(ratio.numerator_variance, self.DEFAULT_NUMERATOR_VARIANCE)\n",
        "        self.assertEqual(ratio.denominator_mean, self.DEFAULT_DENOMINATOR_MEAN)\n",
        "        self.assertEqual(ratio.denominator_variance, self.DEFAULT_DENOMINATOR_VARIANCE)\n",
        "        self.assertEqual(ratio.covariance, self.DEFAULT_COVARIANCE)\n",
        "        self.assertEqual(ratio.variance, self.DEFAULT_VARIANCE)\n",
        "        self.assertEqual(ratio.mde, self.DEFAULT_MDE)\n",
        "        self.assertIsInstance(ratio.power_analysis_instance, NormalIndPower)\n",
        "\n",
        "    def test_ratio_metric_variance(self):\n",
        "        ratio = RatioMetric(\n",
        "            self.DEFAULT_NUMERATOR_MEAN,\n",
        "            self.DEFAULT_NUMERATOR_VARIANCE,\n",
        "            self.DEFAULT_DENOMINATOR_MEAN,\n",
        "            self.DEFAULT_DENOMINATOR_VARIANCE,\n",
        "            self.DEFAULT_COVARIANCE,\n",
        "            self.DEFAULT_MDE,\n",
        "            self.DEFAULT_ALTERNATIVE,\n",
        "        )\n",
        "\n",
        "        self.assertEqual(ratio.variance, 5.0)\n",
        "\n",
        "    @parameterized.expand(product((1, 2, 10), (2, 10), TEST_ALTERNATIVES))\n",
        "    @patch(\"sample_size.metrics.RatioMetric.variance\")\n",
        "    @patch(\"scipy.stats.norm\")\n",
        "    def test_ratio__generate_alt_p_values(self, size, sample_size, alternative, mock_norm, mock_variance):\n",
        "        p_value_generator = mock_norm.sf\n",
        "        p_values = MagicMock()\n",
        "        mock_norm.rvs.return_value = -ord(\"🌮\")\n",
        "        p_value_generator.return_value = p_values\n",
        "        mock_variance.__get__ = MagicMock(return_value=self.DEFAULT_VARIANCE)\n",
        "\n",
        "        metric = RatioMetric(\n",
        "            self.DEFAULT_NUMERATOR_MEAN,\n",
        "            self.DEFAULT_NUMERATOR_VARIANCE,\n",
        "            self.DEFAULT_DENOMINATOR_MEAN,\n",
        "            self.DEFAULT_DENOMINATOR_VARIANCE,\n",
        "            self.DEFAULT_COVARIANCE,\n",
        "            self.DEFAULT_MDE,\n",
        "            self.DEFAULT_ALTERNATIVE,\n",
        "        )\n",
        "\n",
        "        p = metric._generate_alt_p_values(size, sample_size, RANDOM_STATE)\n",
        "\n",
        "        effect_sample_size = self.DEFAULT_MDE / np.sqrt(2 * self.DEFAULT_VARIANCE / sample_size)\n",
        "        mock_norm.rvs.assert_called_once_with(loc=effect_sample_size, size=size, random_state=RANDOM_STATE)\n",
        "        mock_norm.sf.assert_called_once_with(np.abs(mock_norm.rvs.return_value))\n",
        "        expected_p_values = p_values if alternative != \"two-sided\" else 2 * p_values\n",
        "        assert_array_equal(p, expected_p_values)"
      ],
      "metadata": {
        "id": "ftfDu7rKPRMe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from unittest.mock import call\n",
        "from unittest.mock import patch\n",
        "\n",
        "from parameterized import parameterized\n",
        "\n",
        "#from sample_size.metrics import BooleanMetric\n",
        "#from sample_size.metrics import NumericMetric\n",
        "#from sample_size.metrics import RatioMetric\n",
        "#from sample_size.sample_size_calculator import DEFAULT_ALPHA\n",
        "#from sample_size.sample_size_calculator import DEFAULT_POWER\n",
        "#from sample_size.sample_size_calculator import DEFAULT_VARIANTS\n",
        "#from sample_size.sample_size_calculator import RANDOM_STATE\n",
        "#from sample_size.sample_size_calculator import SampleSizeCalculator\n",
        "#from tests.sample_size.test_metrics import ALTERNATIVE\n",
        "\n",
        "\n",
        "class SampleSizeCalculatorTestCase(unittest.TestCase):\n",
        "    def test_sample_size_calculator_constructor_sets_params(self):\n",
        "        test_alpha = 0.1\n",
        "        test_variants = 2\n",
        "        test_power = 0.9\n",
        "        calculator = SampleSizeCalculator(\n",
        "            test_alpha,\n",
        "            test_variants,\n",
        "            test_power,\n",
        "        )\n",
        "\n",
        "        self.assertEqual(calculator.alpha, test_alpha)\n",
        "        self.assertEqual(calculator.power, test_power)\n",
        "        self.assertEqual(calculator.metrics, [])\n",
        "\n",
        "    def test_sample_size_calculator_constructor_sets_params_with_default_params(self):\n",
        "        calculator = SampleSizeCalculator()\n",
        "\n",
        "        self.assertEqual(calculator.alpha, DEFAULT_ALPHA)\n",
        "        self.assertEqual(calculator.variants, DEFAULT_VARIANTS)\n",
        "        self.assertEqual(calculator.power, DEFAULT_POWER)\n",
        "        self.assertEqual(calculator.metrics, [])\n",
        "\n",
        "    @patch(\"statsmodels.stats.power.NormalIndPower.solve_power\")\n",
        "    def test_get_single_sample_size_normal(self, mock_solve_power):\n",
        "        test_probability = 0.05\n",
        "        test_mde = 0.02\n",
        "        test_sample_size = 2000\n",
        "        test_metric = BooleanMetric(\n",
        "            test_probability,\n",
        "            test_mde,\n",
        "            ALTERNATIVE,\n",
        "        )\n",
        "        mock_solve_power.return_value = test_sample_size\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        sample_size = calculator._get_single_sample_size(test_metric, calculator.alpha)\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        mock_solve_power.assert_called_once_with(\n",
        "            effect_size=0.09176629354822471,\n",
        "            alpha=DEFAULT_ALPHA,\n",
        "            power=DEFAULT_POWER,\n",
        "            ratio=1,\n",
        "            alternative=\"two-sided\",\n",
        "        )\n",
        "\n",
        "    @patch(\"statsmodels.stats.power.TTestIndPower.solve_power\")\n",
        "    def test_get_single_sample_size_ttest(self, mock_solve_power):\n",
        "        test_variance = 1000\n",
        "        test_mde = 5\n",
        "        test_sample_size = 2000\n",
        "        test_metric = NumericMetric(\n",
        "            test_variance,\n",
        "            test_mde,\n",
        "            ALTERNATIVE,\n",
        "        )\n",
        "        mock_solve_power.return_value = test_sample_size\n",
        "        calculator = SampleSizeCalculator()\n",
        "\n",
        "        sample_size = calculator._get_single_sample_size(test_metric, calculator.alpha)\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        mock_solve_power.assert_called_once_with(\n",
        "            effect_size=0.15811388300841897,\n",
        "            alpha=DEFAULT_ALPHA,\n",
        "            power=DEFAULT_POWER,\n",
        "            ratio=1,\n",
        "            alternative=\"two-sided\",\n",
        "        )\n",
        "\n",
        "    @parameterized.expand(\n",
        "        [\n",
        "            (\"boolean\", {\"probability\": 0.05, \"mde\": 0.02, \"alternative\": \"two-sided\"}),\n",
        "            (\"numeric\", {\"variance\": 500, \"mde\": 5, \"alternative\": \"smaller\"}),\n",
        "            (\n",
        "                \"ratio\",\n",
        "                {\n",
        "                    \"numerator_mean\": 2000,\n",
        "                    \"numerator_variance\": 100000,\n",
        "                    \"denominator_mean\": 200,\n",
        "                    \"denominator_variance\": 2000,\n",
        "                    \"covariance\": 5000,\n",
        "                    \"mde\": 10,\n",
        "                    \"alternative\": \"larger\",\n",
        "                },\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator.get_multiple_sample_size\")\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator._get_single_sample_size\")\n",
        "    def test_get_sample_size_single(\n",
        "        self, metric_type, metadata, mock_get_single_sample_size, mock_get_multiple_sample_size\n",
        "    ):\n",
        "        test_metric_type = metric_type\n",
        "        test_sample_size = 2000\n",
        "        mock_get_single_sample_size.return_value = test_sample_size\n",
        "\n",
        "        test_mde = metadata[\"mde\"]\n",
        "        test_metric_metadata = metadata\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "\n",
        "        sample_size = calculator.get_sample_size()\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        mock_get_multiple_sample_size.assert_not_called()\n",
        "        mock_get_single_sample_size.assert_called_once()\n",
        "        self.assertEqual(mock_get_single_sample_size.call_args[0][0], calculator.metrics[0])\n",
        "        self.assertEqual(mock_get_single_sample_size.call_args[0][0].mde, test_mde)\n",
        "\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator.get_multiple_sample_size\")\n",
        "    @patch(\"sample_size.sample_size_calculator.SampleSizeCalculator._get_single_sample_size\")\n",
        "    def test_get_sample_size_multiple(self, mock_get_single_sample_size, mock_get_multiple_sample_size):\n",
        "        test_metric_type = \"boolean\"\n",
        "        test_sample_size = 2000\n",
        "        mock_get_multiple_sample_size.return_value = test_sample_size\n",
        "        mock_get_single_sample_size.return_value = test_sample_size\n",
        "        test_metric_metadata = {\"probability\": 0.05, \"mde\": 0.02, \"alternative\": ALTERNATIVE}\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics(\n",
        "            [\n",
        "                {\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata},\n",
        "                {\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata},\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        sample_size = calculator.get_sample_size()\n",
        "\n",
        "        self.assertEqual(sample_size, test_sample_size)\n",
        "        self.assertEqual(mock_get_single_sample_size.call_count, 4)\n",
        "        mock_get_single_sample_size.assert_has_calls(\n",
        "            [\n",
        "                call(calculator.metrics[0], calculator.alpha),\n",
        "                call(calculator.metrics[1], calculator.alpha),\n",
        "                call(calculator.metrics[0], calculator.alpha / 2),\n",
        "                call(calculator.metrics[1], calculator.alpha / 2),\n",
        "            ]\n",
        "        )\n",
        "        mock_get_multiple_sample_size.assert_called_once_with(test_sample_size, test_sample_size, RANDOM_STATE)\n",
        "\n",
        "    # TODO: parameterize register metric functions\n",
        "    def test_register_metric_boolean(self):\n",
        "        test_metric_type = \"boolean\"\n",
        "        test_probability = 0.05\n",
        "        test_mde = 0.02\n",
        "        test_metric_metadata = {\"probability\": test_probability, \"mde\": test_mde, \"alternative\": \"larger\"}\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertIsInstance(calculator.metrics[0], BooleanMetric)\n",
        "        self.assertEqual(len(calculator.metrics), 1)\n",
        "        self.assertEqual(calculator.metrics[0].variance, 0.0475)\n",
        "        self.assertEqual(calculator.metrics[0].mde, test_mde)\n",
        "\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertEqual(len(calculator.metrics), 2)\n",
        "\n",
        "    def test_register_metric_numeric(self):\n",
        "        test_metric_type = \"numeric\"\n",
        "        test_variance = 5000.0\n",
        "        test_mde = 5.0\n",
        "        test_metric_metadata = {\"variance\": test_variance, \"mde\": test_mde, \"alternative\": \"two-sided\"}\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertIsInstance(calculator.metrics[0], NumericMetric)\n",
        "        self.assertEqual(len(calculator.metrics), 1)\n",
        "        self.assertEqual(calculator.metrics[0].variance, test_variance)\n",
        "        self.assertEqual(calculator.metrics[0].mde, test_mde)\n",
        "\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertEqual(len(calculator.metrics), 2)\n",
        "\n",
        "    def test_register_metric_ratio(self):\n",
        "        test_metric_type = \"ratio\"\n",
        "        test_numerator_mean = 2000.0\n",
        "        test_numerator_variance = 100000.0\n",
        "        test_denominator_mean = 200.0\n",
        "        test_denominator_variance = 2000.0\n",
        "        test_covariance = 5000.0\n",
        "        test_mde = 5.0\n",
        "        test_variance = 5\n",
        "        test_metric_metadata = {\n",
        "            \"numerator_mean\": test_numerator_mean,\n",
        "            \"numerator_variance\": test_numerator_variance,\n",
        "            \"denominator_mean\": test_denominator_mean,\n",
        "            \"denominator_variance\": test_denominator_variance,\n",
        "            \"covariance\": test_covariance,\n",
        "            \"mde\": test_mde,\n",
        "            \"alternative\": \"smaller\",\n",
        "        }\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertIsInstance(calculator.metrics[0], RatioMetric)\n",
        "        self.assertEqual(len(calculator.metrics), 1)\n",
        "        self.assertEqual(calculator.metrics[0].variance, test_variance)\n",
        "        self.assertEqual(calculator.metrics[0].mde, test_mde)\n",
        "\n",
        "        calculator.register_metrics([{\"metric_type\": test_metric_type, \"metric_metadata\": test_metric_metadata}])\n",
        "        self.assertEqual(len(calculator.metrics), 2)\n",
        "\n",
        "    def test_register_metric_invalid_metadata(self):\n",
        "        test_metric_type = \"numeric\"\n",
        "\n",
        "        calculator = SampleSizeCalculator()\n",
        "        with self.assertRaises(Exception):\n",
        "            calculator.register_metrics([{\"metric_type\": test_metric_type}])"
      ],
      "metadata": {
        "id": "DonfBRY2NVRN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tester = SampleSizeCalculatorTestCase()\n",
        "tester.test_sample_size_calculator_constructor_sets_params()"
      ],
      "metadata": {
        "id": "Lstha0CFPaqz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Baseline Conversion Rate\n",
        "\n",
        "Your control group's expected conversion rate.\n",
        "\n",
        "\n",
        "\n",
        "> Minimum Detectable Effect\n",
        "\n",
        "The minimum relative change in conversion rate you would like to be able to detect.\n",
        "\n",
        "\n",
        "> Statistical Significance\n",
        "\n",
        "95% is an accepted standard for statistical significance, although Optimizely allows you to set your own threshold for significance based on your risk tolerance.\n",
        "\n"
      ],
      "metadata": {
        "id": "RxUbnxh9SgfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "第一类错误：原假设为真的时候，拒绝原假设的概率。\n",
        "\n",
        "α：假设AB没有差异时，观察到有差异的概率\n",
        "\n",
        "> Significance level α\n",
        "\n",
        "Percent of the time a difference will be detected, assuming one does NOT exist\n",
        "\n",
        "\n",
        "第二类错误：原假设为假的时候，接受原假设的概率。\n",
        "\n",
        "β：假设AB有差异时，观察到没有差异的概率\n",
        "\n",
        "> Statistical power 1−β\n",
        "\n",
        "Percent of the time the minimum effect size will be detected, assuming it exists\n",
        "\n"
      ],
      "metadata": {
        "id": "yCldNciVTDhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evan's Awesome A/B Tools:\n",
        "\n",
        "## Sample Size Calculator\n",
        "\n",
        "### Question: How many subjects are needed for an A/B test?\n",
        "\n",
        "Baseline conversion rate\n",
        "\n",
        "\n",
        "Minimum Detectable Effect:\n",
        "The Minimum Detectable Effect is the smallest effect that will be detected (1-β)% of the time.\n",
        "\n",
        "\n",
        "Statistical power 1−β:\n",
        "Percent of the time the minimum effect size will be detected, assuming it exists.\n",
        "\n",
        "Significance level α:\n",
        "Percent of the time a difference will be detected, assuming one does NOT exist.\n"
      ],
      "metadata": {
        "id": "zP2V_U-5ZOPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "def compute_sample_size(p0, mde, alpha=0.05, beta=0.2, tails=\"Two\"):\n",
        "    \"\"\"\n",
        "    Returns the sample size for a two-tailed AB test comparing conversion\n",
        "    rates.\n",
        "\n",
        "    The sample size equation is for binomial distributions only.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    p0 : float\n",
        "        Baseline conversion rate\n",
        "\n",
        "    mde : float or int\n",
        "        Minimum detectable effect. This is the 'sensitivity' of the test or\n",
        "        the relative difference in conversion rates that you want to be able\n",
        "        to detect.\n",
        "\n",
        "    alpha : float\n",
        "        The chances of a Type I error. Tests are normally run to a 95%\n",
        "        significance meaning an alpha of 1 - 0.95 = 0.05. Default = 0.05.\n",
        "\n",
        "    beta : float\n",
        "        The chances of a Type II error. For sample sizing, a beta of 0.2 is\n",
        "        acceptable and provides the test with 80% statistical power as is\n",
        "        standard.\n",
        "\n",
        "    tails : str\n",
        "        One or two tails to specify what type of hypothesis test this is.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Minimum number of observations required per variant.\n",
        "    \"\"\"\n",
        "\n",
        "    # Conditional alpha value based on whether one or two tail test\n",
        "    if tails == \"Two\":\n",
        "        computed_alpha = alpha / 2\n",
        "    else:\n",
        "        computed_alpha = alpha\n",
        "\n",
        "    p1 = p0 * (1 + mde)\n",
        "    N = (\n",
        "        (norm.ppf(1 - computed_alpha) + norm.ppf(1 - beta)) ** 2\n",
        "        * (p0 * (1 - p0) + p1 * (1 - p1))\n",
        "        / ((p0 - p1) ** 2)\n",
        "    )\n",
        "    return int(N)"
      ],
      "metadata": {
        "id": "SeUQA_DBS56Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_sample_size(0.89, 0.0011, 0.05, 0.2, \"Two\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMvi6xOjWo6B",
        "outputId": "d70fa45c-f06a-4878-98e1-3e0311ca27ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1597187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_sample_size(0.89, 0.0011, 0.05, 0.2, \"One\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVgrElanYSKV",
        "outputId": "5eab0757-bbf4-492c-a44d-ab9cdabd3c58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1258103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-Squared Test\n",
        "\n",
        "### Question: Does the rate of success differ across two groups?\n",
        "\n",
        "If the experiment is repeated many times, the confidence level is the percent of the time each sample's success rate will fall within the reported confidence interval.\n",
        "\n",
        "It is also the percent of the time no difference will be detected between the two groups, assuming no difference exists."
      ],
      "metadata": {
        "id": "1icuuzPZaTCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest as ztest\n",
        "import numpy as np\n",
        "\n",
        "ztest(count=np.array([3000,3200]), nobs=np.array([10000,10000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_yJ5VtygPwH",
        "outputId": "1039d053-2d49-47ec-adad-6cb5da6c2a75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.057803726183795, 0.0022296556161908814)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "对照组：参与人数 10000，转化人数 3000\n",
        "\n",
        "实验组：参与人数 10000，转化人数 3200\n",
        "\n",
        "显著性水平：0.05\n",
        "\n",
        "\n",
        "第1个值为z分数，第2个值为p值。\n",
        "p值<0.05，从而可知两组存在显著差异，实验结果提升是显著的。\n"
      ],
      "metadata": {
        "id": "OusCmZ40gzoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([3200,3000]), nobs=np.array([10000,10000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENx66XHaiy0J",
        "outputId": "030a75f9-c2cc-4a88-b7f2-8332e772a2cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.057803726183795, 0.0022296556161908814)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([320,3000]), nobs=np.array([1000,10000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG7sirwMi5MK",
        "outputId": "d6cf202d-65e7-4f84-9143-5e8d3d53f2f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.3136409747118007, 0.18896705292826543)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([125810*(0.89-0.0011),1258103*0.89]), nobs=np.array([125810,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwCKaXxWhAJQ",
        "outputId": "6448e828-2e4e-4dd7-8588-d564a77ad939"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.1884740633049435, 0.23464669236156277)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([1258103*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5H6awyTiGt6",
        "outputId": "3368acb2-1917-4882-f52d-c6786ddd7e1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-2.782246745764699, 0.005398397957847781)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([2000000*(0.89-0.0011),2000000*0.89]), nobs=np.array([2000000,2000000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNytFl5Eic5G",
        "outputId": "1c3dd5f7-2f54-456d-8241-d366b8588ce4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.5079431131165877, 0.0004515856033560191)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=1\n",
        "z,p = ztest(count=np.array([1258103*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103,1258103]))\n",
        "while p<=0.05:\n",
        "  r=r-0.1\n",
        "  z,p = ztest(count=np.array([1258103*r*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103*r,1258103]))\n",
        "\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iluIn-7LkJVO",
        "outputId": "76d8d3be-9b7a-428c-d903-ee28ecc47d0c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30000000000000016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([1258103*0.4*(0.89-0.0011),1258103*0.89]), nobs=np.array([1258103*0.4,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlRzpZ38kt5x",
        "outputId": "74de4e65-605c-4ec3-84d5-d0c20a4b2709"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-2.105147713673478, 0.035278451987355554)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ztest(count=np.array([1258103*0.1*(0.89-0.01),1258103*0.89]), nobs=np.array([1258103*0.1,1258103]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhWNEoN8k8zn",
        "outputId": "c69bd4c6-56c3-4257-dcac-5f08e021e20d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-10.76973702446419, 4.783655666578137e-27)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Sampling\n",
        "\n",
        "### Question: How many conversions are needed for a sequential A/B test?\n",
        "\n",
        "\n",
        "\n",
        "序贯抽样方案是指在抽样时，不事先规定总的抽样个数（观测或实验次数），而是先抽少量样本，根据其结果，再决定停止抽样或继续抽样、抽多少，这样下去，直至决定停止抽样为止。\n",
        "\n",
        "\n",
        "例如，一个产品抽样检验方案规定按批抽样品20件，若其中不合格品件数不超过3，则接收该批，否则拒收。在此，抽样个数20是预定的，是固定抽样。\n",
        "\n",
        "若方案规定为：第一批抽出3个，若全为不合格品，拒收该批，若其中不合格品件数为 x1<3，则第二批再抽 3-x1 个，若全为不合格品，则拒收该批，若其中不合格品数为 x2<3-x1，则第三批再抽 3-x1-x2 个，这样下去，直到抽满20件或抽得3个不合格品为止。这是一个序贯抽样方案，其效果与前述固定抽样方案相同，但抽样个数平均讲要节省些。"
      ],
      "metadata": {
        "id": "8QFpmmOQbgez"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lxXQhcbbEt07"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Sample T-Test\n",
        "\n",
        "### Question: Does the average value differ across two groups?"
      ],
      "metadata": {
        "id": "KXYYSjuDb0ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pingouin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jB4SRHFHCBA",
        "outputId": "973abbc4-9483-447c-e60a-934d8be8a12e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pingouin in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from pingouin) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.11 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.12.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.13.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.2.2)\n",
            "Requirement already satisfied: pandas-flavor>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.5.0)\n",
            "Requirement already satisfied: outdated in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.8.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pingouin) (2022.7.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin) (2022.12.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin) (0.2)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (2.27.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basic datascience/data manipulation libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy.random as npr\n",
        "import scipy.stats as stats\n",
        "\n",
        "# graphs\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# formulat interface to statsmodels (standard linear models)\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# easy-to-use traditional psychological stats (t-test, anova)\n",
        "import pingouin as pg\n",
        "\n",
        "# hate these things\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "hZqXXQ14G7tq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "drug = np.array([101,100,102,104,102,97,105,105,98,101,100,123,105,103,100,95,102,106,\n",
        "        109,102,82,102,100,102,102,101,102,102,103,103,97,97,103,101,97,104,\n",
        "        96,103,124,101,101,100,101,101,104,100,101])\n",
        "placebo = np.array([99,101,100,101,102,100,97,101,104,101,102,102,100,105,88,101,100,\n",
        "           104,100,100,100,101,102,103,97,101,101,100,101,99,101,100,100,\n",
        "           101,100,99,101,100,102,99,100,99])\n",
        "\n",
        "\n",
        "# packing the data into a tidy dataframe can be nice\n",
        "exp_df = pd.DataFrame(dict(group=[0]*len(drug)+[1]*len(placebo), score=np.r_[drug,placebo]))\n",
        "\n",
        "exp_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tQ_v29d4HGzD",
        "outputId": "16fc1150-9b21-41f3-9816-840387b8d8e9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   group  score\n",
              "0      0    101\n",
              "1      0    100\n",
              "2      0    102\n",
              "3      0    104\n",
              "4      0    102"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-203729c3-0ea2-4482-9b6d-5d03b7e40105\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-203729c3-0ea2-4482-9b6d-5d03b7e40105')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-203729c3-0ea2-4482-9b6d-5d03b7e40105 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-203729c3-0ea2-4482-9b6d-5d03b7e40105');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the mean of the drug group different than the mean of the placebo group?"
      ],
      "metadata": {
        "id": "5ZRG5BBvHwCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean of drug group:\", drug.mean())\n",
        "print(\"Mean of placebo group:\", placebo.mean())\n",
        "print(\"The difference in means is: \", drug.mean()-placebo.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrPrfG5lHnb1",
        "outputId": "c37030d7-b59e-4ab5-9599-689347356b6c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of drug group: 101.91489361702128\n",
            "Mean of placebo group: 100.35714285714286\n",
            "The difference in means is:  1.5577507598784166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The look close but not identical. However, \"look\" isn't enough.\n",
        "\n",
        "Lets begin with a two-sample, independent samples t-test. We will assume that both groups have equal variance here."
      ],
      "metadata": {
        "id": "hd-WRPkKH8_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pg.ttest(x=drug, y=placebo, paired=False, alternative='two-sided', correction=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "_SZukA-7H24s",
        "outputId": "399cd2ef-ab30-44b3-a712-acdd4f401c7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               T  dof alternative     p-val          CI95%   cohen-d   BF10  \\\n",
              "T-test  1.558695   87   two-sided  0.122699  [-0.43, 3.54]  0.330965  0.642   \n",
              "\n",
              "           power  \n",
              "T-test  0.338035  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c0476a5-9b15-41a7-830a-040e85f2277a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>dof</th>\n",
              "      <th>alternative</th>\n",
              "      <th>p-val</th>\n",
              "      <th>CI95%</th>\n",
              "      <th>cohen-d</th>\n",
              "      <th>BF10</th>\n",
              "      <th>power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-test</th>\n",
              "      <td>1.558695</td>\n",
              "      <td>87</td>\n",
              "      <td>two-sided</td>\n",
              "      <td>0.122699</td>\n",
              "      <td>[-0.43, 3.54]</td>\n",
              "      <td>0.330965</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.338035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c0476a5-9b15-41a7-830a-040e85f2277a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c0476a5-9b15-41a7-830a-040e85f2277a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c0476a5-9b15-41a7-830a-040e85f2277a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We specified group `x` as `drug` and `y` as `placebo` (arbitrarily, you could flip that).\n",
        "\n",
        "We used 'two-sided' which is the traditionally more conservative test which you use unless you have a strong a-priori belief one group is going to have a higher mean value.\n",
        "\n",
        "We did not apply a correction known as the Welch-Satterthwaite correction for unequal variances.\n",
        "\n",
        "We will try that later."
      ],
      "metadata": {
        "id": "8INS1aAiJAqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that the t-value for the mean difference is 1.599.\n",
        "\n",
        "The test has 87 degrees of freedom.\n",
        "\n",
        "The p-value is 0.122699 which is greater than the traditional \"alpha\" cut off at p=0.05.\n",
        "\n",
        "Therefore this test is not significant.\n",
        "\n",
        "The 95% confidence interval for the differences between the means is -0.43 on the low end to 3.54 with (1.5577 the center).\n",
        "\n",
        "The effect size (Cohen's d) is 0.331.\n",
        "\n",
        "The Bayes Factor in favor of the alternative hypothesis (that the means are difference) is lower than one (0.642).\n",
        "\n",
        "The post-hoc power of the test is 0.338.\n",
        "\n",
        "All of this is consistent with there being basically no differences between these two groups.\n"
      ],
      "metadata": {
        "id": "s_qCEyTlJbpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Survival Times\n",
        "\n",
        "### Question: Does the hazard rate differ across two groups?"
      ],
      "metadata": {
        "id": "no3WLdXnb_8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lifelines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkmnXLhVPaOs",
        "outputId": "91c554b7-5669-4a59-90ca-4107519f9095"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.6.1)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines) (0.6.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines) (0.18.3)\n",
            "Requirement already satisfied: astor>=0.8 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (0.8.1)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.6.3)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->lifelines) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lifelines.datasets import load_waltons\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines.utils import median_survival_times\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 数据载入\n",
        "df = load_waltons()\n",
        "print(df.head(),'\\n')\n",
        "print(df['T'].min(),df['T'].max(),'\\n')\n",
        "print(df['E'].value_counts(),'\\n')\n",
        "print(df['group'].value_counts(),'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqZqSVz3QIWb",
        "outputId": "401371e2-9266-44c7-8356-55c663340deb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      T  E    group\n",
            "0   6.0  1  miR-137\n",
            "1  13.0  1  miR-137\n",
            "2  13.0  1  miR-137\n",
            "3  13.0  1  miR-137\n",
            "4  19.0  1  miR-137 \n",
            "\n",
            "6.0 75.0 \n",
            "\n",
            "1    156\n",
            "0      7\n",
            "Name: E, dtype: int64 \n",
            "\n",
            "control    129\n",
            "miR-137     34\n",
            "Name: group, dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到数据有三列，其中T代表min(D,O)，其中D为死亡时间，O为观测截止时间。\n",
        "\n",
        "E代表是否观察到“死亡”，1代表观测到了，0代表未观测到，即生存分析中的删失数据，共7个。\n",
        "\n",
        "group代表是否存在病毒，miR-137代表存在病毒，control代表为不存在即对照组，根据统计，存在miR-137病毒人数34人，不存在129人。\n",
        "\n",
        "需要注意，该格式并非严格的寿命表。"
      ],
      "metadata": {
        "id": "IkJVCyn0QeWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logrank检验的零假设是指两组的生存时间分布完全一致，当我们通过计算拒绝零假设时，就可以认为两组的生存时间分布存在统计学差异。"
      ],
      "metadata": {
        "id": "fHfZB6pVPnc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lifelines.statistics import logrank_test\n",
        "\n",
        "T = df['T']\n",
        "E = df['E']\n",
        "\n",
        "dem = (df['group'] == 'miR-137')\n",
        "\n",
        "results = logrank_test(T[dem], T[~dem], E[dem], E[~dem], alpha=.99)\n",
        "results.print_summary()\n",
        "print(results.p_value)\n",
        "print(results.test_statistic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "rxRoBVk-Pclx",
        "outputId": "3424e008-821b-46cc-c651-cc28937ffb61"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<lifelines.StatisticalResult: logrank_test>\n",
              "               t_0 = -1\n",
              " null_distribution = chi squared\n",
              "degrees_of_freedom = 1\n",
              "             alpha = 0.99\n",
              "         test_name = logrank_test\n",
              "\n",
              "---\n",
              " test_statistic      p  -log2(p)\n",
              "         122.25 <0.005     91.99"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>t_0</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>null_distribution</th>\n",
              "      <td>chi squared</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>degrees_of_freedom</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha</th>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_name</th>\n",
              "      <td>logrank_test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_statistic</th>\n",
              "      <th>p</th>\n",
              "      <th>-log2(p)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122.25</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>91.99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/latex": "\\begin{tabular}{lrrr}\n & test_statistic & p & -log2(p) \\\\\n0 & 122.25 & 0.00 & 91.99 \\\\\n\\end{tabular}\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0359832222854986e-28\n",
            "122.2491255730062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P值小于0.05，拒绝原假设，存在差异。"
      ],
      "metadata": {
        "id": "Yw-QFsiLR1go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count Data\n",
        "\n",
        "### Question: Does the rate of arrival differ across two time periods?"
      ],
      "metadata": {
        "id": "PZ2YG882bpPn"
      }
    }
  ]
}