{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWv79DVAff6cIJe8sqboKn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannasmile/colab_code_note/blob/main/Pytorch012.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AE（包含卷积）"
      ],
      "metadata": {
        "id": "rWrwocU85o8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdpqKUfi5jEP",
        "outputId": "91230c2f-a0b7-4c7a-cc4c-7ff78f8c9e32"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 77992674.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 67522683.29it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 28234927.58it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14132439.74it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/100], loss:186.2933\n",
            "epoch [2/100], loss:106.8397\n",
            "epoch [3/100], loss:82.3638\n",
            "epoch [4/100], loss:73.6374\n",
            "epoch [5/100], loss:69.2785\n",
            "epoch [6/100], loss:66.3837\n",
            "epoch [7/100], loss:64.1606\n",
            "epoch [8/100], loss:62.5021\n",
            "epoch [9/100], loss:61.2466\n",
            "epoch [10/100], loss:60.2273\n",
            "epoch [11/100], loss:59.3377\n",
            "epoch [12/100], loss:58.7013\n",
            "epoch [13/100], loss:58.1021\n",
            "epoch [14/100], loss:57.5438\n",
            "epoch [15/100], loss:56.9899\n",
            "epoch [16/100], loss:56.6212\n",
            "epoch [17/100], loss:56.2619\n",
            "epoch [18/100], loss:55.9111\n",
            "epoch [19/100], loss:55.6041\n",
            "epoch [20/100], loss:55.2879\n",
            "epoch [21/100], loss:54.9531\n",
            "epoch [22/100], loss:54.6254\n",
            "epoch [23/100], loss:54.3218\n",
            "epoch [24/100], loss:53.9432\n",
            "epoch [25/100], loss:53.4427\n",
            "epoch [26/100], loss:52.9927\n",
            "epoch [27/100], loss:52.6488\n",
            "epoch [28/100], loss:52.2780\n",
            "epoch [29/100], loss:51.9335\n",
            "epoch [30/100], loss:51.5701\n",
            "epoch [31/100], loss:51.2124\n",
            "epoch [32/100], loss:50.9080\n",
            "epoch [33/100], loss:50.5378\n",
            "epoch [34/100], loss:50.2258\n",
            "epoch [35/100], loss:49.8870\n",
            "epoch [36/100], loss:49.6210\n",
            "epoch [37/100], loss:49.3358\n",
            "epoch [38/100], loss:49.0879\n",
            "epoch [39/100], loss:48.8846\n",
            "epoch [40/100], loss:48.6908\n",
            "epoch [41/100], loss:48.5416\n",
            "epoch [42/100], loss:48.3689\n",
            "epoch [43/100], loss:48.2284\n",
            "epoch [44/100], loss:48.0754\n",
            "epoch [45/100], loss:47.9497\n",
            "epoch [46/100], loss:47.7436\n",
            "epoch [47/100], loss:47.6193\n",
            "epoch [48/100], loss:47.4334\n",
            "epoch [49/100], loss:47.3509\n",
            "epoch [50/100], loss:47.2679\n",
            "epoch [51/100], loss:47.1313\n",
            "epoch [52/100], loss:47.0107\n",
            "epoch [53/100], loss:46.9363\n",
            "epoch [54/100], loss:46.8717\n",
            "epoch [55/100], loss:46.7352\n",
            "epoch [56/100], loss:46.6484\n",
            "epoch [57/100], loss:46.5913\n",
            "epoch [58/100], loss:46.4340\n",
            "epoch [59/100], loss:46.3989\n",
            "epoch [60/100], loss:46.3170\n",
            "epoch [61/100], loss:46.2060\n",
            "epoch [62/100], loss:46.1701\n",
            "epoch [63/100], loss:46.0739\n",
            "epoch [64/100], loss:45.9983\n",
            "epoch [65/100], loss:45.9466\n",
            "epoch [66/100], loss:45.8994\n",
            "epoch [67/100], loss:45.8118\n",
            "epoch [68/100], loss:45.7508\n",
            "epoch [69/100], loss:45.7086\n",
            "epoch [70/100], loss:45.6304\n",
            "epoch [71/100], loss:45.6023\n",
            "epoch [72/100], loss:45.5459\n",
            "epoch [73/100], loss:45.4713\n",
            "epoch [74/100], loss:45.4514\n",
            "epoch [75/100], loss:45.3635\n",
            "epoch [76/100], loss:45.3247\n",
            "epoch [77/100], loss:45.2780\n",
            "epoch [78/100], loss:45.2530\n",
            "epoch [79/100], loss:45.1999\n",
            "epoch [80/100], loss:45.1831\n",
            "epoch [81/100], loss:45.1442\n",
            "epoch [82/100], loss:45.0890\n",
            "epoch [83/100], loss:45.0275\n",
            "epoch [84/100], loss:45.0157\n",
            "epoch [85/100], loss:44.9858\n",
            "epoch [86/100], loss:44.9830\n",
            "epoch [87/100], loss:44.9101\n",
            "epoch [88/100], loss:44.8828\n",
            "epoch [89/100], loss:44.8179\n",
            "epoch [90/100], loss:44.7791\n",
            "epoch [91/100], loss:44.7426\n",
            "epoch [92/100], loss:44.7314\n",
            "epoch [93/100], loss:44.6598\n",
            "epoch [94/100], loss:44.6474\n",
            "epoch [95/100], loss:44.6410\n",
            "epoch [96/100], loss:44.5498\n",
            "epoch [97/100], loss:44.5101\n",
            "epoch [98/100], loss:44.5133\n",
            "epoch [99/100], loss:44.4639\n",
            "epoch [100/100], loss:44.4094\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import MNIST\n",
        "import os\n",
        "\n",
        "if not os.path.exists('./dc_img'):\n",
        "    os.mkdir('./dc_img')\n",
        "\n",
        "\n",
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.size(0), 1, 28, 28)\n",
        "    return x\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "dataset = MNIST('./data', transform=img_transform, download=True)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
        "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = autoencoder()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "#model = autoencoder().cuda()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        img, _ = data\n",
        "        img = Variable(img)\n",
        "        if torch.cuda.is_available():\n",
        "            img = img.cuda()\n",
        "        # ===================forward=====================\n",
        "        output = model(img)\n",
        "        loss = criterion(output, img)\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.data\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss:{:.4f}'\n",
        "          .format(epoch+1, num_epochs, total_loss))\n",
        "    if epoch % 10 == 0:\n",
        "        pic = to_img(output.cpu().data)\n",
        "        save_image(pic, './dc_img/image_{}.png'.format(epoch))\n",
        "\n",
        "torch.save(model.state_dict(), './conv_autoencoder.pth')"
      ]
    }
  ]
}